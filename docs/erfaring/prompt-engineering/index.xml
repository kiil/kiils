<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Prompt engineering on Kiils</title>
    <link>https://www.kiils.dk/erfaring/prompt-engineering/</link>
    <description>Recent content in Prompt engineering on Kiils</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>da-dk</language>
    <lastBuildDate>Sat, 01 Apr 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://www.kiils.dk/erfaring/prompt-engineering/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hvad er en stor sprogmodel</title>
      <link>https://www.kiils.dk/erfaring/prompt-engineering/hvad-er-en-stor-sprogmodel/</link>
      <pubDate>Tue, 16 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kiils.dk/erfaring/prompt-engineering/hvad-er-en-stor-sprogmodel/</guid>
      <description>En stor sprogmodel er et program eller en kompleks funktion der forholder tekst til tekst. Det lyder meget abstrakt.
Så hvad betyder det i praksis?
En sprogmodel kan fodres med en sekvens af ord (eller orddele, kaldet tokens), altså en sætning eller et afsnit eller et længere stykke tekst som jo egentligt bare er ord og tegn i en bestemt rækkefølge, og derfra forsøge at forudsige det mest sandsynlige ord eller sekvens af ord der kommer efter.</description>
    </item>
    
    <item>
      <title>Hvorfor prompt engineering</title>
      <link>https://www.kiils.dk/erfaring/prompt-engineering/hvorfor/</link>
      <pubDate>Tue, 16 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kiils.dk/erfaring/prompt-engineering/hvorfor/</guid>
      <description>Up above, we used an analogy of prompts as the “source code” that a language model “interprets”. Prompt engineering is the art of writing prompts to get the language model to do what we want it to do – just like software engineering is the art of writing source code to get computers to do what we want them to do.
When writing good prompts, you have to account for the idiosyncrasies of the model(s) you’re working with.</description>
    </item>
    
    <item>
      <title>udenomssnak</title>
      <link>https://www.kiils.dk/erfaring/prompt-engineering/udenomssnak/</link>
      <pubDate>Tue, 16 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kiils.dk/erfaring/prompt-engineering/udenomssnak/</guid>
      <description>Mig: fortæl mig om ordet gladiator
ChatGPT giver så et langt svar hvor kun en enkelt sætning handler om ordet selv, mens 90 procent af svaret handler om det ordet betegner.
Nu prøver jeg noget andet:
Mig: Du er etymolog og ekspert i ords oprindelse. Du skal forklare mig hvor et ord stammer fra og hvordan det har udviklet sig sproghistorisk.
ChatGPT: Selvfølgelig! Jeg hjælper gerne med at udforske et ords oprindelse og dets sproghistoriske udvikling.</description>
    </item>
    
    <item>
      <title>advanceret</title>
      <link>https://www.kiils.dk/erfaring/prompt-engineering/advanceret/</link>
      <pubDate>Mon, 15 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kiils.dk/erfaring/prompt-engineering/advanceret/</guid>
      <description>Techniques to improve reliability
When GPT-3 fails on a task, what should you do?
Search for a better prompt that elicits more reliable answers? Invest in thousands of examples to fine-tune a custom model? Assume the model is incapable of the task, and move on? There is no simple answer - it depends. However, if your task involves logical reasoning or complexity, consider trying the techniques in this article to build more reliable, high-performing prompts.</description>
    </item>
    
    <item>
      <title>Show and tell</title>
      <link>https://www.kiils.dk/erfaring/prompt-engineering/show-and-tell/</link>
      <pubDate>Mon, 15 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kiils.dk/erfaring/prompt-engineering/show-and-tell/</guid>
      <description>I journalistik siger man ofte, show it, don&amp;rsquo;t tell it.
Når det gælder</description>
    </item>
    
    <item>
      <title>System</title>
      <link>https://www.kiils.dk/erfaring/prompt-engineering/system/</link>
      <pubDate>Mon, 15 May 2023 00:00:00 +0000</pubDate>
      
      <guid>https://www.kiils.dk/erfaring/prompt-engineering/system/</guid>
      <description>Traditionally, GPT models consumed unstructured text. ChatGPT models instead expect a structured format, called Chat Markup Language (ChatML for short). ChatML documents consists of a sequence of messages. Each message contains a header (which today consists of who said it, but in the future will contain other metadata) and contents (which today is a text payload, but in the future will contain other datatypes).
openai-python/chatml.md at main · openai/openai-python · GitHub ¶ Note: you need to be using OpenAI Python v0.</description>
    </item>
    
  </channel>
</rss>
