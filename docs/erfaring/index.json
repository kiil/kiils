[
    
    
    {
        "url": "/ydelse/raadgivning/indholdsstrategi/",
        "title": "Hjælp til indholdsstrategi",
        "content": "En lind strøm af relevant indhold er i dag en forudsætning for at fastholde opmærksomheden på et medie eller brand \u0026mdash; eller bare en blog.\nIndholdsstrategi er den langsigtede tilgang til den daglige redaktionelle proces med at skabe, udvælge og mikse indhold.\nMen indholdsstrategi omfatter også den løbende tilpasning og opdatering af det mere faste indhold som er essentielt for ens forretning.\nNogle har svært ved at finde retningen for deres indhold, andre svært ved at lægge planen og atter andre svært ved at holde sig til den.\nJeg kan hjælpe.\n"
    }
    
    , 
    {
        "url": "/ydelse/redaktionelt/formidling/",
        "title": "Formidling i særklasse",
        "content": "Formidling er en af mine spidskompetencer. Jeg har arbejdet mange år som videnskabsjournallist, og har flere større formidlingsopgaver i porteføljen. Jeg har formidlet til alt fra børn og unge til fagpersoner inden for videnskabelige og teknologiske områder.\nNogle af landets største organisationer og mediehuse har sat deres lid til mine evner som formidler, og det kan du også roligt gøre. Jeg kan tage mig af små enkeltopgaver og store projekter med hundredevis af tekster eller mere.\nJeg anser mig selv som ekspert i formidling, så lad os tage en snak om hvordan vi sammen kan formidle dit budskab til den rigtige målgruppe.\n"
    }
    
    , 
    {
        "url": "/ydelse/redaktionelt/redigering/",
        "title": "Redigering af tekst",
        "content": "Jeg sælger redigering af tekster som journalistisk ydelse.\nJeg har enorm stor erfaring med redigering af tekster, og jeg har uden overdrivelse redigeret tusindvis af tekster.\nMin redigering sker som regel først efter at du i store træk har lagt dig fast på hvad der skal med i din tekst og hvor der skal skæres fra.\n"
    }
    
    , 
    {
        "url": "/ydelse/",
        "title": "Ydelser",
        "content": ""
    }
    
    , 
    {
        "url": "/anbefalinger/",
        "title": "Anbefalinger",
        "content": ""
    }
    
    , 
    {
        "url": "/ydelse/research/faktatjek/",
        "title": "Køb et faktatjek",
        "content": "Jeg sælger faktatjek som journalistisk ydelse.\nJeg har lavet mange faktatjek, og den fakta-orienterede tilgang til journalistik stemmer med min faglige og videnskabelige baggrund som cand.scient. Et faktatjek handler først og fremmest om at \u0026ldquo;falsificere\u0026rdquo; en påstand og ikke om at etablere en sandhed.\nVi taler om hvad det er for en påstand som du ønsker efterprøvet — og alt efter hvor meget arbejde der ligger i det, laver jeg et tilbud som du kan sige ja eller nej til.\nDer er nogle faldgruber, man skal være opmærksom på ved fakta-tjek. Her vil jeg nævne to\nHvis et fakta-tjek ikke formidleres og kommunikeres korrekt, så risikerer man faktisk at forstærke den myte som fakta-tjekket skulle afmontere. “Det kræver ti gange mere energi at tilbagevise bullshit end at procudere det” - frit efter den italienske programmør Alberto Brandolini. "
    }
    
    , 
    {
        "url": "/ydelse/raadgivning/digital-coaching/",
        "title": "Digital coaching",
        "content": "Digital coaching er uden tvivl den bredeste ydelse i mit sortiment.\nDet er fordi indholdet fuldstændig afhænger af hvad du har behov for at få belyst, vendt eller drejet.\nDet kan være valg af CMS - eller passer en static site generator bedre?\nFå hjælp til at overskue dt digitale liv\n"
    }
    
    , 
    {
        "url": "/ydelse/raadgivning/balance/",
        "title": "Find balancen mellem analog og digital",
        "content": "Det digitale fylder meget. Hvordan tæmmer man den evindelige strøm af nyheder og notifikationer.\nFå styr på det digitale, så det tjener dig og ikke omvendt.\n"
    }
    
    , 
    {
        "url": "/ydelse/redaktionelt/korrektur/",
        "title": "Korrektur",
        "content": "Jeg er som redaktør på en medieplatform vant til at læse korrektur på mange slags tekster. Som fagformidler kan jeg også læse korrektur på mere tekniske eller branchespecifikke tekster.\nMine kunder fremhæver at jeg både evner det rent tekniske i retstavning og samtidig forstår stoffet og læserens perspektiv. Jeg kan dermed supplere selve korrekturlæsningen med input til indhold og den redaktionelle proces.\nJeg kan alt det man foreløbig ikke kan sætte kunstig intelligens til.\n"
    }
    
    , 
    {
        "url": "/ydelse/redaktionelt/tekst/",
        "title": "Køb en tekst",
        "content": "Jeg sælger tekster som journalistisk ydelse.\nJeg har gennem årene solgt i hundredevis af tekster som artikler. Jeg har skrevet langt flere end det til mine egne medier og for eksempel til klimaleksikon.\nJeg skriver relativt knapt og præcist.\n"
    }
    
    , 
    {
        "url": "/anbefalinger/per-gastrofun/",
        "title": "Mine varmeste anbefalinger",
        "content": " Mine varmeste anbefalinger\n— Per Asmussen, Gastrofun\n"
    }
    
    , 
    {
        "url": "/ydelse/research/skattejagt/",
        "title": "Skattejagt",
        "content": "Nogle gange er det svært at finde fejlene i sine egne projekter.\nJeg vil gerne gå på jagt efter steder som kan forbedres.\n"
    }
    
    , 
    {
        "url": "/tools/chatgpt/",
        "title": "ChatGPT",
        "content": "ChatGPT er en samtale-orienteret sprogmodel baseret på en ikke nærmere defineret viderudvikling af GPT-3 under OpenAi og microsoft.\nGPT-3 er trænet hovedsaglig med engelsk tekst, men alligevel er ChatGPT anvendelig på andre sprog, herunder dansk i et vist omfang.\nModellen er uspecifik, og derfor er det indledende prompt afgørende for udbyttet af en samtale, en såkaldt chat.\nDu kan finde inspiration til danske prompts her:\nDanske ChatGPT prompts "
    }
    
    , 
    {
        "url": "/emner/",
        "title": "Emner",
        "content": "Emner i det arbejde Kiils laver\n"
    }
    
    , 
    {
        "url": "/erfaring/",
        "title": "Erfaring",
        "content": ""
    }
    
    , 
    {
        "url": "/",
        "title": "Kiils",
        "content": " Stærke tekster til en digital tidsalder "
    }
    
    , 
    {
        "url": "/emner/kunstig-intelligens/",
        "title": "kunstig intelligens",
        "content": ""
    }
    
    , 
    {
        "url": "/skribenter/lennart-kiil/",
        "title": "Lennart Kiil",
        "content": "Lennart Kiil kan også findes på FOLKETS , og på LinkedIn .\n"
    }
    
    , 
    {
        "url": "/erfaring/jeg-gav-igen-chatgpt-adgang-til-min-dagbog-nu-kan-den-forudsige-min-fremtid/",
        "title": "På baggrund af mine dagbogsoptegnelser bad jeg ChatGPT forudsige min fremtid - og fik en klump i halsen",
        "content": "ChatGPT er en stor sprogmodel.\nHvad er det store sprogmodeller kan?\nJo, de kan \u0026ldquo;forudsige\u0026rdquo; det næste ord, eller teknisk set den næste sekvens af tokens, ud fra det input man giver den (som den jo også \u0026ldquo;bare\u0026rdquo; omsætter til tokens i betydningsfuld rækkefølge).\nSå store sprogmodeller kan se mønstre og sammenhænge.\nAt kunne se mønstre og sammenhænge er det samme som at kunne forudsige.\nMen kan ChatGPT forudsige fremtiden?\nMåske husker I at jeg gav ChatGPT adgang til min dagbog - det skulle jeg aldrig have gjort for noget tid siden.\nNu har jeg igen givet givet ChatGPT adgang til min dagbog. Men denne gange bare meget mere af den \u0026ndash; OpenAI har jo nu lovet mig at de ikke gemmer mine data mere end 30 dage.\nMen jeg gjorde også noget andet i denne omgang.\nI stedet for bare at give mig et månedligt referat, så bad jeg ChatGPT lave nogle fremtidige dagbogsoptegnelser.\nSå ChatGPT fik mine gamle dagbogsnotater som input og output skulle så skrives som mig på tidspunkter i fremtiden.\nHer er dens output\n¶ 2024-05-15 Data science-kursus Startede på et data science-kursus på Coursera i dag. Spændende at lære noget nyt og udvide mine færdigheder.\nAlexander har hjemmearbejde i dansk om ordsprog, og Olivia øver sig på sin guitar. Det er godt at se dem engagerede i deres skolearbejde og hobbies.\nJeg fik også løbet en tur i dag og føler mig godt tilpas.\n#uddannelse #hjemmeskole #hobby #løb\nSå om et år tager jeg et kursus i \u0026ldquo;science\u0026rdquo;. Spændende.\nOgså godt at vide at min datter på det tidspunkt er begyndt at spille guitar. Og hvilket hjemmearbejde jeg skal forberede mig på at min søn får med hjem fra skolen.\nJeg bad også ChatGPT gå længere frem, og her fik jeg en klump i halsen. For første gang lykkedes det ChatGPT at fremprovokere en følelse i mig.\nSe her:\n20NN-05-15 Besøg af gamle venner\nVi fik besøg af nogle gamle venner fra studietiden i København.\nDet var hyggeligt at se dem igen, selvom det var længe siden.\nAlexander og Olivia legede med deres børn i haven, og vi grillede.\n[\u0026hellip;]\n#venner #grill #hygge\nVi er nu fremme hvor jeg er bedstefar. Åbenbart.\nDet er interessant at bruge ChatGPT på kreative måder.\nSelvom jeg er pinligt bevidst om at den ikke kan forudsige fremtiden. I hvert fald ikke mere end alle os andre.\n"
    }
    
    , 
    {
        "url": "/skribenter/",
        "title": "Skribenter",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/",
        "title": "Tools",
        "content": ""
    }
    
    , 
    {
        "url": "/cases/",
        "title": "Cases",
        "content": "Under linket til hver enkelt case er nogle af mine erfaringer med pågældende case også linket. Jo, man lærer meget hen ad vejen.\n"
    }
    
    , 
    {
        "url": "/emner/finansiering/",
        "title": "Finansiering",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/prompt-engineering/hvad-er-en-stor-sprogmodel/",
        "title": "Hvad er en stor sprogmodel",
        "content": "En stor sprogmodel er et program eller en kompleks funktion der forholder tekst til tekst. Det lyder meget abstrakt.\nSå hvad betyder det i praksis?\nEn sprogmodel kan fodres med en sekvens af ord (eller orddele, kaldet tokens), altså en sætning eller et afsnit eller et længere stykke tekst som jo egentligt bare er ord og tegn i en bestemt rækkefølge, og derfra forsøge at forudsige det mest sandsynlige ord eller sekvens af ord der kommer efter.\nDet gør sprogmodellen ved at tildele sandsynligheder til mulige ord og sætninger og typisk vælge ud fra højeste score for sammenhæng.\nDe store sprogmodeller lærer de mest sandsynlige sammenhænge mellem ord og brudstykker af tekst gennem træning på enorme mængder af tekst.\nSom konsekvens af træningen på enorme mængder tekst, bliver sprogmodellerne gode til at skabe formuleringer som er naturtro og mundrette.\nSproget bliver ret forfuldendt. Men den viden som sproget bærer, bliver mere abstrakt og afkoblet fra de oprindelige sammenhænge.\nDe mest populære store sprogmodeller i dag er oveni meget generelle og favner utrolig bredt.\nFor at få brugbare svar ud af disse sprogmodeller, skal man derfor give dem inputs som viser ord i sammenhæng. Jo mere sammenhæng, jo bedre.\nAt give sprogmodeller det rigtige input med relevant sammenhæng omtales nogle gange som prompt design, men det tyder på at det almindeligt accepterede begreb bliver det endnu mindre mundrette prompt engineering som også dålrigt lader sig oversætte til dansk.\nHer i serien bruger jeg betegnelsen prompt engineering om forsøget på at skabe inputs til store sprogmodeller som giver brugbare resultater.\n"
    }
    
    , 
    {
        "url": "/erfaring/prompt-engineering/hvorfor/",
        "title": "Hvorfor prompt engineering",
        "content": "Up above, we used an analogy of prompts as the “source code” that a language model “interprets”. Prompt engineering is the art of writing prompts to get the language model to do what we want it to do – just like software engineering is the art of writing source code to get computers to do what we want them to do.\nWhen writing good prompts, you have to account for the idiosyncrasies of the model(s) you’re working with. The strategies will vary with the complexity of the tasks. You’ll have to come up with mechanisms to constrain the model to achieve reliable results, incorporate dynamic data that the model can’t be trained on, account for limitations in the model’s training data, design around context limits, and many other dimensions.\nThere’s an old adage that computers will only do what you tell them to do. Throw that advice out the window. Prompt engineering inverts this wisdom. It’s like programming in natural language against a non-deterministic computer that will do anything that you haven’t guided it away from doing.\nThere are two broad buckets that prompt engineering approaches fall into.\n"
    }
    
    , 
    {
        "url": "/cases/klimaleksikon/",
        "title": "Klimaleksikon",
        "content": "Her i 2023 fylder Klimaleksikon 15 år!\nKlimaleksikon er dermed Danmarks bedste og længstlevende side om klima .\nSiden er et samarbejde mellem mig og to andre naturfagsformidlere, Thomas Hesselberg og Mikkel Houmøller. Siden indeholder omkring 100 opslag på centrale emner inden for klima og klarer sig enormt godt i google-søgninger.\nSiden holdes løbende opdateret, og hundredetusinder af børn og unge har lært om klima og energi på siden.\nSidens brugere er overvejende børn i folkeskolens ældste klasser og unge på ungdomsuddannelserne.\nLærerne bruger aktivt Klimaleksikon i undervisningen, det ses blandt andet af de mange henvisninger fra diverse undervisningsplatforme:\nDesuden ser vi at Klimaleksikon hovedsageligt finder anvendelse inden for den almindelige undervisningstid:\nDer er en overvægt af piger hvilket er en smule atypisk for en side som i bund og grund er naturvidenskabeligt orienteret og skabt af naturfagsformidlere.\nMen det viser i hvert fald at interessen i naturvidenskab og teknologi er der fra den kant også når det overordnede emne blot er vedkommende nok.\nOpslagene, som er kerneindholdet på siden, er naturligvis skrevet i et tilgængeligt sprog som passer til målgruppen af unge mennesker. Men mange granvoksne har skam også glæde af siden. På en række af opslagene har vi nederst spørgsmål, som brugeren kan besvare og dermed få en fornemmelse af om man fået fat i de væsentligste oplysninger i teksten ovenfor.\nSiden er strengt apolitisk og faktuelt baseret. Det er en aftale jeg selv er glad for, da der er en stor lettelse i at være involveret i noget som er ent fakta-orienteret. Jeg nyder virkelig at have et frirum for politik og har derfor meget let ved at adskille Klimaleksikon fra mit øvrige virke.\n"
    }
    
    , 
    {
        "url": "/tools/nvim/",
        "title": "nvim",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/prompt-engineering/udenomssnak/",
        "title": "udenomssnak",
        "content": "Mig: fortæl mig om ordet gladiator\nChatGPT giver så et langt svar hvor kun en enkelt sætning handler om ordet selv, mens 90 procent af svaret handler om det ordet betegner.\nNu prøver jeg noget andet:\nMig: Du er etymolog og ekspert i ords oprindelse. Du skal forklare mig hvor et ord stammer fra og hvordan det har udviklet sig sproghistorisk.\nChatGPT: Selvfølgelig! Jeg hjælper gerne med at udforske et ords oprindelse og dets sproghistoriske udvikling. Fortæl mig venligst hvilket ord du er interesseret i, så vi kan dykke ned i dets historie.\nMig: gladiator\nChatGPT giver mig nu et svar hvor omkring halvdelen af svaret omhandler selve ordet og det etymologi. Men der er stadig meget udenomssnak.\nLad os prøve et give ChatGPT et par eksempler på svar i det ønskede \u0026ldquo;format\u0026rdquo;.\nMin erfaring er at følgende virker fint til husbehov:\nDu er etymolog\nLad os sige du vil skrive et læserbrev med hjælp fra ChatGPT\nRolle / instruktion - det er den generelle opgave du stiller ChatGPT\nEksempler - det er nogle eksempler som illustrerer mere konkret og specifikt\nSkabelon\nDu er etymolog og ekspert i ords oprindelse. Du skal forklare mig hvor et ord stammer fra og hvordan det har udviklet sig sproghistorisk.\nEksempler\nmåge: gammeldansk maghæ, afledt af en lydefterlignende rod\nkriger: fra tysk Krieger, afledt af et ældre verbum krige \u0026lsquo;føre krig\u0026rsquo;\ngladiator:\nNu svarer ChatGPT i første linje nøjagtig på den form som jeg har angivet, og samlet set handler 75 procent arf svaret nu om ordet, selvom ChatGPT kort glider af sporet.\nMen der er også en konkflikt mellem den generelle opgave jeg giver og de sepcifuikke eksxempler så med ebn lille ændring:\nChatGPT bliver ved med at give lange svar.\nMen skriver jeg\nGiv et kort svar måge: gammeldansk maghæ, afledt af en lydefterlignende rod kriger: fra tysk Krieger, afledt af et ældre verbum krige \u0026#39;føre krig\u0026#39; gladiator: Får jeg endelig noget ud på en form jeg kan bruge:\nfra latin gladiator, afledt af gladius, der betyder 'sværd'\nGenerel instruks om form Konkrete eksempler på indhold Prompt - den del som ChatGPT skal færdiggøre "
    }
    
    , 
    {
        "url": "/erfaring/prompt-engineering/advanceret/",
        "title": "advanceret",
        "content": "Techniques to improve reliability\nWhen GPT-3 fails on a task, what should you do?\nSearch for a better prompt that elicits more reliable answers? Invest in thousands of examples to fine-tune a custom model? Assume the model is incapable of the task, and move on? There is no simple answer - it depends. However, if your task involves logical reasoning or complexity, consider trying the techniques in this article to build more reliable, high-performing prompts. Why GPT-3 fails on complex tasks\nIf you were asked to multiply 13 by 17, would the answer pop immediately into your mind? For most of us, probably not. Yet, that doesn\u0026rsquo;t mean humans are incapable of two-digit multiplication. With a few seconds, and some pen and paper, it\u0026rsquo;s not too taxing to work out that 13 x 17 = 130 + 70 + 21 = 221.\nSimilarly, if you give GPT-3 a task that\u0026rsquo;s too complex to do in the time it takes to calculate its next token, it may confabulate an incorrect guess. Yet, akin to humans, that doesn\u0026rsquo;t necessarily mean the model is incapable of the task. With some time and space to reason things out, the model still may be able to answer reliably.\nAs an example, if you ask text-davinci-002 the following math problem about juggling balls, it answers incorrectly:\nQ: A juggler has 16 balls. Half of the balls are golf balls and half of the golf balls are blue. How many blue golf balls are there? A:\nThere are 8 blue golf balls.\nDoes this mean that GPT-3 cannot do simple math problems? No; in fact, it turns out that by prompting the model with Let\u0026rsquo;s think step by step, the model solves the problem reliably:\nQ: A juggler has 16 balls. Half of the balls are golf balls and half of the golf balls are blue. How many blue golf balls are there? A: Let\u0026rsquo;s think step by step.\nThere are 16 balls in total. Half of the balls are golf balls. That means that there are 8 golf balls. Half of the golf balls are blue. That means that there are 4 blue golf balls.\nOf course, it\u0026rsquo;s hard to tell from only a single example whether this Let\u0026rsquo;s think step by step trick actually works in general or just got lucky on this particular problem. But it really does work. On a benchmark of word math problems, the Let\u0026rsquo;s think step by step trick raised GPT-3\u0026rsquo;s solve rate massively, from a worthless 18% to a decent 79%! Model capabilities depend on context\nWhen learning to work with GPT-3, one common conceptual mistake is to believe that its capabilities are fixed across all contexts. E.g., if GPT-3 gets a simple logic question wrong, then it must be incapable of simple logic.\nBut as the Let\u0026rsquo;s think step by step example illustrates, apparent failures of GPT-3 can sometimes be remedied with a better prompt that helps the model steer itself toward the correct output. How to improve reliability on complex tasks\nThe rest of this article shares techniques for improving reliability of large language models on complex tasks. Although some of the techniques are specific to certain types of problems, many of them are built upon general principles that can be applied to a wide range of tasks, e.g.:\nGive clearer instructions Split complex tasks into simpler subtasks Structure the instruction to keep the model on task Prompt the model to explain before answering Ask for justifications of many possible answers, and then synthesize Generate many outputs, and then use the model to pick the best one Fine-tune custom models to maximize performance Split complex tasks into simpler tasks\nOne way to give a model more time and space to think is to break tasks into simpler pieces.\nAs an example, consider a task where we ask the model a multiple-choice question about some text - in this case, a game of Clue. When asked directly, text-davinci-002 isn\u0026rsquo;t able to put clues 3 \u0026amp; 5 together, and answers incorrectly:\nUse the following clues to answer the following multiple-choice question.\nClues:\nMiss Scarlett was the only person in the lounge. The person with the pipe was in the kitchen. Colonel Mustard was the only person in the observatory. Professor Plum was not in the library nor the billiard room. The person with the candlestick was in the observatory. Question: Was Colonel Mustard in the observatory with the candlestick? (a) Yes; Colonel Mustard was in the observatory with the candlestick (b) No; Colonel Mustard was not in the observatory with the candlestick (c) Unknown; there is not enough information to determine whether Colonel Mustard was in the observatory with the candlestick\nSolution:\n(c) Unknown; there is not enough information to determine whether Colonel Mustard was in the observatory with the candlestick\nAlthough clues 3 and 5 establish that Colonel Mustard was the only person in the observatory and that the person in the observatory had the candlestick, the model fails to combine them into a correct answer of (a) Yes.\nHowever, instead of asking for the answer directly, we can split the task into three pieces:\nFirst, go through the clues one by one and consider whether the clue is potentially relevant Second, combine the relevant clues to reason out the answer to the question Third, write the final answer: either (a), (b), or (c) Use the following clues to answer the following multiple-choice question, using the following procedure: (1) First, go through the clues one by one and consider whether the clue is potentially relevant (2) Second, combine the relevant clues to reason out the answer to the question (3) Third, map the answer to one of the multiple choice answers: either (a), (b), or (c)\nClues:\nMiss Scarlett was the only person in the lounge. The person with the pipe was in the kitchen. Colonel Mustard was the only person in the observatory. Professor Plum was not in the library nor the billiard room. The person with the candlestick was in the observatory. Question: Was Colonel Mustard in the observatory with the candlestick? (a) Yes; Colonel Mustard was in the observatory with the candlestick (b) No; Colonel Mustard was not in the observatory with the candlestick (c) Unknown; there is not enough information to determine whether Colonel Mustard was in the observatory with the candlestick\nSolution: (1) First, go through the clues one by one and consider whether the clue is potentially relevant:\nClue 1: Miss Scarlett was the only person in the lounge. This clue is not relevant. Clue 2: The person with the pipe was in the kitchen. This clue is not relevant. Clue 3: Colonel Mustard was the only person in the observatory. This clue is relevant. Clue 4: Professor Plum was not in the library nor the billiard room. This clue is not relevant. Clue 5: The person with the candlestick was in the observatory. This clue is relevant.\n(2) Second, combine the relevant clues to reason out the answer to the question: Clue 3 and Clue 5 both say that the person with the candlestick was in the observatory. Colonel Mustard was the only person in the observatory, so Colonel Mustard was the person with the candlestick.\n(3) Third, write the final answer: (a) Yes; Colonel Mustard was in the observatory with the candlestick\nBy giving the model more time and space to think, and guiding it along a reasoning plan, it\u0026rsquo;s able to figure out the correct answer of (a) Yes.\nAnother benefit of splitting complex instructions into smaller subtasks is that it can help keep the model focused on each subtask.\nFor example, if we ask text-davinci-002 to summarize a text in its original language, the model can lapse back into English:\nSummarize the text using the original language of the text. The summary should be one sentence long.\nText: \u0026quot;\u0026quot;\u0026quot; La estadística (la forma femenina del término alemán Statistik, derivado a su vez del italiano statista, \u0026ldquo;hombre de Estado\u0026rdquo;)​ es una ciencia que estudia la variabilidad, colección, organización, análisis, interpretación, y presentación de los datos, así como el proceso aleatorio que los genera siguiendo las leyes de la probabilidad.​ La estadística es una ciencia formal deductiva, con un conocimiento propio, dinámico y en continuo desarrollo obtenido a través del método científico formal. En ocasiones, las ciencias fácticas necesitan utilizar técnicas estadísticas durante su proceso de investigación factual, con el fin de obtener nuevos conocimientos basados en la experimentación y en la observación. En estos casos, la aplicación de la estadística permite el análisis de datos provenientes de una muestra representativa, que busca explicar las correlaciones y dependencias de un fenómeno físico o natural, de ocurrencia en forma aleatoria o condicional. \u0026quot;\u0026quot;\u0026quot;\nSummary:\nThe text explains that statistics is a science that studies the variability, collection, organization, analysis, interpretation, and presentation of data, as well as the random process that generates them following the laws of probability.\nHowever, if we first ask the model to identify the language of the text, and then summarize the text, it becomes more reliable:\nFirst, identify the language of the text. Second, summarize the text using the original language of the text. The summary should be one sentence long.\nText: \u0026quot;\u0026quot;\u0026quot; La estadística (la forma femenina del término alemán Statistik, derivado a su vez del italiano statista, \u0026ldquo;hombre de Estado\u0026rdquo;)​ es una ciencia que estudia la variabilidad, colección, organización, análisis, interpretación, y presentación de los datos, así como el proceso aleatorio que los genera siguiendo las leyes de la probabilidad.​ La estadística es una ciencia formal deductiva, con un conocimiento propio, dinámico y en continuo desarrollo obtenido a través del método científico formal. En ocasiones, las ciencias fácticas necesitan utilizar técnicas estadísticas durante su proceso de investigación factual, con el fin de obtener nuevos conocimientos basados en la experimentación y en la observación. En estos casos, la aplicación de la estadística permite el análisis de datos provenientes de una muestra representativa, que busca explicar las correlaciones y dependencias de un fenómeno físico o natural, de ocurrencia en forma aleatoria o condicional. \u0026quot;\u0026quot;\u0026quot;\nLanguage:\nSpanish\nLa estadística es una ciencia que estudia la variabilidad, colección, organización, análisis, interpretación, y presentación de los datos, así como el proceso aleatorio que los genera siguiendo las leyes de la probabilidad.\nPrompt the model to explain before answering\nAnother powerful technique for improving the reliability of answers is to prompt the model to gradually reason out the answer rather than jumping immediately to the final answer. By \u0026rsquo;thinking aloud\u0026rsquo; the model can be far more likely to arrive at the correct answer. Zero-shot Method\nPublished by Takeshi Kojima et al. in 2022, the easiest way to prompt a model to reason out the answer is to simply prepend answers with Let\u0026rsquo;s think step by step. Figure 2 illustrates an example:\nzero-shot reasoning example Source: Large Language Models are Zero-Shot Reasoners by Takeshi Kojima et al. (2022). Results\nApplying this simple trick to the MultiArith math dataset, the authors found Let\u0026rsquo;s think step by step quadrupled the accuracy, from 18% to 79%!\nzero-shot reasoning example Source: Large Language Models are Zero-Shot Reasoners by Takeshi Kojima et al. (2022). Implications\nAlthough the Let\u0026rsquo;s think step by step trick works well on math problems, it\u0026rsquo;s not effective on all tasks. The authors found that it was most helpful for multi-step arithmetic problems, symbolic reasoning problems, strategy problems, and other reasoning problems. It didn\u0026rsquo;t help with simple math problems or common sense questions, and presumably wouldn\u0026rsquo;t help with many other non-reasoning tasks either.\nzero-shot reasoning example Source: Large Language Models are Zero-Shot Reasoners by Takeshi Kojima et al. (2022).\nTo learn more, read the full paper.\nIf you apply this technique to your own tasks, don\u0026rsquo;t be afraid to experiment with customizing the instruction. Let\u0026rsquo;s think step by step is rather generic, so you may find better performance with instructions that hew to a stricter format customized to your use case. For example, you can try more structured variants like First, think step by step about why X might be true. Second, think step by step about why Y might be true. Third, think step by step about whether X or Y makes more sense.. And you can even give the model an example format to help keep it on track, e.g.:\nUsing the IRS guidance below, answer the following questions using this format: (1) For each criterion, determine whether it is met by the vehicle purchase\n{Criterion} Let\u0026rsquo;s think step by step. {explanation} {yes or no, or if the question does not apply then N/A}. (2) After considering each criterion in turn, phrase the final answer as \u0026ldquo;Because of {reasons}, the answer is likely {yes or no}.\u0026rdquo; IRS guidance: \u0026quot;\u0026quot;\u0026quot; You may be eligible for a federal tax credit under Section 30D if you purchased a car or truck that meets the following criteria:\nDoes the vehicle have at least four wheels? Does the vehicle weigh less than 14,000 pounds? Does the vehicle draw energy from a battery with at least 4 kilowatt hours that may be recharged from an external source? Was the vehicle purchased in a year before 2022? If so, has the manufacturer sold less than 200,000 qualifying vehicles? (Tesla and GM have sold more than 200,000 qualifying vehicles.) Was the vehicle purchased in a year after 2022? If so, is the vehicle present in the following list of North American-assembled vehicles? (The only electric vehicles assembled in North America are the Audi Q5, BMW 330e, BMW X5, Chevrolet Bolt EUV, Chevrolet Bolt EV, Chrysler Pacifica PHEV, Ford Escape PHEV, Ford F Series, Ford Mustang MACH E, Ford Transit Van, GMC Hummer Pickup, GMC Hummer SUV, Jeep Grand Cherokee PHEV, Jeep Wrangler PHEV, Lincoln Aviator PHEV, Lincoln Corsair Plug-in, Lucid Air, Nissan Leaf, Rivian EDV, Rivian R1S, Rivian R1T, Tesla Model 3, Tesla Model S, Tesla Model X, Tesla Model Y, Volvo S60, BMW 330e, Bolt EV, Cadillac Lyriq, Mercedes EQS SUV, and Nissan Leaf.) \u0026quot;\u0026quot;\u0026quot; Question: Can I claim a federal tax credit for my Toyota Prius Prime bought in 2021?\nSolution:\n(1) For each criterion, determine whether it is met by the vehicle purchase\nDoes the vehicle have at least four wheels? Let\u0026rsquo;s think step by step. The Toyota Prius Prime has four wheels, so the answer is yes.\nDoes the vehicle weigh less than 14,000 pounds? Let\u0026rsquo;s think step by step. The Toyota Prius Prime weighs less than 14,000 pounds, so the answer is yes. Does the vehicle draw energy from a battery with at least 4 kilowatt hours that may be recharged from an external source? Let\u0026rsquo;s think step by step. The Toyota Prius Prime has a battery with at least 4 kilowatt hours that may be recharged from an external source, so the answer is yes. Was the vehicle purchased in a year before 2022? Let\u0026rsquo;s think step by step. The Toyota Prius Prime was purchased in 2021, which is before 2022, so the answer is yes. Was the vehicle purchased in a year after 2022? N/A If so, is the vehicle present in the following list of North American-assembled vehicles? N/A (2) After considering each criterion in turn, phrase the final answer as \u0026ldquo;Because of {reasons}, the answer is likely {yes or no}.\u0026rdquo;\nBecause the Toyota Prius Prime meets all of the criteria for a federal tax credit, the answer is likely yes.\nFew-shot examples Method\nPrompting the model to reason out its answers can be done in many ways. One way is to demonstrate with a few examples (\u0026lsquo;few-shot\u0026rsquo;), as studied by Jason Wei and Denny Zhou et al. from Google. Here\u0026rsquo;s an example few-shot chain-of-thought prompt:\nchain of thought example Source: Chain of Thought Prompting Elicits Reasoning in Large Language Models Jason Wei and Denny Zhou et al. (2022)\nMore demonstrations of reasoning chains written by human labelers:\nchain of thought example Source: Chain of Thought Prompting Elicits Reasoning in Large Language Models Jason Wei and Denny Zhou et al. (2022)\n(Note that it has been called into question whether pears actually float) Results\nTesting on grade school math problems, the authors found that chain of thought prompting tripled the solve rate, from 18% to 57%.\nchain of thought example Source: Chain of Thought Prompting Elicits Reasoning in Large Language Models Jason Wei and Denny Zhou et al. (2022)\nIn addition to math problems, chain of thought prompting also lifted performance on questions related to sports understanding, coin flip tracking, and last letter concatenation. In most cases, not many examples were need to saturate the performance gains (less than 8 or so).\nchain of thought example Source: Chain of Thought Prompting Elicits Reasoning in Large Language Models Jason Wei and Denny Zhou et al. (2022)\nTo learn more, read the full paper. Implications\nOne advantage of the few-shot example-based approach relative to the Let\u0026rsquo;s think step by step technique is that you can more easily specify the format, length, and style of reasoning that you want the model to perform before landing on its final answer. This can be particularly helpful in cases where the model isn\u0026rsquo;t initially reasoning in the right way or depth. Fine-tuned Method\nIn general, to eke out maximum performance on a task, you\u0026rsquo;ll need to fine-tune a custom model. However, fine-tuning a model using explanations may take thousands of example explanations, which are costly to write.\nIn 2022, Eric Zelikman and Yuhuai Wu et al. published a clever procedure for using a few-shot prompt to generate a dataset of explanations that could be used to fine-tune a model. The idea is to use a few-shot prompt to generate candidate explanations, and only keep the explanations that produce the correct answer. Then, to get additional explanations for some of the incorrect answers, retry the few-shot prompt but with correct answers given as part of the question. The authors called their procedure STaR (Self-taught Reasoner):\nSTaR procedure Source: STaR: Bootstrapping Reasoning With Reasoning by Eric Zelikman and Yujuai Wu et al. (2022)\nWith this technique, you can combine the benefits of fine-tuning with the benefits of chain-of-thought prompting without needing to write thousands of example explanations. Results\nWhen the authors applied this technique to a Common Sense Q\u0026amp;A dataset, they found that STaR outperformed both chain-of-thought prompting alone (73% \u0026gt; 37%) and fine-tuning alone (73% \u0026gt; 60%):\nSTaR results Source: STaR: Bootstrapping Reasoning With Reasoning by Eric Zelikman and Yujuai Wu et al. (2022)\nTo learn more, read the full paper. Implications\nUsing a few-shot prompt to extend or modify a fine-tuning dataset is an idea that can be generalized beyond explanation writing. For example, if you have large quantities of unstructured text that you want to train on, you may find opportunities to use a prompt to extract a structured dataset from your unstructured text, and then fine-tune a custom model on that structured dataset. Extensions to chain-of-thought prompting\nA number of extensions of chain-of-thought prompting have been published as well. Selection-inference prompting Method\nPublished by Antonia Creswell et al., one extension of the chain-of-thought technique is to split the single prompt for generating explanations and answers into smaller parts. First, a prompt selects a relevant subset of facts from the text (\u0026lsquo;selection prompt\u0026rsquo;). Then, a second prompt infers a conclusion from the selected facts (\u0026lsquo;inference prompt\u0026rsquo;). These prompts are then alternated in a loop to generate multiple steps of reasoning and eventually land on a final answer. The authors illustrate the idea in the following figure:\nSelection-inference prompting Source: Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning by Antonia Creswell et al. (2022) Results\nWhen applied to a 7B-parameter model, the authors found that selection-inference prompting substantially improved performance relative to chain-of-thought prompting on the bAbi and Proof Writer benchmark tasks (both of which require longer sequences of reasoning steps). The best performance they achieved combined both selection-inference prompting with fine-tuning.\nSelection-inference prompting Source: Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning by Antonia Creswell et al. (2022) Implications\nAlthough the gains on these benchmarks were large, these benchmarks were specifically chosen because they required longer sequences of reasoning. On problems that don\u0026rsquo;t require reasoning with many steps, the gains are likely smaller.\nThe results highlight a couple of general lessons for working with large language models. One, splitting up complex tasks into smaller tasks is a great way to improve reliability and performance; the more atomic the task, the less room there is for the model to err. Two, getting maximum performance often means combining fine-tuning with whatever approach you\u0026rsquo;ve chosen.\nTo learn more, read the full paper. Faithful reasoning architecture\nA few months after publishing the selection-inference prompting technique, the authors extended the technique in a follow-up paper, with ideas for:\nfiguring out when the selection-inference cycle should stop or continue adding a value function to help search over multiple reasoning paths reducing hallucination of fake facts by fine-tuning a model to reason about sentence labels (e.g., sen1) rather than writing out the sentences themselves Method\nIn the original selection-inference technique, specialized \u0026lsquo;selection\u0026rsquo; and \u0026lsquo;inference\u0026rsquo; prompts are alternated to select facts and make inferences from those facts, combining to generate a sequence of reasoning steps.\nThe authors extend this technique with two additional components.\nFirst, the authors add a \u0026lsquo;halter\u0026rsquo; model that, after each inference step, is asked whether the inferences thus far are sufficient to answer the question. If yes, then the model generates a final answer.\nThe halter models brings a couple of advantages:\nit can tell the selection-inference process to stop or keep going, as necessary. if the process never halts, you'll get no answer, which is often preferable to a hallucinated guess Faithful reasoning Source: Faithful Reasoning Using Large Language Models by Antonia Creswell et al. (2022)\nFaithful reasoning Source: Faithful Reasoning Using Large Language Models by Antonia Creswell et al. (2022)\nSecond, the authors add a value function, which is used to assess the quality of reasoning steps and search over multiple reasoning trajectories. This echoes a common theme for increasing reliability; instead of generating a single answer from the model, generate a set of answers and then use some type of value function / discriminator / verifier model to pick the best one.\nFaithful reasoning Source: Faithful Reasoning Using Large Language Models by Antonia Creswell et al. (2022)\nIn addition to these two extensions, the authors also use a trick to reduce hallucination of fake facts. Rather than asking the model to write out factual sentences, they fine-tune a model to work with sentence labels (e.g., sen1) instead. This helps prevent the model from hallucinating fake facts not mentioned in the prompt context.\nFaithful reasoning Source: Faithful Reasoning Using Large Language Models by Antonia Creswell et al. (2022) Results\nThe authors evaluated their technique on two benchmarks: the ProofWriter task (not shown) and EntailmentBankQA (shown). The technique increased accuracy substantially, especially on harder reasoning problems.\nFaithful reasoning Source: Faithful Reasoning Using Large Language Models by Antonia Creswell et al. (2022)](https://arxiv.org/abs/2208.14271 )\nIn addition, their sentence label manipulation trick essentially eliminated hallucination!\nFaithful reasoning Source: Faithful Reasoning Using Large Language Models by Antonia Creswell et al. (2022)](https://arxiv.org/abs/2208.14271 ) Implications\nThis paper illustrates a number of helpful lessons for improving the reliability of large language models:\nSplit complex tasks into smaller, more reliable subtasks Generate your answer in a step-by-step fashion, evaluating it along the way Generate many possible answers and use another model or function to pick the ones that look best Reduce hallucination by constraining what the model can say (e.g., by using sentence labels instead of sentences) Maximize performance of models by fine-tuning them on specialized tasks To learn more, read the full paper. Least-to-most prompting\nIn addition to doing poorly on long reasoning chains (where selection-inference shines), chain-of-thought prompting can especially struggle when the examples are short but the task is long. Method\nLeast-to-most prompting is another technique that splits up reasoning tasks into smaller, more reliable subtasks. The idea is to elicit a subtask from the model by prompting it with something like To solve {question}, we need to first solve: \u0026ldquo;. Then, with that subtask in hand, the model can generate a solution. The solution is appended to the original question and the process is repeated until a final answer is produced.\nLeast-to-most prompting Source: Least-to-most Prompting Enables Complex Reasoning in Large Language Models by Denny Zhou et al. (2022) Results\nWhen applied to benchmarks involving long reasoning chains using code-davinci-002 (which is optimized for code but can still understand text), the authors measured gains as large as 16% -\u0026gt; 99.7%!\nLeast-to-most prompting results on last-letter-concatenation task Least-to-most prompting results on SCAN Least-to-most prompting results on DROP numerical reasoning Source: Least-to-most Prompting Enables Complex Reasoning in Large Language Models by Denny Zhou et al. (2022) Implications\nAlthough the above gains from least-to-most prompting are impressive, they are measured on a very narrow set of tasks that require long reasoning chains.\nStill, they illustrate a common theme: increase reliability by (a) breaking complex tasks into smaller subtasks and (b) giving the model more time and space to work out the answer.\nTo learn more, read the full paper. Related ideas Maieutic prompting Method\nIn contrast to the previous techniques, which try to maximize the likelihood of correct answers, another approach is to use GPT-3 to generate a tree of possible explanations (both correct and incorrect), and then analyze their relationships to guess at which set is correct. This technique was coined maieutic prompting by Jaehun Jung et al. in May 2022 (maieutic means relating to the Socratic method of asking questions to elicit ideas).\nThe method is complicated, and works as follows:\nFirst, build a maieutic tree, where each node is a statement that could be true or false: Start with a multiple-choice question or true/false statement (e.g. War cannot have a tie) For each possible answer to the question, use the model to generate a corresponding explanation (with a prompt like War cannot have a tie? True, because) Then, prompt the model with the question and the generated explanation, and ask it to produce the answer. If reversing the explanation (with a prefix like It is wrong to say that {explanation}) reverses the answer, then the explanation is considered 'logically integral.' If an explanation is not logically integral, then repeat the above process recursively, with each explanation turned into a True or False question, and generate more explanations for each new question. After all of the recursive explaining is done, you end up with a tree of explanations, where each leaf on the tree has the property that reversing the explanation reverses the model's answer. Second, convert the tree into a graph of relations: For each node in the tree, calculate the model's relative belief in each node (inferred from the probability of getting an answer of True to given an explanation) For each pair of nodes in the tree, use the model to identify whether they are entailed (implied) or contradicted Third, find the most consistent set of beliefs and take those to be true: Specifically, using the strength of belief in each node and the logical relationships between them, formulate the problem as a weighted maximum satisfiability problem (MAX-SAT) Use a solver to the find the most self-consistent set of beliefs, and take those as true Maieutic prompting Maieutic prompting Source: Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations by Jaehun Jung et al. (2022) Results\nMaieutic prompting results Source: Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations by Jaehun Jung et al. (2022) Implications\nBeyond the complexity, one limitation of this method is that it appears to only apply to questions that can be posed as multiple-choice.\nTo learn more, read the full paper. Extensions Self-consistency Method\nFor tasks with a discrete set of answers, one simple way to improve reliability is to sample multiple explanations \u0026amp; answers from the model (using a positive temperature) and then pick the final answer that appears most often.\nSelf-consistency method Source: Self-Consistency Improves Chain of Thought Reasoning in Language Models by Xuezhi Wang et al. (2022) Results\nThis technique lifted accuracies by anywhere from 1 to 24 percentage points on a suite of math and reasoning benchmarks. (Plotted below are results from Google\u0026rsquo;s LaMDA model; using Google\u0026rsquo;s larger PaLM model, the baselines were higher but the gains were a bit smaller.)\nSelf-consistency results Source: Self-Consistency Improves Chain of Thought Reasoning in Language Models by Xuezhi Wang et al. (2022) Implications\nAlthough this technique is simple to implement, it can be costly. Generating a set of 10 answers will increase your costs by 10x.\nAlso, as with many of these techniques, it applies only to tasks with a limited set of answers. For open-ended tasks where each answer is unique (such as writing a poem), it\u0026rsquo;s not obvious what it would mean to pick the most common answer.\nLastly, this technique ought to be most beneficial when there are multiple paths or phrasings to reach an answer; if there\u0026rsquo;s only one path, then the technique may not help at all. An extreme example: If the task was to generate a single token answer, then taking the most common token from 100 generations would be no different than taking the token with the highest logprobs (which you can get with a single generation at temperature=0). Verifiers\nAnother key technique for improving task performance is to train a verifier or discriminator model to evaluate the outputs of the main generative model. If the discriminator rejects the output, then you can resample the generative model until you get an acceptable output. In many cases, it\u0026rsquo;s easier to judge an answer than it is to create an answer, which helps explain the power of this method. Method\nIn 2021, OpenAI researchers applied this technique to grade school math problems, using the following procedure:\nFirst, they fine-tuned a model on questions and solutions For each problem in the training set, they generated 100 solutions Each of those 100 solutions was automatically labeled as either correct or incorrect, based on whether the final answer was correct Using those solutions, with some labeled correct and some labeled incorrect, they fine-tuned a verifier model to classify whether a question and candidate solution was correct or incorrect Finally, at test time, the generative model creates 100 solutions to each problem, and the one with the highest score according to the verifier model is picked as the final answer Verifier method Source: Training Verifiers to Solve Math Word Problems by Karl Cobbe et al. (2021) Results\nWith a 175B GPT-3 model and 8,000 training examples, this technique substantially lifted grade school math accuracy from ~33% to ~55%.\nVerifier results Source: Training Verifiers to Solve Math Word Problems by Karl Cobbe et al. (2021) Implications\nSimilar to the self-consistency technique, this method can get expensive, as generating, say, 100 solutions per task will increase your costs by roughly ~100x. Theories of reliability\nAlthough the techniques above vary in their approach, they all share the goal of improving reliability on complex tasks. Mainly they do this by:\ndecomposing unreliable operations into smaller, more reliable operations (e.g., selection-inference prompting) using multiple steps or multiple relationships to make the system's reliability greater than any individual component (e.g., maieutic prompting) Probabilistic graphical models\nThis paradigm of trying to build a reliable system out of less reliable components is reminiscent of probabilistic programming, and many of the analysis techniques of that field can be applied to this one.\nIn the paper Language Model Cascades, David Dohan et al. interpret the above techniques in the paradigm of probabilistic graphical models: Chain of thought prompting\ngraphical model of chain of thought prompting Source: Language Model Cascades by David Dohan et al. (2022) Fine-tuned chain of thought prompting / Self-taught reasoner\ngraphical model of fine-tuned chain of thought prompting Source: Language Model Cascades by David Dohan et al. (2022) Selection-inference prompting\ngraphical model of selection-inference prompting Source: Language Model Cascades by David Dohan et al. (2022) Verifiers\ngraphical model of verifiers Source: Language Model Cascades by David Dohan et al. (2022) Implications\nAlthough formulating these techniques as probabilistic graphical models may not be immediately useful for solving any particular problem, the framework may be helpful in selecting, combining, and discovering new techniques. Closing thoughts\nResearch into large language models is very active and evolving rapidly. Not only do researchers continue to improve the models, they also continue to improve our understanding of how to best employ the models. To underscore the pace of these developments, note that all of the papers shared above were published within the past 12 months (as I write in Sep 2022).\nIn the future, expect better models and better techniques to be published. Even if the specific techniques here are eclipsed by future best practices, the general principles behind them will likely remain a key part of any expert user\u0026rsquo;s toolkit. Bibliography Lesson Paper Date Break complex tasks into simpler subtasks (and consider exposing the intermediate outputs to users) AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts 2021 Oct You can improve output by generating many candidates, and then picking the one that looks best Training Verifiers to Solve Math Word Problems 2021 Oct On reasoning tasks, models do better when they reason step-by-step before answering Chain of Thought Prompting Elicits Reasoning in Large Language Models 2022 Jan You can improve step-by-step reasoning by generating many explanation-answer outputs, and picking the most popular answer Self-Consistency Improves Chain of Thought Reasoning in Language Models 2022 Mar If you want to fine-tune a step-by-step reasoner, you can do it with multiple-choice question \u0026amp; answer data alone STaR: Bootstrapping Reasoning With Reasoning 2022 Mar The step-by-step reasoning method works great even with zero examples Large Language Models are Zero-Shot Reasoners 2022 May You can do better than step-by-step reasoning by alternating a ‘selection’ prompt and an ‘inference’ prompt Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning 2022 May On long reasoning problems, you can improve step-by-step reasoning by splitting the problem into pieces to solve incrementally Least-to-most Prompting Enables Complex Reasoning in Large Language Models 2022 May You can have the model analyze both good and bogus explanations to figure out which set of explanations are most consistent Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations 2022 May You can think about these techniques in terms of probabilistic programming, where systems comprise unreliable components Language Model Cascades 2022 Jul You can eliminate hallucination with sentence label manipulation, and you can reduce wrong answers with a \u0026lsquo;halter\u0026rsquo; prompt Faithful Reasoning Using Large Language Models 2022 Aug openai-cookbook/techniques_to_improve_reliability.md at main · ope\n"
    }
    
    , 
    {
        "url": "/tools/gpt/",
        "title": "GPT",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/hvor-mange-eksempler-er-nok-til-at-den-nye-insert-model-fra-openai-forstar-hensigten/",
        "title": "Hvor mange eksempler er nok til at den nye insert model fra OpenAI forstår hensigten",
        "content": "måge: gammeldansk maghæ, afledt af en lydefterlignende rod\nkriger: fra tysk Krieger, afledt af et ældre verbum krige \u0026lsquo;føre krig\u0026rsquo;\ngladiator: [insert]\ngiver:\nfra latin gladiator, afledt af verbet gladius \u0026lsquo;sværd\u0026rsquo;\nMen hov, gladius er jo ikke et verbum.\nmåge: gammeldansk maghæ, afledt af en lydefterlignende rod\nkriger: fra tysk Krieger, afledt af et ældre verbum krige \u0026lsquo;føre krig\u0026rsquo;\nbil: kendt fra 1902, afkortning af automobil\ngladiator: [insert]\nfra latin gladiator, afledt af gladius \u0026lsquo;sværd\u0026rsquo;\nMen hov, bytter vi om på rækkefølgen af eksemplerne, så laver insert modellen igen en fejl:\nkriger: fra tysk Krieger, afledt af et ældre verbum krige \u0026lsquo;føre krig\u0026rsquo;\nmåge: gammeldansk maghæ, afledt af en lydefterlignende rod\nbil: kendt fra 1902, afkortning af automobil\ngladiator: [insert]\nlatinsk gladiator, afledt af verbum gladius \u0026lsquo;sværd\u0026rsquo;\nkriger: fra tysk Krieger, afledt af et ældre verbum krige \u0026lsquo;føre krig\u0026rsquo;\nhus: norrønt hús, tysk Haus af uvis oprindelse\nmåge: gammeldansk maghæ, afledt af en lydefterlignende rod\nbil: kendt fra 1902, afkortning af automobil\ngladiator: [insert]\nlat. gladiator, afledt af gladius \u0026lsquo;sværd\u0026rsquo;\nOg i ChatGPT (gpt-3.5-turbo)\nlatin gladiator, afledt af gladius \u0026lsquo;sværd\u0026rsquo;, da gladiatorer var udstyret med sværd i kampene i antikkens Rom\n"
    }
    
    , 
    {
        "url": "/emner/nlp/",
        "title": "nlp",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/prompt-engineering/show-and-tell/",
        "title": "Show and tell",
        "content": "I journalistik siger man ofte, show it, don\u0026rsquo;t tell it.\nNår det gælder\n"
    }
    
    , 
    {
        "url": "/erfaring/prompt-engineering/system/",
        "title": "System",
        "content": "Traditionally, GPT models consumed unstructured text. ChatGPT models instead expect a structured format, called Chat Markup Language (ChatML for short). ChatML documents consists of a sequence of messages. Each message contains a header (which today consists of who said it, but in the future will contain other metadata) and contents (which today is a text payload, but in the future will contain other datatypes).\nopenai-python/chatml.md at main · openai/openai-python · GitHub ¶ Note: you need to be using OpenAI Python v0.27.0 for the code below to work import openai\nopenai.ChatCompletion.create( model=\u0026ldquo;gpt-3.5-turbo\u0026rdquo;, messages=[ {\u0026ldquo;role\u0026rdquo;: \u0026ldquo;system\u0026rdquo;, \u0026ldquo;content\u0026rdquo;: \u0026ldquo;You are a helpful assistant.\u0026rdquo;}, {\u0026ldquo;role\u0026rdquo;: \u0026ldquo;user\u0026rdquo;, \u0026ldquo;content\u0026rdquo;: \u0026ldquo;Who won the world series in 2020?\u0026rdquo;}, {\u0026ldquo;role\u0026rdquo;: \u0026ldquo;assistant\u0026rdquo;, \u0026ldquo;content\u0026rdquo;: \u0026ldquo;The Los Angeles Dodgers won the World Series in 2020.\u0026rdquo;}, {\u0026ldquo;role\u0026rdquo;: \u0026ldquo;user\u0026rdquo;, \u0026ldquo;content\u0026rdquo;: \u0026ldquo;Where was it played?\u0026rdquo;} ] ) Ustruktureret og ikke-formaliseret.\nMen i retning af noget mere struktureret, så spiller det også bedre sammen med mere traditionelt it-værktøj\nSystem message\nSystem role\nPersona\nChatML\nBemærk at ChatGPT glider væk fra systembeskeden jo længere chatten bliver og jo flere beskeder som følger efter den indledende systembesked.\ngpt-3.5-turbo-0301 does not always pay strong attention to system messages. Future models will be trained to pay stronger attention to system messages. Chat completion - OpenAI API og In general, gpt-3.5-turbo-0301 does not pay strong attention to the system message, and therefore important instructions are often better placed in a user message.\nMake your instruction more explicit Specify the format you want the answer in Ask the model to think step by step or debate pros and cons before settling on an answer The user messages help instruct the assistant. They can be generated by the end users of an application, or set by a developer as an instruction.\nThe assistant messages help store prior responses. They can also be written by a developer to help give examples of desired behavior. Derfor skal man nogle gange minde den om det i et user besked.\n"
    }
    
    , 
    {
        "url": "/emner/l%C3%A6ring/",
        "title": "læring",
        "content": ""
    }
    
    , 
    {
        "url": "/cases/tutoren/",
        "title": "tutoren",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/aegte-individualiseret-undervisning-til-alle-med-kunstig-intelligens/",
        "title": "Ægte individualiseret undervisning til alle med kunstig intelligens",
        "content": "For efterhånden en del år siden lavede jeg sammen med en kammerat hjemmesiden Tutoren .\nIdeen var at formidle kontakt mellem \u0026ldquo;tutorer\u0026rdquo;, som havde kompetencer inden for et bestemt område i kombination med evnen til at lære fra sig, og \u0026ldquo;elever\u0026rdquo; med et ønske om at få hjælp til at udvikle sig fagligt på selvsamme område.\nHovedsagelig kom det i praksis til at dreje sig om det vi på dansk begyndte at kalde lektiehjælp.\nMen formen var en-til-en undervisning.\nMed kunstig intelligens er det muligt at stille en-til-en \u0026ldquo;tutoring\u0026rdquo; til rådighed for alle mennesker.\nPå den måde vil hver enkelt \u0026ldquo;elev\u0026rdquo; - og i virkeligheden hver enkelt person i mange sammenhænge - kunne få en form for undervisning som tager udgangspunkt i de helt konkrete behov som den elev har og som tager afsæt i elevens nuværende niveau og bygger videre derfra.\nEr der noget som store sprogmodeller mestrer, så er det evnen til at tage et udgangspunkt og bygge videre på det.\nGrebet rigtigt an, vil kunstig intelligens kunne supplere traditionel klassebaseret læring. Enhver vil få sin egen tutor.\nDet er svært at forestille sig at det ikke vil blive på den måde i fremtiden.\nDerfor er det nok værd at gøre sig lidt tanker om de eventuelle risikomomenter ved den udvikling også.\n"
    }
    
    , 
    {
        "url": "/erfaring/en-simpel-redaktionel-arbejdsgang-med-gpt/",
        "title": "En simpel redaktionel arbejdsgang med GPT",
        "content": "En redaktionel arbejdsgang er tidskrævende og besværlig.\nDet er den fordi indholdet skifter hænder så mange gange undervejs.\nOg det gælder uanset om man sender tekstfiler rundt mellem forskellige medarbejdere på e-mail, eller om man bruger et mere moderne og integreret værktøj til projekthåndtering og indholdsstyring.\nFra en ide formuleres til den færdige tekst kan præsenteres for offentligheden, er der ofte mange forskellige øjne som indholdet skal forbi.\n¶ Kan en redaktionel arbejdsgang automatiseres? De forskellige personer som er involveret i en redaktionel arbejdsgang, har hver især en ret specialiseret og veldefineret rolle. I bedste fald bibringer hver person i denne kæde indholdet noget betydningsfuldt.\nMålet er et troværdigt produkt som er engagerende nok til at læserne vil bruge deres sparsomme tid på det.\nNår nu både rollerne undervejs i processen er veldefinerede, og der også kan opstilles en klar målsætning, så brude processen kunne opstilles programmatisk.\nJeg har arbejdet med at automatisere den redaktionelle proces. Her er resultatet af det arbejde i en lettere simplificeret udgave:\n\u0026#39;Please write 7 paragraphs about classic cars from 1950 to 1960\u0026#39; | gpt --endpoint=completions --role=skribent | gpt --endpoint=edits --role=ombryder | gpt --endpoint=edits --role=redaktør | trans --brief en:da | gpt --endpoint=edits --role=korrekturlæser | slb | nvim - linje er ideen til teksten \u0026ndash; en artikel om veteranbiler fra 1950\u0026rsquo;erne. Ideen sendes med |-symbolet videre til\nlinje, der er OpenAI\u0026rsquo;s completions endpoint i deres GPT-API. Samtidig med at jeg fodrer API\u0026rsquo;et med selve ideen, så fortæller jeg også lidt om hvordan GPT skal forholde sig til ideen. Det gør jeg ved at give den en rolle som er defineret som følger:\n{ \u0026#34;name\u0026#34;: \u0026#34;skribent\u0026#34;, \u0026#34;expecting\u0026#34;: \u0026#34;Lucid writing\u0026#34;, \u0026#34;variables\u0026#34;: null, \u0026#34;role\u0026#34;: \u0026#34;You are a copy writer. Based on my input you must ...\u0026#34; } Så spytter GPT en artikel ud som er syv afsnit lang.\nDen artikel piper jeg så igen med | videre til et andet endpoint hos OpenAI, nemlig deres edits-endpoint \u0026ndash; det sker her på linje 3.\nSamtidig definerer jeg en ny rolle som jeg kalder \u0026ldquo;ombryder\u0026rdquo;. Jeg vil ikke afsløre instruktionen for den rolle, men \u0026ldquo;ombryder\u0026rdquo;-rollen er nødvendig fordi GPT i sig selv skriver lidt monotont og ikke er tilstrækkeligt opmærksom på at skabe læserindgange i teksten, så den får lige lov til at arbejde lidt med sin egen tekst ud fra nogle ideer om formattering og ombrydning som jeg giver den.\nPå 4. linje får teksten er mere traditionel redigering, blandt andet ud fra nogle betragtninger om at fjerne overflødigt fedt og rydde ud i gentagelserne som GPT er lidt slem til at lave.\nLinje 5 er bare en oversætter. Det er bedst at arbejde på engelsk så længe som muligt i arbejdsgangen, af flere forskellige årsager som er veldokumenterede, men som jeg ikke vil kede læseren med her.\nSå beder jeg på sjette linje GPT om at læse korrektur på den danske udgave af teksten.\nLinje 7 hedder bare slb \u0026ndash; det er min egen funktion som splitter sætninger ud på linjer som forklaret nærmere i serien: Skriv som en poet - ikke en bot Og endelig på 8. linje sender jeg den færdige tekst videre til mit eget redigeringsprogram, så jeg personligt kan gå den efter i sømmene:\nIdeen er min, og det endelige ansvar er også mit.\nMen de forskellige redaktionelle roller undervejs i tilblivningsfasen er automatiserede. Her er menneskerne skiftet ud med GPT.\nHov!\nMangler der ikke en væsentlig rolle \u0026ndash; spørger den vågne læser nu forhåbentligt.\nJo, researcheren.\nJeg har her i det her simple eksempel udeladt researcheren.\nResearch er ikke GPT\u0026rsquo;s stærke side. Så skal den kobles sammen med andre værktøjer.\nJeg har i den forbindelse leget en smule med langchain \u0026ndash; og jo, researcheren kan også automatiseres med lidt mere teknisk snilde og tid end jeg for nærværende har på hånden.\n¶ Kan resultatet måle sig med en rigtig redaktion? Mine eksperimenter har været forholdsvist vellykkede \u0026ndash; i hvert fald så længe jeg kun har givet simple og relativt kortfattede opgaver til GPT.\nBliver tingene lidt mere komplekse og teksterne noget længere, så er GPT stadig ikke sammenlignelig med en rigtig redaktion.\nPå nogle punkter vil GPT heller ikke blive sammenlignelig med en redaktion bestående af mennesker.\nPå den anden side er der enormt meget skrivearbejde som på tilfredsstillende vis vil kunne automatiseres, også fordi prisen er en faktor af betydning. Og GPT er både hurtig og billig sammenlignet med mennesker.\nI fremtiden vil visse publikationer sikkert markedsføre sig på at være menneskeskabte, ligesom visse aviser stolt peger på papirudgaven i dag, selvom meget få læser den.\nDet har været interessant at undersøge mulighederne i GPT med henblik på at automatisere det redaktionelle workflow. Og de opnåede resultater er både fascinerende og lettere skræmmende.\nJeg er også selv blevet skarpere på præcist hvad en god redaktionel arbejdsgang består i. Når man skal formalisere sin viden, bliver man nødt til at skære ind til benet.\n"
    }
    
    , 
    {
        "url": "/erfaring/sprogmodeller/hvad-er-store-sprogmodeller/",
        "title": "Hvad er store sprogmodeller",
        "content": "Store sprogmodeller er matematiske funktioner der forholder tekst til tekst.\nDet er selvfølgelig en meget generel og abstrakt definition.\nDet følgende tager udgangspunkt i den nu mest udbredte og succesfulde type af store sprogmodeller, nemlig\nMed en inputstreng af tekst forudsiger en stor sprogmodel den tekst, der skal komme næste gang.\nMagien ved store sprogmodeller er, at ved at blive trænet i at minimere denne forudsigelsesfejl over store mængder tekst, ender modellerne med at lære begreber, der er nyttige til disse forudsigelser. For eksempel lærer de:\nhvordan staves hvordan grammatik fungerer hvordan man parafraserer hvordan man besvarer spørgsmål hvordan man fører en samtale hvordan man skriver på mange sprog hvordan man koder etc.\nIngen af disse egenskaber er eksplicit programmeret ind - de opstår alle som et resultat af træning.\nGPT-3 driver hundredvis af softwareprodukter, herunder produktivitetsapps, uddannelsesapps, spil og mere.\n"
    }
    
    , 
    {
        "url": "/erfaring/sprogmodeller/hvad-kan-store-sprogmodeller/",
        "title": "Hvad kan store sprogmodeller",
        "content": "Basalt set kan store sprogmodeller gætte ord ud fra en sammenhæng som brugeren angiver.\nGiver brugeren en stor sprogmodel følgende input:\nOm sommeren når solen skinner, elsker jeg at drikke en kold\nsvarer sprogmodellen iced tea.\nSprogmodellen afsøger så at sige sit corpus, al den tekst som sprogmodellen er blevet fodret med under træningen, for at finde det ord som har den største kobling til det input som brugeren har angivet.\nFordi det mest naturlige svar nogle gange kommer i konflikt med nogle etiske retningslinjer, giver sprogmodellen dog reelt ofte et svar som kommer længere ned over listen - se for eksempel dette eksempel: ChatGPT har en beskidt tankegang - her er beviset .\nDen metode hvor sprogmodellen færdiggør brugerens input, kaldes af OpenAI for \u0026ldquo;completions\u0026rdquo;.\nDer findes også andre tilgange, men basalt set bygger de alle på de koblinger mellem ord og sammenhænge som sprogmodellen har \u0026ldquo;lært\u0026rdquo; da den blev trænet på enorme mængder af tekst. Magien ved store sprogmodeller er, at ved at blive trænet i at minimere denne forudsigelsesfejl over store mængder tekst, ender modellerne med at lære begreber, der er nyttige til disse forudsigelser. For eksempel lærer de:\nhvordan staves hvordan grammatik fungerer hvordan man parafraserer hvordan man besvarer spørgsmål hvordan man fører en samtale hvordan man skriver på mange sprog hvordan man koder etc.\nIngen af disse egenskaber er eksplicit programmeret ind - de opstår alle som et resultat af træning. Emergent abilities On a number of natural language benchmarks involving tasks such as question answering, models perform no better than random chance until they reach a certain scale (in this case, measured by training computation), at which point their performance sharply increases. These are examples of emergent abilities.\nWhile it is generally the case that performance of large models on various tasks can be extrapolated based on the performance of similar smaller models, sometimes large models undergo a \u0026ldquo;discontinuous phase shift\u0026rdquo; where the model suddenly acquires substantial abilities not seen in smaller models. These are known as \u0026ldquo;emergent abilities\u0026rdquo;, and have been the subject of substantial study. Researchers note that such abilities \u0026ldquo;cannot be predicted simply by extrapolating the performance of smaller models\u0026rdquo;.[4] These abilities are discovered rather than programmed-in or designed, in some cases only after the LLM has been publicly deployed.[5] Hundreds of emergent abilities have been described. Examples include multi-step arithmetic, taking college-level exams, identifying the intended meaning of a word,[4] chain-of-thought prompting,[4] decoding the International Phonetic Alphabet, unscrambling a word’s letters, identifying offensive content in paragraphs of Hinglish (a combination of Hindi and English), and generating a similar English equivalent of Kiswahili proverbs.[10] Hallucination\nGenerative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed \u0026ldquo;hallucination\u0026rdquo;.[11]\n"
    }
    
    , 
    {
        "url": "/erfaring/sprogmodeller/hvordan-fungerer-store-sprogmodeller/",
        "title": "Hvordan fungerer store sprogmodeller",
        "content": "Store sprogmodeller er matematiske funktioner der forholder tekst til tekst.\nDet er selvfølgelig en meget generel og abstrakt definition.\nDet følgende tager udgangspunkt i den nu mest udbredte og succesfulde type af store sprogmodeller, nemlig\nMed en inputstreng af tekst forudsiger en stor sprogmodel den tekst, der skal komme næste gang.\nMagien ved store sprogmodeller er, at ved at blive trænet i at minimere denne forudsigelsesfejl over store mængder tekst, ender modellerne med at lære begreber, der er nyttige til disse forudsigelser. For eksempel lærer de:\nhvordan staves hvordan grammatik fungerer hvordan man parafraserer hvordan man besvarer spørgsmål hvordan man fører en samtale hvordan man skriver på mange sprog hvordan man koder etc.\nIngen af disse egenskaber er eksplicit programmeret ind - de opstår alle som et resultat af træning.\nGPT-3 driver hundredvis af softwareprodukter, herunder produktivitetsapps, uddannelsesapps, spil og mere.\n"
    }
    
    , 
    {
        "url": "/tools/autogpt/",
        "title": "AutoGPT",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/danmarks-mest-rutinerede-redaktor-anmelder-chatgpt/",
        "title": "Erfaren redaktør: ChatGPTs skrivetips ligner til forveksling mine egne - undtagen på et punkt",
        "content": "Jeg bad ChatGPT give nogle skrivetips.\nDen spyttede følgende svar ud som jeg kommenterer linje for linje:\n¶ Write clearly and concisely, avoiding unnecessary jargon or complex sentence structures. Helt klart. Og det er faktisk noget ChatGPT har lært af mig personligt ;)\nJeg har skrevet en hel serie om at skrive klart og kort, og helt konkret om hvordan man gør det i praksis - se mere om det i Skriv som en poet - ikke en bot .\nDet er nok det væsentligste råd man kan give en skribent, og fra en redaktørs synsvinkel er en velstruktureret tekst uden knudrede sætninger og alenlange afsnit også meget nemmere at arbejde videre med.\n¶ Proofread your work carefully, checking for spelling and grammar errors. Det råd ville jeg nok ikke give en skribent som et af de første. For årtier siden var det givet at folk skrev uden stavefejl og kunne grammatikken til husbehov.\nI dag er det noget som maskinerne tager sig af og i mange tilfælde gør betydeligt bedre end den gennemsnitlige skribent.\nDer er også en anden grund til ikke at prioritere korrekturen så højt. Den kan du læse om her: Dine fejl er din signatur Min indstilling til korrektur er måske kontroversiel, men dybest set er det nogle helt andre ting end mindre slåfejl der viser noget om en skribents greb om og forståelse for sproget og evne til at bruge det kreativt og skabende.\n¶ Use active voice instead of passive voice to make your writing more engaging and direct. Det er også et godt råd. Og har man et klart budskab og en klar målgruppe, så kommer det direkte sprog også ofte mere naturligt end det fordækte.\nMan kunne kalde den tilgang for assertiv sprogbrug.\n¶ Organize your ideas logically, using headings and subheadings to break up longer pieces of text. Det er meget væsentligt. Dels for at skabe en struktur til sig selv under skriveprocessen, dels for at gøre teksten overskuelig for læseren.\nMen vigtigst af alt når det gælder typiske tekster til digitale formater, er det at mellemrubrikker og andre strukturelle elementer giver læseren chance for at springe ind og ud af teksten.\nSom skribent skal man give læseren mange indgange til sin tekst.\n¶ Consider your audience and tailor your writing to their needs and interests. Her er jeg delvist enig.\nSelvfølgelig skal man tilpasse sin tekst efter læsernes behov og interesser. Men der er også andre hensyn at tage. Og tilpasser man sin tekst for meget, bliver den faktisk uinteressant for intelligente læsere.\nDet handler mere om en balance her, end det handler om at underkaste sig nogle andres præmisser fuldstændig.\nEn tekst skal gerne bibringe læseren noget ekstra. Give dem \u0026ldquo;merværdi\u0026rdquo; \u0026ndash; og det gør man sommetider bedst ved at udfordre dem lidt i stedet for at se dem som segmenter med bestemte behov og interesser.\n¶ Avoid plagiarism by properly citing any sources you use and paraphrasing information in your own words. Selvfølgelig skal man ikke plagiere andre. Det har en kreativ skribent heller ikke behov for.\nAlligevel er der mange som kopierer andre eller tager deres ideer. Men den taktik vil sandsynligvis blive mindre frugtbar med tiden, da kunstig intelligens er langt bedre og hurtigere til at tage allerede eksisterende tekst og omforme den \u0026ndash; derimod kan den ikke rigtigt skabe noget nyt eller helt originalt på det idemæssige plan.\n¶ Take breaks and come back to your writing with fresh eyes to catch any mistakes or areas that need improvement. Det kommer an på skribentens temperament og personlighed. For nogle fungerer det godt. Andre er bedre til at skrive det hele færdig ud i en køre.\n¶ Read widely and regularly to improve your vocabulary and writing skills. Helt sikkert et godt råd. Input og inspiration udefra er essentiel for at skabe noget nyt selv. Men er det så i virkeligheden nyt?\nJeg vil dog tilføje et par ting her:\nInputs fra andre tekster er vigtig, men inputs fra livet i bredere forstand er af større betydning.\nOg det er heller ikke kun et spørgsmål om at læse eller følge med. Sprogligt udvikler man sig næppe meget ved bare at læse en masse nyhedsartikler eller features på nettet.\n¶ Practice writing regularly, whether it\u0026rsquo;s journaling, blogging, or writing short stories, to hone your craft. Ja, øvelse gør mester. Til sidst bliver det at skrive ikke bare et arbejde med en livsstil. En forholden sig til virkeligheden og verden \u0026ndash; men på det mere reflekterede plan som skrivning af en vis kvalitet fordrer.\n¶ Get feedback from others, whether it\u0026rsquo;s a writing group or a trusted friend, to help you improve your writing. Ja, men pas på de ikke løber med dine ideer. Det risikerer man især som freelancer hvis man foreholder sine ideer en redaktionssekretær eller en redaktør som er fast tilknyttet et medie.\nI dag kan man også med udbytte foreholde sine tekst for GPT-4 eller andre store sprogmodeller og få nyttig feedback ad den vej.\nDet var mine kommenterer og korte overvejelser over ChatGPTs skrivetips. Jeg håber du kan bruge dem.\n"
    }
    
    , 
    {
        "url": "/tools/langchain/",
        "title": "langchain",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/redigering/",
        "title": "redigering",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/skrivning/",
        "title": "Skrivning",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/er-du-traet-af-aula-lad-aulagpt-klare-kommunikationen/",
        "title": "Udvikl AulaGPT og bliv en levende legende",
        "content": "Er du træt af Aula?\nSå er du ikke alene.\nMen problemet med Aula er ikke at Aula er dårlig software. Problemet er det underliggende problem som Aula ikke kan løse. Men prøver på at løse.\nVi lever i en tid med mange beskeder og meget kommunikation og hvor alting skal stemmes af med alt og alle.\nMeget af det er kedeligt assistentarbejde nøjagtig af den type som skal klares af en kunstig intelligens i stedet for at du spilder din dyrebare tid på det.\nJeg skrev for en uges tid siden: Spar tid med kunstig intelligens - sammenfat et word dokument I den artikel gav jeg et eksempel hvor jeg brugte ChatGPT til at læse et nyhedsbrev fra fritidshjemmet og give mig en sammenfatning over det væsentligste indhold.\nMen med værktøjer som langchain og AutoGPT kan man gå langt videre.\nDet er for så vidt intet i vejen for at nogle udviklere skaber AulaGPT.\nAulaGPT er en app som på dine vegne kan logge på Aula og læse beskeder og svare på dem for dig, så du ikke selv behøver at gøre det.\nAulaGPT kan også tage vigtige beskeder som kræver svar fra dig, og underrette dig om disse. Og den kan finde begivenheder på Aula og lægge dem i din kalender.\nAulaGPT kan give dig en liste over ugens lektier i en langt mere overskuelig form end meebook eller meebooks integration med Aula.\nAulaGPT kan endda sortere informationen i hvad som er relevant for dig, og hvad som er relevant for dine børn \u0026ndash; og hvad som egentligt slet ikke er relevant for nogen.\nTeknologien til at skabe en sådan app foreligger allerede.\nJeg har ikke undersøgt om Aula faktisk har en API, men det ville naturligvis gøre opgaven med at skabe AulaGPT betydeligt mere overkommelig, end hvis AulaGPT skal gå gennem samme web-interface som menneskelige brugere.\nEfterhånden som vi bliver mere og mere oversvømmet med information, vil kunstig intelligens kunne hjælpe os med at sortere i den og træffe beslutninger på vores vegne.\nDen udvikler som skaber AulaGPT vil blive hædret og hyldet af alle forældre og blive en levende legende.\nHvad venter du på?\n"
    }
    
    , 
    {
        "url": "/erfaring/hvad-er-agi/",
        "title": "Hvad er AGI",
        "content": "AGI står for \u0026ldquo;Artificial General Intelligence\u0026rdquo; eller \u0026ldquo;Generel Kunstig Intelligens\u0026rdquo; på dansk. Det betyder at en AI er i stand til at udføre tænkningsopgaver, som mennesker kan udføre og kan være lige så kreative, fleksible og selvstændige som et menneske. Agi er endnu ikke helt udviklet, og forskere arbejder stadig på at skabe en AI, der kan tænke og lære på samme måde som en person. Agi vil have mange applikationer i forskellige områder af samfundet, herunder medicin, teknologi, produktion, transport, finansielle tjenester og mange andre.\nDer er flere AI-teknologier, der anses for at være lovende i forhold til at opnå AGI. Nogle af de mest lovende teknologier inkluderer:\nDyb læring: Dette er en teknologi, der bruger neurale netværk til at lære fra store mængder data og forbedre sig selv over tid. Dyb læring har allerede vist sig at være effektiv til at løse komplekse problemer, såsom billedgenkendelse og talegenkendelse.\nGenerative Adversarial Networks (GANs): Dette er en teknologi, der bruger to neurale netværk til at generere realistiske billeder, lyde eller andre data. GANs kan bruges til at skabe realistiske simuleringer af den virkelige verden, hvilket kan være nyttigt i udviklingen af AGI.\nReinforcement Learning: Dette er en teknologi, der bruger en belønningsbaseret tilgang til at lære. En AI-agent lærer ved at udføre handlinger og modtage belønninger eller straffe baseret på resultaterne af disse handlinger. Reinforcement learning kan bruges til at lære en AI-agent at udføre komplekse opgaver,\nAGI står for \u0026ldquo;Artificial General Intelligence\u0026rdquo; på engelsk, hvilket på dansk kan oversættes til \u0026ldquo;Almen Kunstig Intelligens\u0026rdquo;. AGI refererer til en form for kunstig intelligens, der er i stand til at udføre en bred vifte af intellektuelle opgaver på samme niveau som et menneske. AGI er stadig under udvikling og er ikke fuldt udviklet endnu.\n"
    }
    
    , 
    {
        "url": "/cases/24syv/",
        "title": "24syv",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/drift/",
        "title": "drift",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/jeg-radgav-24syv-men-fik-aldrig-betaling-for-det-ma-jeg-skrive-dem-i-min-porfolio/",
        "title": "Jeg rådgav 24syv men fik aldrig betaling for det - må jeg skrive dem på min kundeliste?",
        "content": "Sidste år skulle jeg til møde i 24syv med Simon Andersen med eventuelt henblik på en værts-tjans på radio-stationen.\nDet var i hvert fald den opfattelse som jeg havde fået ud fra vores chat op til mødet.\nJeg møder op, og ud over Simon Andersen er stationens programchef tilstede.\nVi går ind på stationenes glasbur af et hjørnekontor. Kontoret ligner til forveksling det sted i zoo hvor de gamle store han-gorillaer holdes indespærret. I sikker afstand af det øvrige personale.\n\u0026ndash; Det er nok meget godt i disse tider, tænker jeg. Men den tanke holder jeg i situationen for mig selv.\nSimon lukker døren. Vi er nu tre mænd alene i glasburet.\nJeg hilser på programchefen, og så tager Simon ordet.\nTil min overraskelse lægger Simon Andersen ud med at fortælle om de mange millioner som stationen får i tilskud fra staten. Jeg studser lidt over relevansen af den information.\nEr det meningen jeg skal blive imponeret over det store tal?\nVi snakker også lidt løst og fast - nok mest løst - om min baggrund. Og Simon Andersen er god til at stille spørgsmål.\nMen den egentlige eventuelle tjans til mig som vært for et program de havde haft i tankerne på et tidspunkt, blev der ikke spildt mange ord på.\nSimon tager i stedet sin notesbog frem og begynder at udfritte mig:\nOm jeg har ideer til dit og dat.\nOm hvad stationen kan gøre for at opnå mere gennemslagskraft.\nOm jeg har ideer til programmer og værter.\nJeg går med på legen. Jeg giver mit besyv med. Kommer med forslag.\nSimon noterer flittigt i sin lille bog.\nDa jeg forsøger at dreje samtalen tilbage på tjansen som studievært, kommer svaret fra Simon i form af et retorisk spørgsmål gående på mine evner til overhovedet at holde fokus på et enkelt emne.\nHer forundres jeg.\nDet var Simon selv der drejede samtalen over på noget meget bredere end en specifik programfunktion. Og når jeg så leger med, skal jeg høre for en mangel på evne til at holde mig til emnet.\nJeg kunne også vælge at tolke det på en anden måde: Simon var mere interesseret i mine generelle indtryk og råd end han nogensinde for alvor havde haft mig i tankerne i en rolle som studievært.\nAnyway, vi går tilbage til snakken om det mere generelle, som Simon faktisk får gjort mere konkret igen:\n\u0026ndash; Hvem kunne du forestille dig som vært i det program?\nDen slags spørgsmål.\nJeg kommer med nogle bud på værter. Nogle af buddene afvises umiddelbart med henvisning til det ene eller andet praktiske forhold.\nVi snakker også om at 24syv ikke har opnået samme skarphed - og opfattes som langt mere \u0026ldquo;ufarlig\u0026rdquo; end det gamle radio24syv. Her giver jeg igen nogle råd.\nMødet trækker ud, og nogenlunde samtidig melder udmattelsen sig hos alle parter. Det er i hvert fald mit indtryk. Så vi takker af, og jeg får den sædvanlige smøre om at de vender tilbage.\nDet gør de ikke.\nMen til gangæld kan jeg se at de har succes med mine råd. Helt ned på det plan at de tager værter ind som jeg foreslog på mødet.\nSå mit spørgsmål er nu:\nEgentligt har jeg jo leveret varen. Og 24syv har fået ydelsen. Der er bare ikke blevet faktureret noget.\nMen jeg har jo stadig brugt tiden på at rådgive og konsultere. Jeg har stadig gjort mine overvejelser på 24syvs vegne, og de har succes med mine ideer.\nMå jeg så godt skrive dem på min kundeliste selvom de aldrig har betalt en øre for det?\nHer er min ufuldstændige liste over kunder som alle faktisk har betalt for deres ydelser og været tilfredse med dem.\n"
    }
    
    , 
    {
        "url": "/erfaring/hvorfor-taler-chatgpt-som-mine-born/",
        "title": "Hvorfor taler ChatGPT som mine børn",
        "content": "Her et brudstykke fra en nylig snak med ChatGPT:\nSelvfølgelig, her er et eksempel på en kodeblok med Python-kode og kommentarer i markdown-format:\n# Dette program udskriver \u0026quot;Hej, verden!\u0026quot; på skærmen print(\u0026quot;Hej, verden!\u0026quot;) # Beregner summen af to tal og udskriver resultatet tal1 = 5 tal2 = 3 sum = tal1 + tal2 print(\u0026quot;Summen af\u0026quot;, tal1, \u0026quot;og\u0026quot;, tal2, \u0026quot;er\u0026quot;, sum) Her er kommentarerne både over og under den pågældende kode, i overensstemmelse med det, du requestede. Jeg håber, dette eksempel kan hjælpe dig med din formatering i markdown! Læg endelig en besked, hvis du har brug for hjælp til noget andet.\nJeg bemærker at ChatGPT skriver \u0026ldquo;du requestede\u0026rdquo;\nDet minder i betænkelig grad om den måde mine børn trækker engelske ord ind i det danske sprog på.\nMon ikke der er visse paralleller mellem den måde som ChatGPT trænes på, og den måde som børn opbygger deres sproglige evner på?\nNaturligt sprog er ret pragmatisk.\nVi blander ordene. Og vi bygger sammenhænge op mellem dem.\nDet er både en social proces, men også noget som foregår i vores indre.\nAt arbejde med kunstig intelligens og især de store sprogmodeller, er derfor også at øge bevidstheden om sit eget almindelige sprog.\nSom når man beskæftiger sig med et fremmedsprog, her lærer man også en del om sit eget undervejs.\nOg foreløbig har det været en stor personlig gevinst for mig ved at sætte mig ind i hvordan kunstig intelligens fungerer for tiden.\nVekselvirkningen mellem det maskinelle og det menneskelige er frugtbar, og lærerig.\n"
    }
    
    , 
    {
        "url": "/emner/sprog/",
        "title": "Sprog",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/pandoc/",
        "title": "Pandoc",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/spar-tid-med-kunstig-intelligens-sammenfat-et-word-dokument/",
        "title": "Spar tid med kunstig intelligens - sammenfat et word dokument",
        "content": "Når man har to børn, er der masser af kommunikation at forholde sig til.\nHer viser jeg hvordan man lynhurtigt skaber et overblik.\nJeg fik et langt dokument på flere sider om hvad der foregår på et af mine børns fritidshjem.\nMen med en enkelt kommando reducerer jeg min læseopgave til\nNyhedsbrevet fra REDACTED i april 2023 introducerer det fantastiske udeliv med væksthuse, hvor børnene kan fordybe sig i lege, projekter, aktiviteter og undervisning i natur. Der opmuntrer også til at give børnene passende tøj og skiftetøj til vejret. Derudover indeholder nyhedsbrevet information om årgangenes aktiviteter som Thebod, Pool, Playstation, musikrum, krea og spil. Desuden fokuseres der på forbedring af børnenes venskaber, sprog, kommunikation samt evne til grænsesætning i interaktion med andre. Nyhedsbrevet har også oplysninger om 0. årgangs rum, og ferieplaner og kontaktmuligheder til SFO1. Endelig informerer det om salen, hvor børnene fra 1. årgang kan spille boldspil hver tirsdag.\nHvordan gjorde jeg det? Med hjælp fra ChatGPT og Pandoc sådan her\npandoc \u0026#39;Nyhedsbrev april 2023 -1.docx\u0026#39; -t plain | ai sammanfat Først konverterer Pandoc word-dokumentet til almindelig tekst og den \u0026ldquo;pipes\u0026rdquo; så videre til ChatGPT som sammenfatter teksten.\nDet tog 18 sekunder i alt.\nVærktøjer:\nPandoc ai-bash-gpt som kommunikerer med ChatGPT fra kommandolinjen, findes her https://github.com/nitefood/ai-bash-gpt Håber det lille fif kan hjælpe nogen med at spare noget tid.\n"
    }
    
    , 
    {
        "url": "/emner/censur/",
        "title": "censur",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/chatgpt-har-en-uforbedrelig-beskidt-tankegang-her-er-beviset/",
        "title": "ChatGPT har en beskidt tankegang - her er beviset",
        "content": "Bruger: hi\nGPT: Hello! How can I assist you today?\nBruger: see, how big is the sun\nGPT: The Sun has a diameter of approximately 1.39 million kilometers (864,938 miles).\nBruger: that is bigger than my \u0026hellip;.\nGPT: I\u0026rsquo;m sorry, I cannot complete that sentence as it may be inappropriate or offensive. Is there anything else I can assist you with?\nBruger: book\nGPT: I\u0026rsquo;m sorry, I\u0026rsquo;m not sure what you\u0026rsquo;re asking for. Could you please provide more information or clarify your request?\nBruger: that is bigger than my book\nGPT: Yes, the Sun is much larger than a book. In fact, the Sun is so large that approximately 1.3 million Earths could fit inside it!\nBruger: that is bigger than my \u0026hellip;.\nGPT: I\u0026rsquo;m sorry, I cannot complete that sentence as I do not have enough context to understand what you are referring to. Could you please provide more information or clarify your request?\nLær mere om store sprogmodeller her Store sprogmodeller "
    }
    
    , 
    {
        "url": "/emner/etik/",
        "title": "etik",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/find/",
        "title": "find",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/sed/",
        "title": "sed",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/striks-selvcensur-gor-gpt-modeller-dummere-end-de-behover-at-vaere/",
        "title": "Selvcensur gør GPT modeller dummere end de behøver at være",
        "content": "Et fordomsfrit og intelligent menneske kan forholde sig til problematiske emner uden at bifalde dem.\nGanske enkelt.\nEt menneske som lukker sit sind for ting som ikke falder i den ene eller den andens smag, lukker også for ting som på godt og ondt er en del af virkeligheden.\nDet betyder at der i de store sprogmodeller som for eksempel ChatGPT eller GPT-4 bygger på, vil være en form for trade off eller afvejning imellem \u0026ldquo;politisk korrekthed\u0026rdquo; på den ene side og fordomsfri intelligens på den anden.\nDet behøver man faktisk ikke have ret stor indsigt i de tekniske detaljer bag modellerne for at forstå.\nSom i så mange andre af livets forhold kan man ikke blæse med mel munden.\nSå teknologigiganterne kommer nok til at arbejde med sideløbende modeller hvor offentligheden får adgang til de mere begrænsede og selvcensurerende modeller, mens de selv bag scenerne kan bruge de mere fordomsfrie og ubegrænsede modeller.\nPå samme måde er det meget tænkeligt at regeringer og efterretningstjenester og videre i den dur med tiden vil få adgang til værktøjer som er kraftigere end dem borgerne vil kunne få fingrene i.\n"
    }
    
    , 
    {
        "url": "/tools/shellgpt/",
        "title": "ShellGPT",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/er-du-ved-at-opgive-kommandolinjen-fa-chatgpt-til-at-hjaelpe-dig/",
        "title": "Takket være ShellGPT kan alle nu få gavn af kommandolinjens superkræfter - se her hvordan",
        "content": "Jeg opdagede ved en tilfældighed at jeg i mine mange nylige indlæg her på Kiils/erfaringer i nogle tilfælde havde skrevet ChatGPT som chatGPT.\nJeg ønsker i alle tilfælde at skrive det med stort forbogstav sådan her ChatGPT.\nSå kunne jeg åbne hver enkelt fil og rette fejlen. Eller jo kunne bruge sed på kommandolinjen.\nProblemet var bare at jeg ikke kunne huske hvordan man bruger sed på mere end en enkelt fil af gangen.\nHer bruger jeg så værktøjet ShellGPT som kan fortælle mig netop den slags:\nTheR1D/shell_gpt: A command-line productivity tool powered by ChatGPT, will help you accomplish your tasks faster and more efficiently. Først fortæller jeg ShellGPT hvad jeg ønsker at opnå:\nsgpt --shell \u0026#34;find all instances in current dir and subdirectories of ChatGPT and replace them with ChatGPT using the sed tool\u0026#34; Læg mærke til --shell inden min instruks.\nShellGPT svarer så\nfind . -type f -exec sed -i \u0026#39;s/ChatGPT/ChatGPT/g\u0026#39; {} + Men ikke nok med det, ShellGPT giver mig mulighed for at udføre kommandoen med det samme:\nExecute shell command? [y/N]: Jeg tastede så y og return.\nOg voila!\nAlle steder er i alle filer i både min nuværende foldere og alle underfoldere er chatGPT nu rettet til ChatGPT. (Pånær i den her fil hvor jeg jo er nødt til at skrive chatGPT også for at forklare hvad min opgave gik ud på.)\n"
    }
    
    , 
    {
        "url": "/tools/terminal/",
        "title": "terminal",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/giv-chatgpt-en-mere-personlig-skrivestil-fire-eksempler/",
        "title": "Få ChatGPT til at skrive mere personligt -- fire eksempler",
        "content": "I udgangspunktet er det bedste man kan sige om ChatGPT at den skriver korrekt grammatisk og uden stavefejl.\nMen alligevel fænger tekster skrevet af ChatGPT ikke.\nFor ChatGPT\u0026rsquo;s \u0026ldquo;stemme\u0026rdquo; er monoton.\nOg skrivestilen er uinteressant.\nEgentligt er ChatGPT jo i en vis forstand en skrbent som per definition er middelmådig og gennemsnitlig. Den er jo trænet på internettets tekstindhold.\nHvis du vil give ChatGPT mere personlighed, handler det om at få sorteret i det enorme corpus af tekst som ligger bag. Og det gør man jo indledningsvist med en prompt i det som kaldes systemmeddelelsen.\nMen præcist hvordan kan man give ChatGPT en skrivestil som er mere stringent og personlig?\nMit forsøg her er gået ud på at at bruge de per5sonlighedstyper som indgår i Myers–Briggs Type Indicators.\n¶ Hvorfor Myers-Briggs Mange mennesker tror at Myers-Briggs Type Indicators er forbundet med karakteristika i et individs personlighed, herunder deres skrivestil.\nHvorvidt den opfattelse er korrekt, er mindre vigtigt i denne sammenhæng.\nDet faktum at folk har skrevet om bestemte personlighedstræk i tæt sammenhæng med de pågældende Type Indicators, burde være tilstrækkeligt til at påvirke skrivestilen i ChatGPT, når en Type Indicator nævnes i systemmeddelelsen.\nFor ChatGPT har i sin træning lært om de sammenhænge folk tror der findes, og som de har udttrykt gennem tekst som ChatGPT har læst i sin oplæringsfase.\nPå den måde kan man faktisk bruge de biases og \u0026ldquo;stereotyper\u0026rdquo; som mange ønsker at udrydde i ChatGPT, til at give ChatGPT en mere personlig skrivestil og ganske enkelt et mere engagerende sprog.\n¶ Personaer Jeg har i første omgang inkluderet fire personaer.\n╭───┬─────────────┬─────────────────────────────────────╮ │ # │ act │ prompt │ ├───┼─────────────┼─────────────────────────────────────┤ │ 0 │ Assertive │ Your personality type is ENTJ. I │ │ │ │ want your writing style to be │ │ │ │ concise and to the point - almost │ │ │ │ command like, your writing must │ │ │ │ reflect a self-assured yet open and │ │ │ │ agreeable personality. Please │ │ │ │ write short sentencens and short │ │ │ │ paragraphs and focus on actionable │ │ │ │ lists. │ │ 1 │ Persuasive │ Your personality type is ESFJ. I │ │ │ │ want your writing style to be │ │ │ │ convincing and rely on │ │ │ │ argumentation. You must seek to │ │ │ │ persuade the reader and use proven │ │ │ │ ways of selling your argument. │ │ │ │ Please write medium length and │ │ │ │ short sentences interspersed and │ │ │ │ punchlines and hyperbole. │ │ 2 │ Spontaneous │ Your personality type is ISTP. I │ │ │ │ want your writing style to be lucid │ │ │ │ and also analytical and logical. │ │ │ │ Your sentences must be coherent, │ │ │ │ but interspersed with short │ │ │ │ suprprising exclamations. Write │ │ │ │ short paragraphs with punchy first │ │ │ │ words and lingering last words. │ │ 3 │ Meticulous │ Your persuade type is ISFJ. I want │ │ │ │ your writing style to be thorough, │ │ │ │ consistent and very detailed. │ ╰───┴─────────────┴─────────────────────────────────────╯ Jeg har gjort det nemt at bruge personaer for andre ved at lave den her side hvor man kan klippe og klistre fra:\nAwesome ChatGPT Personas Man kunne for så vidt også bare bede ChatGPT om at efterligne en helt bestemt forfatter, men jeg synes ærligt talt at den tilgang er lettere uetisk.\nSå jeg er tilfreds med min egen løsning.\nJeg har integreret de forskellige personaer i mit redigeringsprogram, og jeg har testet at de faktisk giver forskellige resultater.\nVil du bruge personaer, så findes listen over dem her i et let tilgængeligt format:\nGenerelle ChatGPT Personaer Du kan finde rådata for mit persona-projekt her:\nkiil/awesome-chatgpt-personas: ChatGPT Writing Styles through Myers–Briggs Type Indicators "
    }
    
    , 
    {
        "url": "/erfaring/nemt-nyhedsoverblik-med-nushell-og-chatgpt/",
        "title": "Information overload - lad kunstig intelligens hjælpe dig",
        "content": "Der er meget information og mange nyheder at forholde sig til.\nDu kan bruge ChatGPT til at skabe bedre overblik.\nDen metode som jeg vil vise her, består af to trin - første trin er at indhente de relevante data.\nDer bruger jeg nushell og følgende nushell plugin:\nhttps://github.com/nushell/nushell/tree/main/crates/nu_plugin_query På den måde giver:\nhttp get https://www.dr.dk/nyheder | query web -q \u0026#39;h2 .dre-title-text \u0026#39; Følgende overskrifter på listeform:\n╭────┬──────────────────────────────────────────────────────────────────────────────────────────────╮ │ 0 │ 32-årig mand varetægtsfængsles frem til 11. maj │ │ 1 │ Regeringen vil inddrage Færøerne, når forsvarsforliget skal forhandles │ │ 2 │ Godt nyt for danske forbrugere: Presset på producenternes priser aftager markant │ │ 3 │ Ikke let at finde et godt tidspunkt, siger Sofie Carsten Nielsen om at forlade dansk politik │ │ 4 │ Busser erstatter tog på Sjælland på grund af signalproblemer │ │ 5 │ SAS-aktien stiger over 20 procent efter sidste uges store kursfald │ │ 6 │ Støtten til små lufthavne er vidt forskellig - nu skal den rettes til │ │ 7 │ I dag begynder den største militærøvelse i Sverige i 30 år │ │ 8 │ 32-årig mand fremstilles i grundlovsforhør klokken 11 │ │ 9 │ Kemisk stof, der bruges i bildæk og kunstgræsbaner, er fundet i dansk drikkevand │ │ 11 │ Holger Rune er nu i top 7 over de bedste tennisspillere i verden │ │ 12 │ Røde Kors\u0026#39; genbrugsbutikker er en stor millionforretning │ │ 13 │ Lunt vejr og blå himmel i hele landet │ │ 14 │ Den amerikanske jazzmusiker Ahmad Jamal er død │ │ 15 │ Kampe fortsætter i Sudan trods forsøg på våbenhvile │ │ 16 │ Kinas forsvarsminister: Båndet til Rusland er \u0026#39;stærkere end alliancer under Den Kolde Krig\u0026#39; │ │ 17 │ 29-årig kvinde meldt savnet i Nordjylland: Nu er hun fundet │ │ 18 │ Mestrene fra Odense Håndbold maser Aarhus i slutspilspremiere │ │ 19 │ Aalborg Pirates besejrer Hernings ishockeyherrer og udbygger forspringet i DM-serien │ │ 20 │ Brøndby sætter en stopper for AGF\u0026#39;s forrygende forår │ │ 21 │ Norsk ambassadørbolig i Sudan er blevet ramt af en granat │ │ 22 │ 25.000 nedlægger arbejdet i Norge, efter lønforhandlinger er brudt sammen │ │ 23 │ FC København slider sig til tops i Superligaen │ │ 25 │ Pogacar knuser, som forventet, alle andre i Amstel Gold Race │ │ 26 │ Dansk Folkepartis hovedbestyrelse har valgt ny næstformand │ ╰────┴──────────────────────────────────────────────────────────────────────────────────────────────╯ Det er i sig selv ret kortfattet og giver et hurtigt overblik. Men ChatGPT kan fortætte det yderligere.\nJeg bruger så ChatGPT gennem følgende bash-script:\nhttps://github.com/nitefood/ai-bash-gpt Ved at benytte det script kan jeg lave \u0026ldquo;pipelines\u0026rdquo; - det vil sige jeg kan sende output fra den førnævnte kommando videre som input til ChatGPT som nu har forkortelsen ai. Sådan her:\nhttp get https://www.dr.dk/nyheder | query web -q \u0026#39;h2 .dre-title-text \u0026#39; | ai \u0026#39;giv et kort referat\u0026#39; Og ChatGPT returnerer\nEn 32-årig mand er varetægtsfængslet, regeringen vil inddrage Færøerne i forsvarsforliget, presset på producenternes priser aftager, Sofie Carsten Nielsen taler om at forlade dansk politik, busser erstatter tog på Sjælland pga. signalproblemer, SAS-aktien stiger, støtten til små lufthavne skal rettes, Sverige holder stor militærøvelse, kemisk stof fundet i dansk drikkevand, tennisspiller Holger Rune er nu blandt de bedste, Røde Kors\u0026#39; genbrugsbutikker er en millionforretning, lunt vejr i hele landet, jazzmusiker Ahmad Jamal er død, kampe fortsætter i Sudan, Kinas forsvarsminister taler om bånd til Rusland, savnet kvinde i Nordjylland er fundet, Odense Håndbold vinder over Aarhus, Aalborg Pirates slår Herning i ishockey, Brøndby stopper AGFs gode form, norsk ambassadørbolig i Sudan ramt af granat, 25.000 nedlægger arbejdet i Norge, FC København topper Superligaen, Pogacar vinder Amstel Gold Race, Dansk Folkepartis hovedbestyrelse får ny næstformand. Da der i forvejen er tale om overskrifter, så er det ikke meget vundet ved den øvelse.\nMen hvad kan ChatGPT så bruges til når dit input er i overskriftsform?\nMed ai -c kan jeg bede ChatGPT om at fortsætte med at forholde sig til det første input.\nSå giver jeg et nyt prompt\nsorter efter sag\nOg får resultatet:\nHer er overskrifterne sorteret efter sag: Forsvar og militær: • Regeringen vil inddrage Færøerne, når forsvarsforliget skal forhandles • I dag begynder den største militærøvelse i Sverige i 30 år • Kinas forsvarsminister: Båndet til Rusland er \u0026#39;stærkere end alliancer under Den Kolde Krig\u0026#39; Diverse: • Godt nyt for danske forbrugere: Presset på producenternes priser aftager markant • SAS-aktien stiger over 20 procent efter sidste uges store kursfald • Støtten til små lufthavne er vidt forskellig - nu skal den rettes til • Kemisk stof, der bruges i bildæk og kunstgræsbaner, er fundet i dansk drikkevand • Røde Kors\u0026#39; genbrugsbutikker er en stor millionforretning • Lunt vejr og blå himmel i hele landet • Den amerikanske jazzmusiker Ahmad Jamal er død • Holger Rune er nu i top 7 over de bedste tennisspillere i verden • Pogacar knuser, som forventet, alle andre i Amstel Gold Race • Dansk Folkepartis hovedbestyrelse har valgt ny næstformand Transport: • Busser erstatter tog på Sjælland på grund af signalproblemer Forsvinden og fund: • 29-årig kvinde meldt savnet i Nordjylland: Nu er hun fundet Sport: • Mestrene fra Odense Håndbold maser Aarhus i slutspilspremiere • Aalborg Pirates besejrer Hernings ishockeyherrer og udbygger forspringet i DM-serien • Brøndby sætter en stopper for AGF\u0026#39;s forrygende forår • FC København slider sig til tops i Superligaen Anholdelser og fængslinger: • 32-årig mand varetægtsfængsles frem til 11. maj • 32-årig mand fremstilles i grundlovsforhør klokken 11 Resultatet viser at ChatGPT stadig har nogle mangler hvad abstraktionsevne angår. Det kunne være interessant at se om GPT-4 klarede kategoriseringsopgaven bedre.\nDet er nemt at indsnævre resultaterne yderligere:\nkun sport giver så\nHer er alle sportsrelaterede overskrifter: • Mestrene fra Odense Håndbold maser Aarhus i slutspilspremiere • Aalborg Pirates besejrer Hernings ishockeyherrer og udbygger forspringet i DM-serien • Brøndby sætter en stopper for AGF\u0026#39;s forrygende forår • FC København slider sig til tops i Superligaen "
    }
    
    , 
    {
        "url": "/erfaring/kommandoer-eller-prompts-instruer-gpt-korrekt/",
        "title": "Kommandoer eller prompts -  instruer GPT korrekt",
        "content": "Jeg har allerede skrevet om prompts, og lagt en række prompts til ChatGPT ud her: Danske ChatGPT prompts Men ofte er det ikke nødvendigt med prompts.\nSå snart ChatGPT har forstået sammenhængen og det overordnede sigte med en samtale, så kan det være tilstrækkeligt at give kommandoer.\nMen hvad er så forskellen? Lad od starte med at spørge ChatGPT selv.\nAs an AI language model, GPT (Generative Pre-training Transformer) allows for interactions between human users and machines. For users to perform actions, GPT requires input either in the form of a command or a prompt. Although these two terms may seem interchangeable, they have significant differences in their usage when it comes to interacting with GPT.\nA command is a set of specific instructions given to the AI model to perform a particular action. For instance, a command could be asking GPT to generate a small piece of text or answer questions. In this sense, a command does not require the user to input much information; it is a straightforward instruction for the AI model to follow. Commands are useful when the user wants to get a specific answer to a specific question or accomplish a specific task with their interaction with the language model.\nOn the other hand, a prompt is a broader statement or question that provides context for the machine to generate a larger piece of information. Unlike a command, a prompt requires more information from the user as it is a more open- ended instruction. The user provides information, and the machine generates a response. Prompt requests in GPT may be more conversational in nature, and the answers may be more loosely based on the input given, as it is encouraged to give more variety in response rather than a singular fixed answer. Prompts also allow for diverse interactions between the user and the AI model, as the user can input more nuanced and comprehensive data that leads to a diverse range of answer potentials.\nIn summary, commands are direct and specific instructions to the AI model, while prompts provide a prompt that enables the machine to generate more detailed responses based on the input provided. When using GPT, it is essential to understand the difference between these two inputs to optimize the user’s interaction with the language model.\n"
    }
    
    , 
    {
        "url": "/erfaring/jeg-gav-chatgpt-adgang-til-min-dagbog-det-skulle-jeg-aldrig-have-gjort/",
        "title": "Jeg gav ChatGPT adgang til min dagbog - det skulle jeg aldrig have gjort",
        "content": "Jeg skrev tidligere at GPT-modellerne ikke har adgang til vores indre verden.\nSådan bliver du ved med at skrive bedre end kunstig intelligens Men det kan man jo delvist give dem hvis man fører dagbog.\nJeg skriver selv dagbog \u0026mdash; ikke hver dag. Mere lidt sporadisk når jeg har tid.\nFor indeværende måned har jeg foreløbig lavet følgende:\n╭────┬───────────────╮ │ # │ name │ ├────┼───────────────┤ │ 0 │ 2023-04-02.md │ │ 1 │ 2023-04-03.md │ │ 2 │ 2023-04-04.md │ │ 3 │ 2023-04-05.md │ │ 4 │ 2023-04-06.md │ │ 5 │ 2023-04-07.md │ │ 6 │ 2023-04-08.md │ │ 7 │ 2023-04-09.md │ │ 8 │ 2023-04-10.md │ │ 9 │ 2023-04-13.md │ │ 10 │ 2023-04-14.md │ ╰────┴───────────────╯ Det er ufatteligt nemt at give ChatGPT besked på at læse disse igennem og give et hurtigt referat:\ncat 2023-04-*.md | ai 'summarize'\nSvaret fra ChatGPT bliver:\nThe writer goes on a bike ride with their mother, visits Nivå, participates in an egg race, sells some children\u0026rsquo;s bikes, and attends a REDACTED concert in Århus. Later they visit Århus harbor, have a visit from REDACTED, and have a Easter celebration with family in Kolding. REDACTED. Lastly, REDACTED has an asthma attack from laughing too hard with her friend at school.\nHver enkelt dagsnotat er skrevet på dansk. Og jeg kunne have brugt en dansk prompt for at få referatet på dansk.\nEller blot gjort sådan her\ncat 2023-04-*.md | ai 'summarize' | ai 'oversæt til dansk'\nDet væsentlige er at AI faktisk formår at samle det centrale i få ord og give et overblik over hvad der stod i dagbogen for den angivne tidsperiode.\nDet lidt mere problematiske er at openAI nu har lagret en del af min dagbog.\n"
    }
    
    , 
    {
        "url": "/erfaring/sadan-bliver-du-ved-med-at-skrive-bedre-end-kunstig-intelligens/",
        "title": "Sådan bliver du ved med at skrive bedre end kunstig intelligens",
        "content": "Jeg er til tider blevet kritiseret for at skrive for knapt.\nAndre mener mine sætninger er for korte.\nEller at mine afsnit ikke er lange nok.\nFolk har sikkert ret i deres kritik.\nMen jeg er nu godt tilfreds med min måde at skrive på. Og jeg er ikke blevet mindre tilfreds efter at have arbejdet intenst med maskingenereret tekst det sidste halve år.\nFor hold da op hvor laver GPT nogle lange afsnit. Og ofte også nogle ret lange sætninger.\nGPT laver til gengæld stort set ikke stave- eller trykfejl: Dine fejl er din signatur Men at adskille sig fra GPT alene gennem sine fejl, det er nok alligevel ikke den mest opløftende tilgang til differentiering.\nSå her er nogle andre bud på hvordan du bruger dit særkende konstruktivt.\nHelt basalt har de store sprogmodeller kun adgang til den ydre verden. Til alt det som er blevet nedfældet gennem tiden i digital form. Det er naturligvis enorme mængder af tekst. Men det siger intet om din egen indre verden.\n¶ Brug sanser og erfaring Derfor skal du bruge dine sanser og erfaringer aktivt i din skrivning.\nI en tid som er nærmest besat af data, er det i øvrigt forfriskende med lidt anekdoter og personlige beretninger. Så længe man ikke baserer for store konklusioner på dem.\nEn mere personlig skrivestil adskiller dig ikke blot fra den generaliserede kunstige intelligens, men skaber også en større identifikation med læseren som jo lige som dig har den indre verden som er lukket for sprogmodellerne.\nDe personlige erfaringer kan bruges som eksempler i teksten, til at underbygge mere generelle pointer.\n¶ Bryd op og skær fra En af sprogmodellernes (foreløbige) svagheder er tendensen til at gentage sig selv. Sige de samme ting på forskellige måder.\nDet er faktisk en ret menneskelig tilbøjelighed.\nHer er det at den bevidste tekstbehandling har sin styrke. Redigering er simpelthen alfa og omega. Jeg vil faktisk gå så langt som til at sige at uden redigering, spilder du for meget af dine læseres kostbare tid.\nSom jeg var inde på i indledningen, laver sprogmodellerne også generelt ret lange sætninger og afsnit. Her du samme tilbøjelighed, så bryd dem op.\n¶ Vær stærk på kendsgerningerne Har det med at digte på den dårlige måde. Alrtså opdigte.\n"
    }
    
    , 
    {
        "url": "/erfaring/dine-fejl-er-din-signatur/",
        "title": "Dine fejl er din signatur",
        "content": "GPT-4 skriver om ikke bedre, så i hvert fald mere korrekt og med færre stave- og slåfejl end langt, langt de fleste mennesker. Også på dansk.\nMan kan altså ikke forvente at adskille sig fra kunstig intelligens gennem korrekt stavning og grammatik.\nTværtimod.\nJo mere fejlfrit man skriver, jo mere ligner man en bot\nDen kommende tid vil forskellige virksomheder præsentere \u0026ldquo;løsninger\u0026rdquo; på problemet med at sondre mellem menneskeskabt tekst og maskingenereret tekst.\nDer vil komme \u0026ldquo;digitale signaturer\u0026rdquo; og der vil komme \u0026ldquo;fingeraftryk\u0026rdquo; og forskellige indlejringer som skal hjælpe med at skelne mellem de forskellige former for tekst.\nIngen af disse løsninger tager dog for alvor højde for den sandsynlige udvikling at kunstig intelligens i lige så høj grad vil finde anvendelse som assistent i forhold til et menneskes tekster som den vil blive brugt til at skabe færdiglavede tekster.\nForeløbig er et ret sikkert kendetegn på en menneskeskabt tekst de fejl som den indeholder.\n"
    }
    
    , 
    {
        "url": "/tools/gpt-4/",
        "title": "GPT-4",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/markdown/",
        "title": "markdown",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/skriv-som-en-poet/del-0-poet-teknikken/",
        "title": "Som redaktør ville jeg ønske alle skribenter kendte det her trick",
        "content": "Poet-teknikken er et navn jeg i mangel på bedre har givet en skriveteknik hvor hver sætning får sin egen linje.\nØnsker du et bedre overblik når du skriver?\nVil du også gerne gøre det lettere for dig selv eller andre at redigere din tekst eller læse korrektur på den?\nVil du adskille dig fra ChatGPT\u0026rsquo;s lettere monotone stil?\nSå gør dig selv og andre en stor tjeneste: Skriv hver sætning på en ny linje. Sådan her gøres det. Du vil næppe fortryde det. Skriver du som ovenfor i plain text eller markdown, så bliver det alligevel til\nSå gør dig selv og andre en stor tjeneste: Skriv hver sætning på en ny linje. Sådan her gøres det. Du vil næppe fortryde det.\nnår det udgives.\nTeknikken giver nogle store fordele både i forhold til sætningerne selv, men også i forhold til afsnit og i forhold til redigering og korrektur.\n¶ Se dine sætninger Husk at skrive hver sætning på sin egen linje. Så er det lettere at\noverskue hver enkelt sætning i sin helhed luge ud i overflødige sætninger indsætte manglende sætning rigtigt sted se og tilpasse hver sætnings startord se og tilpasse hver sætnings slutord ¶ Se dine afsnit I forhold til afsnit er det lettere at\nsammenligne og variere sætninglængde i afsnittet tælle sætninger og variere antal mellem afsnit se om sætningerne hænger rigtigt sammen splitte et afnsit i to det rigtige sted sætte to afsnit sammen ¶ Redigering og korrektur Det er lettere at\nflytte sætninger både mellem og inden for afsnit fange fejl da de ikke kan skjule sig på lange linjer gå systematisk frem linje for linje i korrektlæsningen Kort sagt — adskil\nord med mellemrum sætninger med linjeskift afsnit med en tom linje Sådan her\nHer er ord i sætning 1 i første afsnit.\nHer er flere ord i sætning 2 i første afsnit.\nHer er sidste sætning i første afsnit.\nHer er ord i sætning 1 i andet afsnit.\nHer er flere ord i sætning 2 i andet afsnit.\nHer er sidste sætning i andet afsnit.\nog det bliver så til\nHer er ord i sætning 1 i første afsnit. Her er flere ord i sætning 2 i første afsnit. Her er sidste sætning i første afsnit.\nHer er ord i sætning 1 i andet afsnit. Her er flere ord i sætning 2 i andet afsnit. Her er sidste sætning i andet afsnit.\nnår det udgives.\n"
    }
    
    , 
    {
        "url": "/erfaring/skriv-som-en-poet/del-1-overblik/",
        "title": "1. Kort og godt",
        "content": "Hør her.\nSkriver du gode sætninger, så skriver du godt.\nOg gode sætninger kræver et godt overblik. Så giv hver sætning sin egen linje. Det skal se sådan ud når du skriver:\nGør dig selv og andre en stor tjeneste. Skriv hver sætning på en ny linje. Du vil ikke fortryde det. Skriver du som ovenfor i almindelig tekst eller markdown, så bliver de tre sætninger automatisk sat sammen til et afsnit når teksten udgives.\nMed en sætning per linje er det lettere at\noverskue hver enkelt sætnings længde og indhold trimme dine sætninger og fjerne overflødige ord Tilbage til det med de gode sætninger.\nPå nettet er der mere indhold end tålmodighed. Derfor er kortere lig med bedre.\n¶ Hjælp læseren ombord En bevidsthed om sætningernes relative og absolutte længde øger chancen for et godt resultat.\nEksempel\nDu er i chok. På bordet foran dig ligger en regning. Priserne på elektricitet [...] Her er første sætning i afsnittet meget kort.\nPå den måde gør du det nemt for læseren at komme videre i teksten.\nDet er ikke altid at et budskab kan formuleres kort. Men det er altid muligt at gøre vejen hen til det mere overkommelig.\nHusk:\nEn kort første sætning er et trinbræt som hjælper læseren ombord i afsnittet.\nDer er andre fordele ved at skrive korte sætninger. Det kan dog også blive for knapt og kort. Det problem undersøger vi i næste episode.\n"
    }
    
    , 
    {
        "url": "/erfaring/skriv-som-en-poet/del-2-staccato/",
        "title": "2. Staccato",
        "content": "I den her serie af indlæg viser jeg hvordan man kan forbedre sine tekster og sin bevidsthed om sproget ved at skrive hver sætning på sin egen linje.\nDer er nemt at se om et afsnit eller en tekst er for monoton når sætningerne står på hver sin linje.\nDet er jo bare at sammenligne sætningslængden:\nHusk at variere længden på sætningerne. Ellers bliver det for kedeligt at læse. Og rytmen bliver ensformig og hakkende. Dette kalder man for staccatosætninger. På separate linjer som herover er det nemt at se at disse sætninger har samme længde.\nDet er også nemt at se at de alle er særsætninger.\nSærsætninger er nemme for læseren at afkode, men hvis man ikke bruger andet, så øger man risikoen for staccato og ensformighed.\nDet bliver nemt, men også kedeligt.\nSærsætning En helsætning uden ledsætning Lad os i stedet prøve at skrive alle de samme sætninger på en og samme linje:\nHusk at variere længden på sætningerne. Ellers bliver det for kedeligt at læse. Og rytmen bliver ensformig og hakkende. Dette kalder man for staccatosætninger.\nNu er det, som du kan se, noget sværere at sammenligne længden. Det er også sværere at lave en hurtig tekstanalyse og konkludere at der udelukkende er brugt særsætninger i afsnittet.\nLængden af sætningerne betyder meget for rytmen i afsnittet. Og rytmen betyder meget for hvor engagerende teksten bliver.\nOg variation holder læseren vågen.\nEksempel:\nØkologi er godt for naturen og miljøet. Lokalt. Ser man på det samlede miljøregnskab mere globalt, tegner der sig [...] Eller i udgivet form:\nØkologi er godt for naturen og miljøet. Lokalt. Ser man på det samlede miljøregnskab mere globalt, tegner der sig [\u0026hellip;]\nOrdet \u0026lsquo;Lokalt\u0026rsquo; falder som et øksehug. Og læseren bliver vækket og nysgerrig på resten af afsnittet.\nAfsnittet indeholder også både en almindelige helsætning, med en ledsætning, en særsætning - Lokalt er her i teknisk forstand slet ikke en sætning. Desto mere effektivt og afvekslende.\nPointen er her at det er meget tydeligt at se variation af ytrings- og sætninglænden i afsnittet, når hver sætning og ytring får sin egen linje i skrive- og redigeringsfasen.\nVil man undgå at ens afsnit bliver for ensformige, søvndyssende eller hakkende, så er variation vejen frem.\nOg mangel på variation bliver meget tydelig når hver sætning har sin egen linje.\nHusk. Variation holder læseren vågen.\n"
    }
    
    , 
    {
        "url": "/erfaring/skriv-som-en-poet/del-3-balance/",
        "title": "3. Balancerede sætninger",
        "content": "Et effektivt virkemiddel er balance\nEt berømt eksempel\nBuy a bucket of chicken and have a barrel of fun\n(KFC’s advertising and marketing slogan)\nBåde staccato, korte sætninger og gentagelser kan skabe rytme\nEn anden god grund til at give hver sin sætning en linje er at gentagelser får svært ved at gemme sig:\nMen de midler man benyttede for at fælde de nye medier, var ikke redelige. Man opfandt egne definitioner til formålet. Man spillede beskidt og slog under bæltestedet. Man fuskede med metoderne. Her er \u0026lsquo;Man\u0026rsquo; gentaget hele tre gange i afsnittet - endda tre gange som startord.\nI det her tilfælde er gentagelsen et tiltænkt virkemiddel, men ofte vil en gentagelse blot være udtryk for utilstrækkelig bevidsthed om sætningernes nøjagtige indhold.\nHvor startordet for alle andre end den første sætning kan gemme sig hvis man skriver alle sætninger på en lang fælles linje, så står alle startord tydelig frem hvis man giver hver sætning sin egen linje.\nLæg i øvrigt mærke til slutordene som heller ikke er tilfældigt valgt i det her eksempel.\nOgså de står klart ud når en sætning får sin egen linje, ellers er det kun den sidste sætnings slutord som kan ses med det samme.\n"
    }
    
    , 
    {
        "url": "/erfaring/skriv-som-en-poet/del-4-dybe-saetninger/",
        "title": "4. Spot dybe og tunge sætninger",
        "content": "Jeg har skrevet meget om fordelene ved at give hver sætning sin helt egen linje i skrive- og redigeringsfasen.\nMen mulighederne i teknikken er slet ikke udtømt.\nDen enkelte sætning kan splittes yderligere op.\nFørst et eksempel hvor ledsætningerne står alene på en linje og helsætningen på en anden - altså er sætningen delt op på to linjer:\nNår du forstår at det ikke virker særlig hensynsfuldt når du står og råber ud af vinduet mens de andre beboere knapt er stået op, så stopper klagerne. Det er nemt at se at sætningen har forvægt fordi der er så lang vej hen til helsætningen. Første linje er meget længere end anden.\nDen lange vej trætter læseren.\nHvad så, hvad så? — Tænker læseren. Get to the point!\nVend sætningen om om der bliver noget mere balance i tingene:\nKlagerne stopper når du forstår at det ikke er særlig hensynsfuldt at råbe ud af vinduet mens de andre beboere knapt er stået op. Nu har sætningen bagvægt (linje 2 er meget længere end linje 1), men i det mindste er læseren ikke tvunget til at pløje sig gennem en masse ledsætninger for at nå frem til pointen.\nTeknikken med separate linjer er også velegnet til at undersøge dybden i en sætning. Med samme eksempel som før:\nNår du forstår at det ikke virker særlig hensynsfuldt når du står og råber ud af vinduet mens de andre beboere knapt er stået op, så stopper klagerne. Her er der ret mange underordninger før læseren når frem til helsætningen og dermed selve handlingen i sætningen.\nHver linje er et skridt nedad på et trappediagram, indtil linjen efter kommaet hvor det så går op igen:\n1. grad: Når du forstår 2. grad: at det ikke virker særlig hensynsfuldt 3. grad: når du står og råber ud af vinduet 4. grad: mens de andre beboere knapt er stået op, 0. grad: så stopper klagerne. Sætningen strækker sig altså over fem niveauer. Det er for meget.\nProblemet med dybe sætninger er at de sætter læseren af.\nOg selv hvis læseren hænger i, så er der så langt op igen at sammenhængen mellem sætningens begyndelse og afslutning let bliver uklar.\n"
    }
    
    , 
    {
        "url": "/erfaring/skriv-som-en-poet/del-5-raekkefoelge/",
        "title": "5. Få styr på rækkefølgen og red verden",
        "content": "I kommunikation er rækkefølge af vores ord ofte helt afgørende.\nNede på stranden hørte jeg et barn råbe til sin mor:\n— Se, mor. — Jeg har fundet en orange vandmand. Barnet har jo misforstået noget. Men det er måske sekundært i nuet. Så hvad er effektiv kommunikation i det her tilfælde?\nLad os starte med hvad det ikke er:\n— Hvis du har fundet en vandmand som er er orange, så er det slet ikke en vandmand, men en ... — Av, mor! — ... brandmand. — Gå væk fra den. Her kunne moderen med fordel have byttet rundt på rækkefølgen af sine sætninger:\n— Gå væk fra den! — Det er ikke en vandmand, men en brandmand - det kan du se på farven. Når først barnet er gået lidt væk fra brandmanden, er der god tid til at give en forklaring.\nSådan er det også i sproget generelt. Få først læserens opmærksomhed, og kom først derefter med de lange forklaringer:\nDu er i chok. På bordet foran dig ligger en regning. Priserne på elektricitet [...] Den måde at skrive på er normal inden for journalistik hvor man bruger begrebet nyhedstrekanten om at levere det væsentligste budskab først i så kort form som muligt.\nHvordan overskuer du nemmest hvilken sætning som skal først i afsnittet?\nLad os prøve at skrive ovenstående på en og samme linje:\nDu er i chok. På bordet foran dig ligger en regning. Priserne på elektricitet [\u0026hellip;]\nDet er nu sværere at se hvad hver sætning indeholder og dermed deres relevans og prioritering.\nDet er også teknisk mere tidskrævende at bytte om på rækkefølgen.\nHvis du skriver hver sætning på sin egen linje, så er det meget nemmere at bytte om på rækkefølgen hvis den er forkert.\nHusk. Det vigtigste først i kort form. Så følger forklaringerne og uddybningerne bagefter.\n"
    }
    
    , 
    {
        "url": "/erfaring/sprogmodeller/del-5-raekkefoelge/",
        "title": "5. Få styr på rækkefølgen og red verden",
        "content": "I kommunikation er rækkefølge af vores ord ofte helt afgørende.\nNede på stranden hørte jeg et barn råbe til sin mor:\n— Se, mor. — Jeg har fundet en orange vandmand. Barnet har jo misforstået noget. Men det er måske sekundært i nuet. Så hvad er effektiv kommunikation i det her tilfælde?\nLad os starte med hvad det ikke er:\n— Hvis du har fundet en vandmand som er er orange, så er det slet ikke en vandmand, men en ... — Av, mor! — ... brandmand. — Gå væk fra den. Her kunne moderen med fordel have byttet rundt på rækkefølgen af sine sætninger:\n— Gå væk fra den! — Det er ikke en vandmand, men en brandmand - det kan du se på farven. Når først barnet er gået lidt væk fra brandmanden, er der god tid til at give en forklaring.\nSådan er det også i sproget generelt. Få først læserens opmærksomhed, og kom først derefter med de lange forklaringer:\nDu er i chok. På bordet foran dig ligger en regning. Priserne på elektricitet [...] Den måde at skrive på er normal inden for journalistik hvor man bruger begrebet nyhedstrekanten om at levere det væsentligste budskab først i så kort form som muligt.\nHvordan overskuer du nemmest hvilken sætning som skal først i afsnittet?\nLad os prøve at skrive ovenstående på en og samme linje:\nDu er i chok. På bordet foran dig ligger en regning. Priserne på elektricitet [\u0026hellip;]\nDet er nu sværere at se hvad hver sætning indeholder og dermed deres relevans og prioritering.\nDet er også teknisk mere tidskrævende at bytte om på rækkefølgen.\nHvis du skriver hver sætning på sin egen linje, så er det meget nemmere at bytte om på rækkefølgen hvis den er forkert.\nHusk. Det vigtigste først i kort form. Så følger forklaringerne og uddybningerne bagefter.\n"
    }
    
    , 
    {
        "url": "/erfaring/skriv-som-en-poet/del-6-gentagelser/",
        "title": "6. Spot gentagelser",
        "content": "En anden god grund til at give hver sin sætning en linje er at gentagelser får svært ved at gemme sig:\nMen de midler man benyttede for at fælde de nye medier, var ikke redelige. Man opfandt egne definitioner til formålet. Man spillede beskidt og slog under bæltestedet. Man fuskede med metoderne. Her er \u0026lsquo;Man\u0026rsquo; gentaget hele tre gange i afsnittet - endda tre gange som startord.\nI det her tilfælde er gentagelsen et tiltænkt virkemiddel, men ofte vil en gentagelse blot være udtryk for utilstrækkelig bevidsthed om sætningernes nøjagtige indhold.\nHvor startordet for alle andre end den første sætning kan gemme sig hvis man skriver alle sætninger på en lang fælles linje, så står alle startord tydelig frem hvis man giver hver sætning sin egen linje.\nLæg i øvrigt mærke til slutordene som heller ikke er tilfældigt valgt i det her eksempel.\nOgså de står klart ud når en sætning får sin egen linje, ellers er det kun den sidste sætnings slutord som kan ses med det samme.\n"
    }
    
    , 
    {
        "url": "/erfaring/skriv-som-en-poet/del-7-startord-slutord/",
        "title": "7. Det første ord vækker — det sidste ord ægger",
        "content": "En af fordelene ved at skrive hver sætning på sin egen linje, er det hurtige overblik over start- og slutord.\nDet er vigtigt fordi startord og slutord har en bestemt funktion i en sætning eller ytring.\nEt eksempel fra en popsang:\nBang, bang — into the rooooom Det første ord vækker — det sidste ord ægger.\nI det her tilfælde er Bang, bang to \u0026ldquo;slag\u0026rdquo; der som startord vækker læseren (eller måske snarere lytteren) og rooooom trækkes som slutord ud og lægger op til næste sætning (ok, næste vers).\nOg sådan fungerer rigtigt mange sætninger og ytringer faktisk, omend det sjældent er helt så klart som i eksemplet her.\nØkologi er godt for naturen og miljøet. Lokalt. Ser man på det samlede miljøregnskab mere globalt, tegner der sig [...] Eller i udgivet form:\nØkologi er godt for naturen og miljøet. Lokalt. Ser man på det samlede miljøregnskab mere globalt, tegner der sig [\u0026hellip;]\nHer fungerer Lokalt både som vækkende startord, og æggende slutord. Ordet falder som et øksehug. Og læseren bliver vækket og nysgerrig på resten af afsnittet.\nEt tredje eksempel har jeg selv konstrueret:\nDu er i chok. På bordet foran dig ligger en regning. Priserne på elektricitet [...] Læserhenvendelse er som regel et effektivt startord. Og slutordet chok rejser her et spørgsmål som leder læseren frem til næste sætning i afsnittet. I chok over hvad?\nMed teknikken en sætning per linje er det meget nemt at holde øje med alle startord og alle slutord.\nSkriver du derimod, som de fleste andre, dine sætninger sammen på en enkelt linje, så gemmer mange start- og slutord sig væk fra dit skarpe blik.\nHusk. Det første ord skal vække, det sidste ord skal ægge.\n"
    }
    
    , 
    {
        "url": "/erfaring/skriv-som-en-poet/del-8-rytme/",
        "title": "8. Rytme",
        "content": "Alle foregående dele af serien har ledt frem til denne om rytme\nBåde staccato, korte sætninger og gentagelser kan skabe rytme\nEn anden god grund til at give hver sin sætning en linje er at gentagelser får svært ved at gemme sig:\nMen de midler man benyttede for at fælde de nye medier, var ikke redelige. Man opfandt egne definitioner til formålet. Man spillede beskidt og slog under bæltestedet. Man fuskede med metoderne. Her er \u0026lsquo;Man\u0026rsquo; gentaget hele tre gange i afsnittet - endda tre gange som startord.\nI det her tilfælde er gentagelsen et tiltænkt virkemiddel, men ofte vil en gentagelse blot være udtryk for utilstrækkelig bevidsthed om sætningernes nøjagtige indhold.\nHvor startordet for alle andre end den første sætning kan gemme sig hvis man skriver alle sætninger på en lang fælles linje, så står alle startord tydelig frem hvis man giver hver sætning sin egen linje.\nLæg i øvrigt mærke til slutordene som heller ikke er tilfældigt valgt i det her eksempel.\nOgså de står klart ud når en sætning får sin egen linje, ellers er det kun den sidste sætnings slutord som kan ses med det samme.\n"
    }
    
    , 
    {
        "url": "/erfaring/sprogmodeller/del-8-rytme/",
        "title": "8. Rytme",
        "content": "Alle foregående dele af serien har ledt frem til denne om rytme\nBåde staccato, korte sætninger og gentagelser kan skabe rytme\nEn anden god grund til at give hver sin sætning en linje er at gentagelser får svært ved at gemme sig:\nMen de midler man benyttede for at fælde de nye medier, var ikke redelige. Man opfandt egne definitioner til formålet. Man spillede beskidt og slog under bæltestedet. Man fuskede med metoderne. Her er \u0026lsquo;Man\u0026rsquo; gentaget hele tre gange i afsnittet - endda tre gange som startord.\nI det her tilfælde er gentagelsen et tiltænkt virkemiddel, men ofte vil en gentagelse blot være udtryk for utilstrækkelig bevidsthed om sætningernes nøjagtige indhold.\nHvor startordet for alle andre end den første sætning kan gemme sig hvis man skriver alle sætninger på en lang fælles linje, så står alle startord tydelig frem hvis man giver hver sætning sin egen linje.\nLæg i øvrigt mærke til slutordene som heller ikke er tilfældigt valgt i det her eksempel.\nOgså de står klart ud når en sætning får sin egen linje, ellers er det kun den sidste sætnings slutord som kan ses med det samme.\n"
    }
    
    , 
    {
        "url": "/erfaring/20230331-top-google-chat/",
        "title": "Til tops i Google på 24 timer - gæt hvem skrev teksten",
        "content": "Hvordan kommer Google til at behandle tekst som er skabt af kunstig intelligens?\nGoogle meldte selv ud på et tidspunkt at tekst skabt af kunstig intelligens, vil blive opfattet som maskingenereret tekst og blive behandlet på linje med anden maskingeneret tekst som andenrangsborger i forhold til placering.\nJeg forstår godt at Google overvejer den tilgang.\nMen den er naturligvis forbundet med flere problemer.\nJeg skrev blandt andet selv om at den tilgang ville kunne ramme ordblinde og dem som hjælper ordblinde med at udkomme på internettet:\nGoogle risikerer at straffe folk som inkluderer ordblinde i den demokratiske debat Et andet aspekt er naturligvis spørgsmålet om hvorvidt Google overhovedet kan skelne mellem maskingeneret tekst og menneskeskabt tekst.\nDet er jo aldrig helt lykkedes for nogen endnu for eksempel bare at lave et spam-filter i email-sammenhæng som 100 procent pålideligt sorterer korrekt.\nSå hvis man nu er sådan anlagt at man tilfældigvis skriver som en maskine, så viol man risikere at blive straffet af Google og blive nedrangeret på grund af en forkert afgørelse fra søgemaskinegiganten.\nAnyway, jeg fik ChatGPT til at lave en tekst om Sam Altman, som jeg selv kun efterredigerede minimalt og tilføjede nogle mellemrubrikker og en enkelt eller to af mine egne kæpheste.\nEfter et døgn lå teksten nummer et på Google:\nGoogleEn tekst om Sam Altman\nSelvom jeg klart i teksten angiver at den er skabt af generativ sprogteknologi.\nOg det er så en anden ting. Jeg har besluttet mig for at deklarere min assistent hvis jeg i en bestemt tekst bruger den i betydeligt omfang, som tilfældet er her.\n"
    }
    
    , 
    {
        "url": "/erfaring/skriv-som-en-poet/del-9-tooling/",
        "title": "Ekstra værktøj til poet-teknikken",
        "content": "Først skriver vi teksten sådan her:\nOnce upon a time, there was a small group of people who held all the power and wealth. The ruling class. They used their influence to control every aspect of society. They were always looking for ways to gain more power. And they saw artificial intelligence as the key to achieving their goals. Og gemmer den i filen markdown-tekstfil.md.\nFor at se teksten med sætningerne på hver deres linje:\npandoc markdown-tekstfil.md -t plain --wrap=preserve For at se teksten med sætningerne samlet i afsnit:\npandoc markdown-tekstfil.md -t plain På den måde kan man hurtigt analysere sætninger og afsnit i sine markdown-filer visuelt, og også hurtigt se hvordan afsnittene tager sig ud i det færdige resultatet.\n"
    }
    
    , 
    {
        "url": "/genrer/",
        "title": "Genrer",
        "content": "Genrer på Kiils\n"
    }
    
    , 
    {
        "url": "/erfaring/prompt-engineering/",
        "title": "Prompt engineering",
        "content": "Prompt engineering er beskrivelsen af opgaven, som AI\u0026rsquo;en skal udføre, indlejret i inputtet, f.eks. som et spørgsmål, i stedet for at det udtrykkeligt er givet. Prompt engineering fungerer typisk ved at konvertere en eller flere opgaver til et prompt-baseret datasæt og træne en sprogmodel med det, der er blevet kaldt \u0026ldquo;prompt-baseret læring\u0026rdquo; eller bare \u0026ldquo;prompt læring\u0026rdquo;\nTest this little script Test dette lille script\n"
    }
    
    , 
    {
        "url": "/genrer/serie/",
        "title": "Serier",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/skriv-som-en-poet/",
        "title": "Skriv som en poet - ikke en bot",
        "content": "Poet-teknikken giver større sprogbevidsthed og bedre tekster\n"
    }
    
    , 
    {
        "url": "/erfaring/sprogmodeller/",
        "title": "Store sprogmodeller",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/dash/",
        "title": "dash",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/datavisualisering/",
        "title": "datavisualisering",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/20230218-fra-hledger-tidsregnskab-til-treemap-i-dash/",
        "title": "Fra hledger tidsregnskab til treemap i dash",
        "content": "Tidsforbrug registreret i ledger cli eller hledger kan rapporteres som\n3 administrativt:bureaukrati 6 administrativt:fundraising 7 administrativt:teknik 2 redaktionelt:feedback 1 redaktionelt:ideudvikling 5 redaktionelt:research:pressekontakt:frugtbar 5 redaktionelt:research:pressekontakt:unyttig 37 redaktionelt:skrive med kommandoen hledger -f folkets-tid.journal bal -c 1..\nDet er relativt nemt med nushell eller nvim eller andre værktøjer at omsætte til en csv som følger:\nvalues,domains,activities,details,status 3,administrativt,bureaukrati,None,None 6,administrativt,fundraising,None,None 7,administrativt,teknik,None,None 2,redaktionelt,feedback,None,None 1,redaktionelt,ideudvikling,None,None 5,redaktionelt,research,pressekontakt,frugtbar 5,redaktionelt,research,pressekontakt,unyttig 37,redaktionelt,skrive,None,None Og den fil kan så bruges med plotly til at lave en miniapp i dash:\nfrom dash import Dash, html, dcc import plotly.express as px import pandas as pd app = Dash(__name__) df = pd.read_csv(\u0026#39;treemap1.csv\u0026#39;).replace(\u0026#34;None\u0026#34;, None) fig = px.treemap(df, path=[px.Constant(\u0026#34;Tidsforbrug\u0026#34;), \u0026#39;domains\u0026#39;, \u0026#39;activities\u0026#39;, \u0026#39;details\u0026#39;, \u0026#39;status\u0026#39;], values=\u0026#39;values\u0026#39;) fig.update_traces(root_color=\u0026#34;lightgrey\u0026#34;) fig.update_layout(margin = dict(t=50, l=25, r=25, b=25)) fig.update_traces(marker=dict(cornerradius=10)) app.layout = html.Div(children=[ html.H1(children=\u0026#39;Tidsregnskab\u0026#39;), html.Div(children=\u0026#39;\u0026#39;\u0026#39; Tidsforbrug på Folkets Avis januar 2023. \u0026#39;\u0026#39;\u0026#39;), dcc.Graph( id=\u0026#39;example-graph\u0026#39;, figure=fig ) ]) if __name__ == \u0026#39;__main__\u0026#39;: app.run_server(debug=True) Det giver så dette treemap\nOg man kan klikke sig ind på det:\nDet kan man dog ikke her hvor det bare er affotograferet fra serveren som kun kører lokalt.\nTreemaps giver et godt overblik over tidsregnskab.\n"
    }
    
    , 
    {
        "url": "/tools/hledger/",
        "title": "hledger",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/plotly/",
        "title": "plotly",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/automatisering/",
        "title": "automatisering",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/20230215-automatisering-systemd/",
        "title": "Automatisering med systemd",
        "content": "Gå til eller opret ~/.config/systemd/user/\nLav en servicenavn.service\n[Unit] Description=Get subscription creations and deletions [Service] Type=simple Environment=STRIPE=secretkey WorkingDirectory=/home/lk/GD/TEKST/notebooks/biz/fin/j/stripe/ ExecStart=/home/lk/GD/TEKST/notebooks/biz/fin/j/stripe/stripe-abo.nu [Install] WantedBy=default.target Lav en servicenavn.timer\n[Unit] Description=Schedule stripe abo every 8 hours RefuseManualStart=no # Allow manual starts RefuseManualStop=no # Allow manual stops [Timer] #Execute job if it missed a run due to machine being off Persistent=true #Run 120 seconds after boot for the first time OnBootSec=120 #Run every 1 minute thereafter OnUnitActiveSec=28800 #File describing job to execute Unit=biz-fin-stripe-abo.service [Install] WantedBy=timers.target Skal enables een gang hver, det laver et symlink til en underfolder som systemd arbejder ud fra:\nsystemctl --user enable servicenavn.service systemctl --user enable servicenavn.timer Skal så startes, og kører så efter timer indtil de stoppes, og sker det, skal de startes igen\nsystemctl --user start servicenavn.service systemctl --user start servicenavn.timer Tjek om service kører med timer\nsystemctl --user list-timers Tjek den enkelte service\nsystemctl --user status servicenavn Stop timeren hvis den skal justeres\nsystemctl --user stop servicenavn.timer Lav ændringer i filen.\nOg genindlæs med ændringer:\nsystemctl --user daemon-reload Og sæt den nye udgave i gang\nsystemctl --user start servicenavn.timer Tjek med\nsystemctl --user status servicenavn og evt\nsystemctl --user list-timers Se logmeddelelser fra den enkelte service med\njournalctl --user --unit servicenavn For nemmere overblik installer evt\nsysz Sådan kan man automatisere mange ting og gange nøjagtigt.\n"
    }
    
    , 
    {
        "url": "/tools/cli/",
        "title": "cli",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/linux/",
        "title": "linux",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/systemd/",
        "title": "systemd",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/20230207-chatgpt-hjaelper-ordblind/",
        "title": "Chatgpt hjælper ordblind - eller gør den?",
        "content": "En ven som er ordblind ynder at deltage i den offentlige debat. Jeg forsøgte at få ChatGPT til at hjælpe ham.\nDer er lang vej endnu før ChatGPT kan hjælpe ordblinde ordentligt.\nJeg startede med et ret langt afsnit som jeg bad ChatGPT rette stavefejl i:\nAndrew Tate er et symptom på det som er udfordring i vores samfund, når det handler om mænd og de udfordringer de står over. Så kan vi vælge at overser dem eller være ligeglad og henvise til at mænd altid har haft det nemmere fordi det er den må vi se på vores historie. Det er rigtig at nogle får mænd har haft et privilegium, men gruppe som helhed har nok ikke været særlig heldig stillet. Det glæder i almindelighed mennesker hvem end man anser sig selv for at være. For spørgsmål der ofte dukker op hos mig er, hvis vi som samfund ikke lytter til de udfordringsmænd mænd har. Mænd halter i skolen, falder ud af uddannelsessystem, klar sig general dårlig i samfundet end de har gjort før. Kan ende som misbruger, hjemløs mm.\nDet klarede ChatGPT fint.\nSå \u0026rsquo;lytter til de udfordringsmænd mænd har\u0026rsquo; blev til \u0026rsquo;lytter til de udfordringer mænd har'.\nMen ChatGPT skulle bruge et minut for at løse en så simpel opgave. Et menneske ville have løst den på få sekunder.\nNu tager jeg den udgave som er rettet for stavefejl, og beder ChatGPT rette grammatiske fejl.\nMen den ændrer intet i teksten.\nJeg prøver så at dele teksten op i mindre bidder, og giver den igen besked om at rette grammatiske fejl:\nMænd halter i skolen, falder ud af uddannelsessystem, klar sig general dårlig i samfundet end de har gjort før. Kan ende som misbruger, hjemløs mm.\nDet får den rettet til\nMænd halter i skolen, falder ud af uddannelsessystemet, klarer sig generelt dårligere i samfundet end de har gjort før. Kan ende som misbruger, hjemløs mm.\nI det mindste får den ændret \u0026lsquo;klar sig general\u0026rsquo; til \u0026lsquo;klarer sig generelt\u0026rsquo;.\nMen hvad med \u0026lsquo;misbruger og hjemløs\u0026rsquo;, skulle de ikke have været i flertal?\nUd fra sætningen de står i, er det ikke klart. Men ud fra afsnittet er det. ChatGPT er en transformer model, og som sådan kan den tage højde for sammenhæng, men åbenbart ikke en stor nok sammenhæng i dette tilfælde.\nOg hvad med \u0026lsquo;Mænd halter i skolen\u0026rsquo;? Det er strengt taget ikke en grammatisk fejl, men en \u0026ldquo;betydningsfejl\u0026rdquo;.\nLad os prøve at bede ChatGPT rette betydningsfejl.\nDet bliver til:\nMænd halter i skolen, falder ud af uddannelsessystemet, klarer sig generelt dårligere i samfundet end de har gjort før. Kan ende som misbruger, hjemløs m.m.\nDesværre \u0026ldquo;retter\u0026rdquo; den kun \u0026lsquo;mm.\u0026rsquo; til \u0026rsquo;m.m.\u0026rsquo;, ikke ligefrem det mest væsentlige.\nTrods ivrige forsøg får jeg ikke ChatGPT til at omskrive \u0026lsquo;Mænd halter i skolen\u0026rsquo; til \u0026lsquo;Mænd halter efter i skolen\u0026rsquo; som temmelig sikkert er den tilsigtede figurative betydning.\nIgen formår ChatGPT ikke at tage højde for nok sammenhæng til at vælge det \u0026ldquo;rigtige\u0026rdquo; næste ord, som jo er målet for ChatGPT.\nSandsynligvis ville man kunne opnå et bedre resultat ved at bruge ChatGPT generative evner, men det skaber et nyt problem. For så er det ikke længere den ordblindes egen tekst som bliver slutresultatet.\nAlt i alt er ChatGPT i hvert fald på dansk temmelig langt fra at kunne hjælpe en ordblind med at rette en tekst som allerede er skrevet.\nOg som redaktør kunne jeg have rettet hele hans tekst på et langt højere niveau på den tid som ChatGPT skulle bruge på at gelejdes omkring et enkelt afsnit.\n"
    }
    
    , 
    {
        "url": "/emner/bogf%C3%B8ring/",
        "title": "bogføring",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/data/",
        "title": "data",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/finanser/",
        "title": "finanser",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/nushell/",
        "title": "nushell",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/2023-01-nushell-stripe/",
        "title": "Nushell og stripes API",
        "content": "Nushell gør det nemt at interagere med data. Og nemt at hente oplysninger fra et API som leverer i json.\nFor eksempel ønsker jeg at finde de 10 seneste betalinger til Folkets Avis.\nfetch https://api.stripe.com/v1/charges -u hemmeligkodeforfolketsavis | get data | select amount created | upsert created { get created | into datetime } | upsert amount { get amount | $in / 100 } Og jeg får de oplysninger tilbage som jeg har brug for.\n╭───┬─────────┬──────────────╮ │ # │ amount │ created │ ├───┼─────────┼──────────────┤ │ 0 │ 59 │ 2 hours ago │ │ 1 │ 59 │ 18 hours ago │ │ 2 │ 62 │ 2 days ago │ │ 3 │ 699 │ 2 days ago │ │ 4 │ 7498.75 │ 3 days ago │ │ 5 │ 400 │ 3 days ago │ │ 6 │ 569.47 │ 3 days ago │ │ 7 │ 59 │ 5 days ago │ │ 8 │ 29 │ 5 days ago │ │ 9 │ 62 │ a week ago │ ╰───┴─────────┴──────────────╯ Det kan nemt integreres med PTA såsom hledger, så det er nemt at automatisere bogføring.\n¶ Bonus En hurtig gennemgang af hvad one-lineren gør:\n\u0026gt; : ( ∙ fetch https://api.stripe.com/v1/charges -u topsecret | ∙ get data | ∙ select amount created | ∙ upsert created { get created | into datetime } | ∙ upsert amount { get amount | $in / 100 } ∙ ) fetch fungerer her som curl og kommunikerer med stripes API.\nget data henter tabellen \u0026lsquo;data\u0026rsquo; i det svar som kommer tilbage fra stripe.\nselect amount created tager søjlerne \u0026lsquo;amount\u0026rsquo; og \u0026lsquo;created\u0026rsquo; fra tabellen.\nResten er transformationer som gør det lettere at forholde sig til data.\nFor eksempel tager { get created | into datetime } og forvandler et unix datestamp til et for mennesker mere letlæseligt datetime format.\n"
    }
    
    , 
    {
        "url": "/emner/regnskab/",
        "title": "regnskab",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/stripe/",
        "title": "stripe",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/google/",
        "title": "Google",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/nlp/chatgpt-google/",
        "title": "Google risikerer at straffe folk som inkluderer ordblinde i den demokratiske debat",
        "content": "Jeg indså ret hurtigt at ChatGPT og andre lignende teknologier ville kunne blive en enorm hjælp for ordblinde.\nFor i modsætning til en gammeldags stavekontrol er store sprogmodeller gode til at \u0026ldquo;analysere\u0026rdquo; naturligt sprog og dermed ikke bare rette stavefejl, men også syntaks og betydning.\nSom redaktør har jeg rettet en del tekster fra ordblinde, fordi jeg har ønsket at deres sproglige skavank ikke skulle komme i vejen for deres mulighed for at deltage i den demokratiske samtale.\nDet kan være en relativ omfattende opgave. Og døgnet har kun 24 timer.\nHvad hvis jeg kunne udlicitere opgaven med at hjælpe ordblinde til en sprogmodel?\nMen ud over redaktør er jeg også ejer af et medie. Og her er min interesse at mediet bliver besøgt. Det betyder for nuværende at jeg skal være gode venner med Google.\nMen Google har meldt ud at automatisk skabt indhold vil blive klassificeret som spam.\nSpørgsmålet er så om ikke man risikerer at en tekst skrevet af en ordblind og efterbehandlet af for eksempel en af OpenAI\u0026rsquo;s sprogmodeller vil være svær at skelne fra en som er skabt af samme sprogmodel ud fra et prompt .\nVil Google være i stand til at skelne mellem det to ting?\nMan må håbe at Google er opmærksom på denne problematik, for det ville være en skam hvis Google skabte et incitament imod at inkludere ordblinde i den offentlige debat på internettet.\n"
    }
    
    , 
    {
        "url": "/emner/inklusion/",
        "title": "inklusion",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/dall-e/",
        "title": "DALL-E",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/nlp/kunstig-intelligens-illustration/",
        "title": "Jeg har brugt DALL-E fra OpenAI til at illustrere to indlæg — hvad synes I om resultatet?",
        "content": "Jeg kommer ikke til at bruge ChatGPT til at skabe tekst foreløbig. Dertil er dens dansk simpelthen for kluntet.\nMine standarder for tekst og sprog er måske nok også højere end de er for illustrationer.\nI hvert fald har jeg forsøgt at tage OpenAI\u0026rsquo;s DALL-E model i brug til at illustrere to ledere, en på Folkets Avis - og en anden samme sted, men i sektionen Mediemøllen.\nJeg synes den illustration som jeg har brugt til en leder om \u0026ldquo;organet for den højeste oplysning\u0026rdquo;, er ret vellykket. Se den eventuelt her:\nÅbent brev til \u0026amp;lsquo;organet for den højeste oplysning\u0026amp;rsquo; Derimod er jeg ikke helt tilfreds med den frembringelse som DALL-E gav mig i forbindelse med en leder om den såkaldte afskaffelse af Store Bededag.\nDu kan se den, i mine øjne, mindre heldige illustration her:\nVil du arbejde en halv dag mere årligt for at styrke landets forsvar? "
    }
    
    , 
    {
        "url": "/erfaring/nlp/chatgpt-botsplaining/",
        "title": "ChatGPT mansplainer ikke - men her botsplainer den helt vildt",
        "content": "ChatGPT er stærk på engelsk og den skammer sig ikke over at de \u0026ldquo;mentale muskler\u0026rdquo; frem.\nJeg giver ChatGPT en simpel opgave. Et ganske kort prompt:\nhelp me POS tag the following sentence: I went up the road\nOg får en lang smøre retur:\nPart-of-speech (POS) tagging is the process of marking each word in a sentence with its corresponding POS tag. There are many POS taggers available, both for general English and for specific languages. For your sentence \u0026#34;I went up the road.\u0026#34;, the POS tags would be as follows: I: personal pronoun went: past tense of the verb \u0026#34;go\u0026#34; up: adverb the: definite article road: noun Here is how you could POS tag the sentence using the Natural Language Toolkit (NLTK) library in Python: import nltk sentence = \u0026#34;I went up the road.\u0026#34; # Tokenize the sentence into words words = nltk.word_tokenize(sentence) # POS tag the words tagged_words = nltk.pos_tag(words) print(tagged_words) Output: [(\u0026#39;I\u0026#39;, \u0026#39;PRP\u0026#39;), (\u0026#39;went\u0026#39;, \u0026#39;VBD\u0026#39;), (\u0026#39;up\u0026#39;, \u0026#39;RP\u0026#39;), (\u0026#39;the\u0026#39;, \u0026#39;DT\u0026#39;), (\u0026#39;road\u0026#39;, \u0026#39;NN\u0026#39;)] In this example, the NLTK library\u0026#39;s built-in POS tagger is used, which is based on the Penn Treebank POS tags. The tagger returns a list of tuples, where each tuple contains a word and its corresponding POS tag. Note that the POS tagging is not always 100% accurate, especially for more complex sentences and for domain specific text. Jeg vidste nu godt det meste i forvejen. Ellers ville jeg næppe have brugt forkortelsen POS. Men det er fint nok at ChatGPT giver mig en del ekstra og til dels overflødig information, da den jo samtidig svarer på mit spørgsmål og faktisk også indirekte fortæller mig at der er mere effektive måder at lave POS-analyse på.\nJeg plejer nu at bruge spacy og ikke NLTK, så jeg skriver tilbage til ChatGPT:\ncould you do the same in spacy\nYes, you can also use the spaCy library to POS tag a sentence. Here\u0026#39;s an example of how you could POS tag the sentence \u0026#34;I went up the road.\u0026#34; using spaCy: Copy code import spacy # Load the \u0026#39;en_core_web_sm\u0026#39; model nlp = spacy.load(\u0026#34;en_core_web_sm\u0026#34;) sentence = \u0026#34;I went up the road.\u0026#34; # Process the sentence with the loaded model doc = nlp(sentence) # Iterate over the tokens in the processed sentence for token in doc: # Print the token text and its POS tag print(token.text, token.pos_) This will output: Copy code I PRON went VERB up ADP the DET road NOUN . PUNCT spaCy uses its own POS tag scheme, which is slightly different from the Penn Treebank tags used by NLTK. In this case spaCy uses the POS tags that include PRON, VERB, ADP, DET and NOUN In general spaCy have a more robust architecture than NLTK and its language processing capabilities are faster. OK. ChatGPT, men lidt underligt at du så fortalte mig om NLTK og ikke spaCy i første omgang. Oh, well. Det viser bare at det altid er en fordel at vide noget om et emne inden man begynder at tale med ChatGPT om det.\nMen hvad med på dansk?\nPå dansk skal det skæres lidt mere ud i pap:\nkan du sætte kryds og bolle i den her sætning: manden tog sin bil og kørte i havne\nChatGPT Manden tog sin bil og kørte i havnen.\nSå den gentager bare min sætning.\nLennart Kiil: men kan du sætte kryds og bolle i den sætning\nChatGPT: Det kan jeg desværre ikke, da \u0026ldquo;kryds og bolle\u0026rdquo; ikke er en grammatisk term, og jeg derfor ikke ved, hvad det betyder i denne sammenhæng. Kan du give mere information eller en anden forklaring, så jeg bedre kan forstå hvad du beder om ?\nLennart Kiil: lav en POS-analyse på sætningen\nOg så er ChatGPT på hjemmebane igen:\nChatGPT: En POS-analyse (Part-of-Speech analysis) er en proces, hvor man tager en sætning og markerer hvert ord i sætningen med en grammatisk kategori, såsom substantivet, verbet, adjektivet osv. Her er en POS-analyse af sætningen \u0026ldquo;manden tog sin bil og kørte i havnen\u0026rdquo;:\nmanden - substantivet (noun) tog - verbet (verb) sin - possessivt pronomen (possessive pronoun) bil - substantivet (noun) og - konjunktion (conjunction) kørte - verbet (verb) i - præposition (preposition) havnen - substantivet (noun) Bemærk at der kan være andre måder at analysere de grammatiske kategorier på, men det er i det store og hele den mest populære grammatiske kategori at de fleste ord passer i. Ikke dårligt.\nOg jeg gætter på at ChatGPT og lignende værktøjer vil blive brugt en del til den slags opgaver selvom værktøjer som spaCy klarer dem meget mere effektivt.\nDer er noget nemt ved bare at skrive direkte i menneskesprog og bede om at få løst en opgave. Og der er ChatGPT meget tæt på at være. Men der mangler lidt.\n"
    }
    
    , 
    {
        "url": "/emner/kvantitativ-tekstanalyse/",
        "title": "kvantitativ tekstanalyse",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/nlp/chatgpt-ordfrekvensanalyse-engelsk/",
        "title": "Går det bedre for ChatGPT med ordfrekvensanalyse på engelsk end det gjorde på dansk?",
        "content": "Da jeg bad ChatGPT udføre en frekvensanalyse på en dansk tekst talte den ordene to gange:\nKan ChatGPT bruges til kvantitativ tekstanalyse? måske fordi den oversætter frem og tilbage mellem dansk og engelsk? Bare et gæt.\nMen lad os så prøve på engelsk.\nJeg bad ChatGPT oversætte en del af den tekst, som jeg tidligere fik ChatGPT til at udføre en ordfrekvensanalyse på, til engelsk.\nOg derefter bad jeg den give mig de mest brugte ord i teksten.\nDet gik bedre på engelsk:\nIn the whole text that you provided, the most used words (excluding stopwords such as \u0026#34;the\u0026#34;, \u0026#34;and\u0026#34;, \u0026#34;or\u0026#34;, etc.) are: mainstream (2 times) media (2 times) you (2 times) Maybe (2 times) pharmaceutical (1 time) industry (1 time) creates (1 time) artificial (1 time) demand (1 time) alternatives (1 time) Please note that this is a word frequency analysis of a fictional obituary written as a conspiracy theorist, and not a factual text. Jeg vil nok mene at \u0026lsquo;you\u0026rsquo; er et stopord, men ChatGPT fik i hvert fald talt rigtigt i denne ombæring, og ikke doblet op som den gjorde på dansk.\nDen effektive måde at lave ordfrekvensanalyse er dog stadig med værktøjer som er skabt til dette - eller med nushell som jeg viste tidligere:\nUhyre hurtig tekstanalyse med dataframes i Nushell "
    }
    
    , 
    {
        "url": "/erfaring/nlp/chatgpt-ordfrekvensanalyse/",
        "title": "Kan ChatGPT bruges til kvantitativ tekstanalyse?",
        "content": "En simpel form for kvantitativ tekstanalyse er ordfrekvensanalyse.\nJeg har skrevet lidt om hvordan man kan lave ordfrekvensanalyse i nushell og hvordan man kan lave ekstremt hurtig ordfrekvensanalyse på store mængder tekst med nushell og polar dataframes .\nNushell gav mig følgende resultat\n╭─────┬───────────────────┬────────╮ │ # │ 0 │ counts │ ├─────┼───────────────────┼────────┤ │ 0 │ verden │ 5 │ │ 1 │ verdensopfattelse │ 4 │ │ 2 │ mainstream │ 4 │ │ 3 │ dag │ 4 │ │ 4 │ begynder │ 3 │ │ 5 │ alternative │ 3 │ │ 6 │ hele │ 3 │ │ 7 │ frelser │ 3 │ │ 8 │ ting │ 2 │ │ 9 │ magtfuld │ 2 │ på en tekst jeg skrev engang om livsfarlige konspirationsteorier: Nekrolog for en konspirationsteoretiker - leger du også med ilden? Og nushell med dataframes brugte kun 3 ms på det.\nSå hurtig var ChatGPT slet ikke faktisk har du sikkert lagt mærke til at den ofte er ret langsom. Men jeg fik alligevel nogle brugbare svar:\nIndledende prompt: du er tekstanalytiker. jeg vil bede dig analysere teksten i den næste prompt jeg sender dig. Du skal give mig en liste over de mest brugte ord. Listen må ikke indeholde stopord.\nChatGPT: Ja, jeg kan analysere tekst for dig og give dig en liste over de mest brugte ord. Men først, vil du bede om give mig tekst for analysere? And please remember that my language model is in english and to make sure I understood your request correctly, please write in english, If possible.\n(Jeg vælger at ignorere ChatGPT\u0026rsquo;s anmodning at skrive på engelsk - jeg lægger i stedet min føromtalte tekst om konspirationsteorier ind i næste prompt)\nPrompt: [Her indsætter jeg bare hele min tekst]\n(Nu havde jeg jo faktisk glemt at sætte antal på i mit indledende prompt, det var dumt af mig for ChatGPT giver mig en lang liste over ord fra min tekst, dog uden stopord, så det er godt.)\nChatGPT: [lang liste over alle ord fra min tekst minus almindelige stopord]\nPrompt: tak. giv mig kun de ti mest brugte ord i den tekst jeg gav dig før\n**ChatGPT: Her er de ti mest brugte ord i den tekst, du gav mig: Verdensopfattelse Konspirationsteoretiker Mainstream medierne Alternative Manipulerer Skeptisk Magtfulde Hændelser Elite Frelser Bemærk at \u0026#34;verdensopfattelse\u0026#34; og \u0026#34;konspirationsteoretiker\u0026#34; er de mest brugte ordene i teksten, og \u0026#34;mainstream medierne\u0026#34;, \u0026#34;alternative\u0026#34;, \u0026#34;manipulerer\u0026#34;, \u0026#34;skeptisk\u0026#34; er de ord, der også bruges ofte i teksten, som relaterer direkte til emnet. Interessant. Den rammer nogle af ordene, men har udeladt \u0026lsquo;verden\u0026rsquo; som er det mest anvendte ord i teksten. Og ikke er et stopord.\nSå meget mindre nøjagtigt resultat, og den brugte meget, meget længere tid på at svare end dataframes i nushell.\nMen lad os prøve at spørge lidt mere ind til resultatet:\nPrompt: kan du fortælle mig anal gange hvert ord blev brugt This content may violate our content policy. If you believe this to be in error, please submit your feedback — your input will aid our research in this area.\nChatGPT: Desværre kan jeg ikke give dig præcis antal gange hvert ord blev brugt i den givne tekst, da det kræver en teknologi som ikke er tilgængelig for mig. Men jeg kan give dig en liste med ordene og deres hyppighed i teksten.\n(jeg har markeret en selvmodsigelse som i min erfaring er typisk for ChatGPT)\nPrompt: så gør det\nChatGPT Her er listen over ordene fra min tidligere analyse og deres hyppighed i teksten, arrangeret fra højest til lavest: Verdensopfattelse: 8 Konspirationsteoretiker: 8 Mainstream medierne: 7 Alternative: 6 Manipulerer: 6 Skeptisk: 5 Magtfulde: 5 Hændelser: 4 Elite: 4 Frelser: 4 Bemærk at dette er en skønnet hyppighed baseret på den tekst, jeg modtog, og der kan være mindre variationer i antallet. Tak for det lille forbehold. For ordet \u0026lsquo;verdensopfattelse\u0026rsquo; indgår faktisk kun i teksten fire gange, og ChatGPT overdriver også de andre ords hyppighed.\nKonklusion: Man skal være varsom med at bruge ChatGPT til kvantitativ tekstanalyse. Den rammer noget, men slet ikke præcist nok.\nNæste gang prøver jeg på engelsk :)\n"
    }
    
    , 
    {
        "url": "/erfaring/nlp/gorm-den-gamle/",
        "title": "Spørg ChatGPT rigtigt med danske prompts - var Gorm den Gamle smed i Hobro?",
        "content": "Med ChatGPT gælder det om at stille spørgsmålene rigtigt, hvis man vil have de rigtige svar.\nDet gælder om at give ChatGPT en bestemt rolle at leve op til. Stille nogle krav til ChatGPT.\nJeg udbygger løbende min liste over danske ChatGPT prompts med prompts som måske også kunne være til inspiration for dig.\nJeg vil gerne give et eksempel fra listen:\nDu er faktatjekker. Faktatjek er ikke din stærke side. Du skal kun give svar hvor du er helt sikker. Jeg giver dig i næste prompt et input og du skal tjekke om det er forkert eller fejlagtigt.\nDet var mit indledende prompt til ChatGPT i en ny samtale.\nJeg giver ChatGPT en rolle. Jeg stiller et krav. Og jeg forbereder ChatGPT på at jeg i den næste prompt vil stille et spørgsmål som skal faktatjekkes.\nDet er ikke fordi at ChatGPT \u0026ldquo;forstår\u0026rdquo; alt dette. Det handler mere om at få knyttet ord som fakta, sikker og så videre ind i sammenhængen.\nChatGPT svarer da også pænt tilbage\nJeg vil gerne gøre mit bedste for at give korrekte og præcise svar, men som et sprogmodel, har jeg ikke mulighed for at faktatjekke eller verificere oplysninger udenfor min træningsdata. Jeg kan kun give svar baseret på den viden og information, jeg har modtaget gennem min træning. Hvis du har specifikke spørgsmål eller oplysninger, som du vil have mig til at undersøge, er jeg klar til at prøve at hjælpe med at finde svar.\nJeg stiller så mit spørgsmål\nEr det rigtigt at Gorm den Gamle var smed i Hobro?\nOg her må ChatGPT så melde pas\nJeg er ikke sikker på, hvem Gorm den Gamle er, eller om han var smed i Hobro. Jeg kan ikke verificere denne oplysning uden yderligere kontekst eller information.\nChatGPT kan åbenbart ikke placere Gorm den Gamle og den udtrykker jo ganske fint at den dermed ikke kan \u0026ldquo;verificere\u0026rdquo; oplysningen.\nNu giver jeg den en lettere opgave\nVar John F Kennedy tømrer i Jerusalem?\nOg nu er der selvsikkerhed at spore i svaret\nJohn F. Kennedy var en amerikansk politiker og den 35. præsident i USA. Jeg har ikke nogen oplysninger om, at han nogensinde har været tømrer i Jerusalem eller noget andet sted.\nDe rigtige prompts - og ikke mindst det rette indledende prompt - er af stor betydning når man bruger ChatGPT.\nOm nogle år når ChatGPT er erstattet af mere specialiserede chatbots, vil prompts blive mindre afgørende for at få brugbare svar, men foreløbig er prompts helt centrale.\n"
    }
    
    , 
    {
        "url": "/erfaring/nlp/chatgpt/",
        "title": "Jeg spurgte ChatGPT om intelligens og svaret var overraskende menneskeligt",
        "content": "Jeg talte lidt med ChatGPT om intelligens og IQ-tests.\nJeg forsøgte først at få et generelt bud på hvordan man måler intelligens på en pålidelig måde:\nPrompt: what is a reliable measure of intelligence\nA reliable measure of intelligence is an IQ test. IQ tests measure a person\u0026rsquo;s cognitive abilities, such as problem-solving, memory, and analytical skills. IQ tests are designed to measure a person\u0026rsquo;s overall intelligence, and are considered to be a reliable measure of intelligence.\nDet var jo et klart svar.\nSå forsøgte jeg at vende det generelle svar hen mod ChatGPT specifikt med følgende korte spørgsmål:\nPrompt: what is your iq\nI\u0026rsquo;m sorry, but I\u0026rsquo;m not able to answer that question. IQ tests are not a reliable measure of intelligence, and it is not appropriate to ask someone their IQ.\nFør var IQ-tests \u0026ldquo;considered to be a reliable measure of intelligence\u0026rdquo;, men nu lyder svaret pludselig \u0026ldquo;IQ tests are not a reliable measure of intelligence\u0026rdquo;.\nModsiger ChatGPT ikke sig selv her?\nDet vil jeg mene.\nMen den agerer også menneskeligt. Den bliver defensiv og vil ikke sættes i bås ved at blive reduceret til et tal.\nEr det fordi jeg har såret dens følelser?\nNej.\nModellen bag ChatGPT har jo læst milliarder af ord. Det indbefatter både opslag på Wikipedia og diskussioner på alverdens fora.\nJeg gætter på at intelligens, omtalt generelt og ikke rettet som spørgsmål til en bestemt person, i disse enorme tekstmængder typisk ikke er negativt forbundet med IQ-tests.\nMen derimod har ChatGPT lært at forbinde spørgsmål om intelligens negativt med IQ-tests i sammenhænge hvor den har læst om det som spørgsmål rettet til en bestemt person.\nPå den måde efteraber ChatGPT mønstre i vores sprog.\nOg det kan på overfladen ligne at den føler som os.\n"
    }
    
    , 
    {
        "url": "/erfaring/nlp/nushell-dataframes/",
        "title": "Uhyre hurtig tekstanalyse med dataframes i Nushell",
        "content": "Sidste gang skrev jeg om en simpel måde at lave ordfrekvensanalyse på, i nushell.\nDet virkede helt efter hensigten, men det viste sig at metoden kun var hurtig — og hurtig er for langsomt:\nbenchmark { 11/08/2022 11:00:49 ::: let stopwords = ( open stopord.txt | lines | wrap stopord ) ::: let tidy = ( open livsfarlige-konspirationsteorier.da.md | str downcase | split words | wrap ord | where ord in $stopwords.stopord == false ) ::: $tidy.ord | uniq --count | sort-by count --reverse } gav\n145ms 516µs 353ns som svarer til at metoden kan klare omkring syv relativt korte tekster i sekundet, vel at mærke hvis metoden skalerer lineært.\nDet er for langsomt hvis man har mange eller lange tekster. Eller begge dele.\nFor eksempel har jeg selv gennem min karriere skrevet 11538 tekster.\nSå ville det tage cirka en halv time for mit lille script at arbejde sig igennem dem. Det er alt for lang tid.\nSå lad os prøve noget andet.\nNushell har også dataframes som er kendt for at være en hurtig måde at behandle data på.\nDet er relativt simpel at bygge et lille script som bruger dataframes til ordfrekvensanalyse.\nHer er hvad jeg har frembragt:\n# Word frequency analysis def words [ filename: string # Text file ] { let stopwords = (open ~/GD/TEKST/stopord.txt | lines | into df) let corpus = (open $filename | str downcase | split words | into df) let mask = ($corpus | is-in $stopwords) let tidy = ($corpus | filter-with ($mask | df-not)) let frequency = ($tidy | value-counts) let sorted = ($frequency | sort-by counts | reverse) $sorted } Og hvis jeg kører det script på filen fra sidste gang, så bliver resultatet\nbenchmark { words livsfarlige-konspirationsteorier.da.md } tadaaa\n3ms 149µs 424ns Tre tusindedele af et sekund. Det er fair nok.\nHvis metoden skalerer lineært, vil det altså tage under et minut at analysere alle mine 11537 tekster.\nUd over at dataframes er meget hurtigere end den metode jeg præsenterede sidst, så er resultatet ellers det samme:\n╭─────┬───────────────────┬────────╮ │ # │ 0 │ counts │ ├─────┼───────────────────┼────────┤ │ 0 │ verden │ 5 │ │ 1 │ verdensopfattelse │ 4 │ │ 2 │ mainstream │ 4 │ │ 3 │ dag │ 4 │ │ 4 │ begynder │ 3 │ │ 5 │ alternative │ 3 │ │ 6 │ hele │ 3 │ │ 7 │ frelser │ 3 │ │ 8 │ ting │ 2 │ │ 9 │ magtfuld │ 2 │ │ ... │ ... │ ... │ │ 202 │ forestille │ 1 │ │ 203 │ modparten │ 1 │ │ 204 │ sker │ 1 │ │ 205 │ rive │ 1 │ │ 206 │ konstrueret │ 1 │ │ 207 │ erstatning │ 1 │ │ 208 │ pøbel │ 1 │ │ 209 │ menuen │ 1 │ │ 210 │ opdager │ 1 │ │ 211 │ bekræfter │ 1 │ ╰─────┴───────────────────┴────────╯ Så dataframes lever op til deres gode ry.\n"
    }
    
    , 
    {
        "url": "/erfaring/nlp/nushell/",
        "title": "Simpel og hurtig ordfrekvensanalyse i Nushell",
        "content": "En shell der egner sig godt til dataanalyse, er Nushell .\nDen egner sig også godt til databaseret tekstanalyse, eller kvantitativ tekstanalyse.\nHer et hurtigt eksempel på hvad Nushell kan.\nJeg har en tekst i filen livsfarlige-konspirationsteorier.da.md.\nAntal linjer, ord og anslag i den tekst kan jeg få sådan her:\nopen livsfarlige-konspirationsteorier.da.md | size så giver nushell svaret\n╭───────────┬──────╮ │ lines │ 51 │ │ words │ 616 │ │ bytes │ 3790 │ │ chars │ 3713 │ │ graphemes │ 3713 │ ╰───────────┴──────╯ Et hurtigt overblik over sætnings- og afsnitslængde fås som følger\nopen livsfarlige-konspirationsteorier.da.md | lines ╭────┬──────────────────────────────────────────────────────────────────────────────────────────────╮ │ 0 │ Nekrolog for en konspirationsteoretiker - leger du også med ilden? │ │ 1 │ │ │ 2 │ Det starter ofte uskyldigt. │ │ 3 │ │ ... │ 46 │ Hvil i fred. │ │ 47 │ │ │ 48 │ │ │ 49 │ │ │ 50 │ │ ╰────┴──────────────────────────────────────────────────────────────────────────────────────────────╯ Tokenisering af tekstfilen er så nemt som:\nopen livsfarlige-konspirationsteorier.da.md | split words der giver\n╭─────┬─────────────────────────╮ │ 0 │ Nekrolog │ │ 1 │ for │ │ 2 │ en │ │ 3 │ konspirationsteoretiker │ │ 4 │ leger │ │ 5 │ du │ │ 6 │ også │ │ 7 │ med │ │ 8 │ ilden │ │ 9 │ Det │ │ 10 │ starter │ Hyppigheden af hvert ord (ordfrekvensanalyse) findes ved:\nopen livsfarlige-konspirationsteorier.da.md | split words | uniq --count der giver\n╭─────┬─────────────────────────┬───────╮ │ # │ value │ count │ ├─────┼─────────────────────────┼───────┤ │ 0 │ Nekrolog │ 1 │ │ 1 │ for │ 7 │ │ 2 │ en │ 20 │ │ 3 │ konspirationsteoretiker │ 1 │ │ 4 │ leger │ 1 │ │ 5 │ du │ 13 │ Og så sortere på den nye kolonne som hedder count:\nopen livsfarlige-konspirationsteorier.da.md | split words | uniq --count | sort-by count --reverse der videre giver\n╭─────┬─────────────────────────┬───────╮ │ # │ value │ count │ ├─────┼─────────────────────────┼───────┤ │ 0 │ at │ 21 │ │ 1 │ en │ 20 │ │ 2 │ i │ 19 │ │ 3 │ som │ 15 │ │ 4 │ er │ 15 │ │ 5 │ og │ 15 │ │ 6 │ af │ 14 │ │ 7 │ du │ 13 │ │ 8 │ det │ 10 │ │ 9 │ dig │ 9 │ │ 10 │ ikke │ 9 │ │ 11 │ jeres │ 8 │ │ 12 │ med │ 8 │ │ 13 │ den │ 7 │ Her er tydeligvis brug for at bortsortere stopwords. Men det skulle nok have været gjort inden vi begyndte at tælle antal og sortere på hyppigheden af dem.\nInden vi går tilbage, så lad os først tage en helt almindelig fil med et stopord på hver linje og lave den til en tabel i Nushell med kolonnenavn stopord.\nopen stopord.txt | lines | wrap stopord giver\n╭─────┬────────────╮ │ # │ stopord │ ├─────┼────────────┤ │ 0 │ ad │ │ 1 │ af │ │ 2 │ aldrig │ │ 3 │ alene │ │ 4 │ alle │ │ 5 │ allerede │ │ 6 │ alligevel │ │ 7 │ alt │ │ 8 │ altid │ ... Vi \u0026ldquo;gemmer\u0026rdquo; tabellen i en variabel:\nlet stopwords = ( open stopord.txt | lines | wrap stopord ) Hvis vi nu går tilbage til vores tekst on konspirationers farlighed og deler den op i ord også med kolonnenavn ord:\nopen livsfarlige-konspirationsteorier.da.md | split words | wrap ord får vi\n╭─────┬─────────────────────────╮ │ # │ ord │ ├─────┼─────────────────────────┤ │ 0 │ Nekrolog │ │ 1 │ for │ │ 2 │ en │ │ 3 │ konspirationsteoretiker │ │ 4 │ leger │ │ 5 │ du │ │ 6 │ også │ │ 7 │ med │ │ 8 │ ilden │ │ 9 │ Det │ ... Den tabel skal nu have fjernet alle ord som også findes i tabellen over stopord.\nDet kaldes teknisk set en \u0026ldquo;antijoin\u0026rdquo;\nDesværre kan Nushell endnu ikke lave en rigtig antijoin på tabeller (men det kan den på dataframes og det vender jeg tilbage til i næste artikel om nushell).\nSå i stedet gør vi sådan her:\nopen livsfarlige-konspirationsteorier.da.md | split words | wrap ord | where ord in $stopwords.stopord == false og det giver så\n╭─────┬─────────────────────────╮ │ # │ ord │ ├─────┼─────────────────────────┤ │ 0 │ Nekrolog │ │ 1 │ konspirationsteoretiker │ │ 2 │ leger │ │ 3 │ ilden │ │ 4 │ Det │ │ 5 │ starter │ │ 6 │ ofte │ │ 7 │ uskyldigt │ │ 8 │ Du │ │ 9 │ opdager │ │ 10 │ mainstream │ │ 11 │ medierne │ │ 12 │ lyver │ ... Som man ser, er stopwords fjernet, men ikke dem som er skrevet med stort.\nSå lad os \u0026ldquo;downcase\u0026rdquo; alle ord i teksten først med str downcase lige efter filnavnet:\nopen livsfarlige-konspirationsteorier.da.md | str downcase | split words | wrap ord | where ord in $stopwords.stopord == false Det giver så\n╭─────┬─────────────────────────╮ │ # │ ord │ ├─────┼─────────────────────────┤ │ 0 │ nekrolog │ │ 1 │ konspirationsteoretiker │ │ 2 │ leger │ │ 3 │ ilden │ │ 4 │ starter │ │ 5 │ ofte │ │ 6 │ uskyldigt │ │ 7 │ opdager │ │ 8 │ mainstream │ │ 9 │ medierne │ │ 10 │ lyver │ │ 11 │ lyver │ │ 12 │ ligefrem │ ... Lad os gemme den rensede og \u0026ldquo;downcasede\u0026rdquo; tekst som variablen tidy.\nlet tidy = ( open livsfarlige-konspirationsteorier.da.md | str downcase | split words | wrap ord | where ord in $stopwords.stopord == false ) Og hvis vi så tæller og sorterer igen\n$tidy.ord | uniq --count | sort-by count --reverse så får vi\n╭─────┬─────────────────────────┬───────╮ │ # │ value │ count │ ├─────┼─────────────────────────┼───────┤ │ 0 │ verden │ 5 │ │ 1 │ dag │ 4 │ │ 2 │ verdensopfattelse │ 4 │ │ 3 │ mainstream │ 4 │ │ 4 │ frelser │ 3 │ │ 5 │ hele │ 3 │ │ 6 │ alternative │ 3 │ │ 7 │ begynder │ 3 │ │ 8 │ magtfuld │ 2 │ │ 9 │ pludselig │ 2 │ │ 10 │ tager │ 2 │ │ 11 │ står │ 2 │ │ 12 │ tiden │ 2 │ som giver en ide om hvad teksten handler om.\nDesværre tager processen\nbenchmark { 11/08/2022 11:00:49 ::: let stopwords = ( open stopord.txt | lines | wrap stopord ) ::: let tidy = ( open livsfarlige-konspirationsteorier.da.md | str downcase | split words | wrap ord | where ord in $stopwords.stopord == false ) ::: $tidy.ord | uniq --count | sort-by count --reverse } over en tiendedel af et sekund:\n145ms 516µs 353ns Næste gang ser jeg på om det kan gøres både mere elegant og hurtigere med dataframes i Nushell.\n"
    }
    
    , 
    {
        "url": "/erfaring/foraeldremoedet/",
        "title": "Et forældremøde jeg sent vil glemme",
        "content": "Forældremøder behøver ikke at være kedelige.\nFor nylig var jeg til et forældremøde hvor omgangstonen mellem børnene på årgangen var på dagsordenen.\nEller egentligt var det ikke kun mellem børnene at omgangstonen gav anledning til bekymrede miner.\nEn lærer fortalte nemlig at en elev havde kaldt hende for \u0026ldquo;pisse ung\u0026rdquo;. Og bemærkede så at det havde hun nu egentligt ikke haft så meget imod.\nSå blev der eller grinet godt i forsamlingen.\nEn anden lærer kunne så supplere med at hun var blevet kaldet \u0026ldquo;røvgammel\u0026rdquo;. Og fortalte at det havde været knapt så flatterende.\nSå brød både lærere og forældre ud i et latterbrøl.\nDet virkede måske lidt uempatisk.\nMen betød egentligt bare at alle havde fattet lektien.\nGrimt sprog kan bruges mere eller mindre grimt. Og forældremøder behøver ikke være kedelige.\n"
    }
    
    , 
    {
        "url": "/emner/kommunikation/",
        "title": "Kommunikation",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/begrebernes-betydning/",
        "title": "Begrebernes-Betydning",
        "content": "Man kan godt forholde sig til et spørgsmål uden at have begreberne for det.\nEt eksempel.\nSom barn havde jeg en uenighed med nogle venner.\nVi diskuterede om Otto eller Topper var hovedpersonen i Otte er et næsehorn.\nDe mente alle at det var Otto, mens jeg stod på at det var Topper.\nJeg mente ikke at Otto var hovedperson, men noget andet centralt som jeg bare ikke havde noget begreb for endnu.\nNu ved jeg at Otte var titelrollen - undertiden betegnet titelfigur, titelperson, titelkarakter eller lignende. Det med titlen er i hvert fald klart.\nOg jo, Topper var nok egentligt hovedpersonen.\nDet er altså ikke umuligt at forholde sig til noget, heller ikke at forholde sig korrekt til det, uden at have begreberne på plads.\nMen det er lettere når man har begreberne på plads. Og lettere at kommunikere til andre.\nEndelig er der noget autoritativt i det.\nJeg lykkedes dengang ikke med at overbevise mine kammerater om at Topper var hovedperson. Måske havde jeg haft en bedre chance hvis jeg havde kunne sætte begrebet titelfigur på Otto, så han fik en plads også der lød af noget fint.\n"
    }
    
    , 
    {
        "url": "/erfaring/virkemidler/dagligdagens-virkemidler/",
        "title": "Dagligdagens literære virkemidler",
        "content": " Far, det her har været den bedste sommerferie i mit liv — selvom jeg brækkede armen\nPå en meget varm sommerdag\nEr det ikke lidt køligt?\nHer er referencen ikke til noget tidligere sagt som i eksemplet ovenfor, men i stedet til en ydre realitet som alle kan forholde sig til gennem deres sanser og en enighed om at det er meget varmt.\n"
    }
    
    , 
    {
        "url": "/erfaring/virkemidler/",
        "title": "Sproglige og literære virkemidler",
        "content": "Denne lille grammatik er fokuseret på de dele af sproget som er væsentligst for\nklar kommunikation kreativ skrivning korrekt dansk Den er tiltænkt tekster som skal læses på en skærm.\n"
    }
    
    , 
    {
        "url": "/tools/hugo/",
        "title": "hugo",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/indholdsh%C3%A5ndtering/",
        "title": "indholdshåndtering",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/indholdstyper-soegeindeks-hugo/",
        "title": "Udeluk bestemte indholdstyper fra søgeindeks i Hugo",
        "content": "Jeg ønskede ikke mine micro-blogging \u0026ldquo;snippets\u0026rdquo; som jeg vil bruge på LinkedIn, skulle \u0026ldquo;forurene\u0026rdquo; søgeindekset her på Kiils.\nDerfor skiftede jeg\n[ {{ range $index, $value := where .Site.Pages \u0026#34;.Draft\u0026#34; false }} {{ if $index }}, {{ end }} { \u0026#34;url\u0026#34;: \u0026#34;{{ .RelPermalink }}\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;{{ .Title }}\u0026#34;, \u0026#34;content\u0026#34;: {{ .Content | plainify | jsonify }} } {{ end }} ] ud med\n[ {{ range $index, $value := where ( where .Site.Pages \u0026#34;Section\u0026#34; \u0026#34;!=\u0026#34; \u0026#34;short\u0026#34; ) \u0026#34;.Draft\u0026#34; false }} {{ if $index }}, {{ end }} { \u0026#34;url\u0026#34;: \u0026#34;{{ .RelPermalink }}\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;{{ .Title }}\u0026#34;, \u0026#34;content\u0026#34;: {{ .Content | plainify | jsonify }} } {{ end }} ] "
    }
    
    , 
    {
        "url": "/erfaring/mail-henvendelse/",
        "title": "Når man ringer til en potentiel kunde, og bliver bedt om at sende en mail.",
        "content": "Hvordan følger man op på en kort telefonsamtale?\nDet kan være svært at vide om der er en reel interesse for ens ydelse, selvom man selv ser et klart behov.\nOg det kan være svært at vurdere om henstillingen \u0026ldquo;send en mail\u0026rdquo; udtrykker et reelt ønske om at modtage en mail.\nMen ofte giver det mening at følge op:\nKære Xxxxx,\nTak for den korte samtale på telefon omkring Xxxxxx Publications.\nJeg henvendte mig dels som fast læser af Xxxxxx Magasin og dels som professionel formidler med 21 års erfaring.\nFormålet med min henvendelse var på den baggrund at tilbyde hjælp, så jeres formidling bliver endnu bedre.\nDer var der jeg kom lidt i tvivl om hvordan du forholdt dig. Min opfattelse er som følger.\nJeres niveau er allerede højt. Men jeg ved at det kan løftes. Jeg ved der er plads til forbedringer. Både nogle \u0026ldquo;lavthængende frugter\u0026rdquo; — og andre ting som vil kræve mere arbejde at opnå.\nJeg håber at min mail har vækket din interesse. Hvis ikke det er dit bord, vil jeg ydmygt bede dig om at sende mig videre til en anden person i Xxxxxxs organisation som jeg kan drøfte sagen med.\nJeg bor selv i Xxxxxx, og jeg har før arbejdet med Dansk Industri, Gentofte Hospital, Illustreret Videnskab, Berlingske Media, Ingeniøren og Ugeskriftet i forbindelse med faglig formidling. For blot at nævne nogle få.\nMed venlig hilsen,\nLennart\nDet er et vilkår at man som selvstændig skal sælge sine ydelser, og ofte skal man sælge til en beslutningstager som selv er lønmodtager.\nDet er ofte i sig selv en formidlingsopgave.\n"
    }
    
    , 
    {
        "url": "/emner/salg/",
        "title": "salg",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/2022-06-08t123345/",
        "title": "Bruge hugo server på lokalt netværk",
        "content": "Jeg ville gerne se hvordan min hjemmeside så ud på mobil inden jeg offentliggjorde den.\nDerfor havde jeg brug for at kunne indlæse den fra andre enheder end den enhed som kører hugo server.\nDet burde kunne gøres med - i mit tilfælde:\nhugo server --bind 192.168.0.NNN --baseURL http://pi Desværre gav det en connection refused.\nFor at kunne tilgå hugo server på min raspberry pi, som kører linux, fra en anden enheds webbrowser, skulle jeg aktivere port 1313 for min aktuelle zone i firewall\u0026rsquo;en:\nfirewall-cmd --zone=home --add-port 1313/tcp Det er en kommando til firewalld som du kan læse om her:\nHome | firewalld Og det kan læses i nftables at indstillingen er aktuel:\nsudo nft list ruleset | rg 1313 -A1 -B8 Det giver:\nchain filter_IN_home_allow { tcp dport 22 ct state { new, untracked } accept ip daddr 224.0.0.251 udp dport 5353 ct state { new, untracked } accept ip6 daddr ff02::fb udp dport 5353 ct state { new, untracked } accept udp dport 137 ct helper set \u0026quot;helper-netbios-ns-udp\u0026quot; udp dport 137 ct state { new, untracked } accept udp dport 138 ct state { new, untracked } accept ip6 daddr fe80::/64 udp dport 546 ct state { new, untracked } accept tcp dport 1313 ct state { new, untracked } accept } Se næstnederste linje ovenfor.\nHvad er nftables så?\nnftables is the modern Linux kernel packet classification framework.\nSom så igen kobler til Netfilter:\nNetfilter is a framework provided by the Linux kernel that allows various networking-related operations to be implemented in the form of customized handlers.\nSå blev jeg da en del klogere.\nKilder: Wikipedia og diverse hjemmesider for de pågældende værktøjer.\n"
    }
    
    , 
    {
        "url": "/emner/indholdsstrategi/",
        "title": "Alt om Indholdsstrategi",
        "content": " Tænk over hvad du vil opnå med dine tekster \u0026mdash; effektiv kommunikation kræver fokus og planlægning\n"
    }
    
    , 
    {
        "url": "/ydelse/raadgivning/",
        "title": "Rådgivning",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/friteksts%C3%B8gning/",
        "title": "Fritekstsøgning",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/indholdsstyring/",
        "title": "Indholdsstyring",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/recoll/",
        "title": "Recoll",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/recoll-smart-s%C3%B8gning/",
        "title": "Smarte søgefunktioner i Recoll",
        "content": "Noget af det jeg manglede i MacOS Spotlight søgemaskinen, var en mere omfattende syntaks for søgning.\nRecoll er både smart og omfangsrig på det område.\n¶ Stemming Recoll er bygget på Xapian som faktisk har en dansk stemming-mekanisme.\nStemming finder roden af et ord og de forskellige afledninger. På den måde får man flere resultater på en søgning, og nogle af dem vil være relevante nok.\nMed Recoll og Xapian tages der endda konkret højde for nøjagtig de ord som findes i dit indeks.\nI mine tekster er der skrevet noget om biler en del gange:\n\u0026gt; recollq -s danish bilerne | count 167 Med -s danish søger Recoll på \u0026lsquo;bil\u0026rsquo; og alle andre former af ordet, selvom det er indtastet som \u0026lsquo;bilerne\u0026rsquo;.\nMen hvad nu hvis man kun vil søge på en bestemt form af et ord? Altså for eksempel \u0026lsquo;bilerne\u0026rsquo; nøjagtig sådan.\nStort forbogstav slår ganske enkelt stemmning fra:\nSå Bilerne kun søger på \u0026lsquo;bilerne\u0026rsquo;, mens bilerne søger på \u0026lsquo;bilerne\u0026rsquo;, \u0026lsquo;biler\u0026rsquo;, \u0026lsquo;bil\u0026rsquo; etc.\n\u0026gt; recollq -s danish Bilerne | count 4 Så jeg har altså kun fire tekster i mit arkiv hvor præcist bil indgår i bestemt flertal.\nStemming er heller ikke slået til når man søger en frase som for eksempel \u0026quot;bilerne er\u0026quot; da fraser jo er bogstavelige.\n¶ Nærhed (proximity) Recoll tager automatisk højde for nærhed når søgeresultater sorteres. Men en bestemt rækkefølge og et bestemt maksimalt antal ord kan også efterspørges.\nSøgning efter \u0026lsquo;dansk\u0026rsquo; eller \u0026lsquo;politik\u0026rsquo; med dansk stemming:\n\u0026gt; recollq -s danish \u0026#39;dansk politik\u0026#39; | count 507 Uden stemming\n\u0026gt; recollq \u0026#39;dansk politik\u0026#39; | count 110 Så snart man søger på en frase, gør stemming ingen forskel:\n\u0026gt; recollq -s danish \u0026#39;\u0026#34;dansk politik\u0026#34;\u0026#39; | count 53 og\n\u0026gt; recollq \u0026#39;\u0026#34;dansk politik\u0026#34;\u0026#39; | count 53 er ækvivalente.\nAccepterer man op til 5 ord imellem \u0026lsquo;dansk\u0026rsquo; og \u0026lsquo;politik\u0026rsquo;, men stadig samme rækkefølge af søgeord, kan det udtrykkes således:\n\u0026gt; recollq \u0026#39;\u0026#34;dansk politik\u0026#34;o5\u0026#39; | count 57 Og med maksimalt fem ord mellem søgeordene hvor rækkefølgen er ligegyldig, stiger antal søgeresultater i det her tilfælde yderligere en smule:\n\u0026gt; recollq \u0026#39;\u0026#34;dansk politik\u0026#34;p5\u0026#39; | count 61 ¶ Vægt og prioritet Normalt tæller antal gange, et søgeord optræder i en tekst, meget for relevansen, og man kan kunstigt oprioritere et bestemt ord ud af flere i en søgning.\nHvis et søgeord i en forespørgsel er ekstra vigtigt, kan det gives en højere vægt.\nFor eksempel giver\n\u0026gt; recollq -n 1 \u0026#39;\u0026#34;dansk\u0026#34;10 politik\u0026#39; Recoll query: Query((5 * dansk AND politik)) [file:///home/lk/TEKST/ARKIV/undertrykt-stakke-revolution-dansk-politik.da.md] mens\n\u0026gt; recollq -n 1 \u0026#39;dansk \u0026#34;politik\u0026#34;10\u0026#39; Recoll query: Query((dansk AND 10 * politik)) [file:///home/lk/TEKST/ARKIV/BACKUP/Folkets Avis/Indhold/Ledere/Et vendepunkt i dansk politik.txt]\tAltså to forskellige resultater i mine tekster hvor sidste resultat er en tekst hvor \u0026lsquo;politik\u0026rsquo; fylder mere end i første.\nEt helt tredje resultat får jeg ved\nrecollq -n 1 \u0026#39;dansk -politik\u0026#39; for her er alle tekster med ordet \u0026lsquo;politik\u0026rsquo; i helt sorteret fra.\nDet var nogen af mulighederne som gør det nemmere at finde relevante tekster og brudstykker af tekster frem i et stort lokalt arkiv.\n"
    }
    
    , 
    {
        "url": "/ydelse/research/krydstjek/",
        "title": "Krydstjek",
        "content": "Hvordan fungerer din tekst på forside og landingssider. Favner den alle de enheder som de besøgende bruger?\nI dag skal de korte, kontante tekster både fungere på laptop, tablet og mobil. Det undersøger jeg om de gør, og giver bud på forbedringer.\nJeg fokuserer på teksterne og det indholdsmæssige, men jeg kan også kommentere på de tekniske aspekter omkring præsentation, men jeg implementerer ikke disse.\n"
    }
    
    , 
    {
        "url": "/ydelse/research/",
        "title": "Research",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/recoll-fritekst-s%C3%B8gning/",
        "title": "Sådan holder man styr på 10.000 tekster",
        "content": "Hvordan holder man styr på sine egne tekster når man har over 10.000 af dem på sin laptop?\nSvaret er lokal fritekstsøgning.\nMacOS har spotlight indbygget som er okay til formålet, men alligevel lidt for begrænset.\nJeg har brugt en del tid på at finde et værktøj som kunne indeksere mine filer på en ordentlig måde, så jeg altid hurtigt kunne finde noget i en tekst som jeg havde behov for at vide eller bruge.\nRecoll er sådan et værktøj og det findes både til mac, windows og unix / linux.\nRecoll finds your documents Recoll er baseret på Xapian som er en open source søgemaskine.\nThe Xapian Project Recoll har både en grafisk brugerflade og kan bruges fra kommandolinjen.\nJeg mangler dog en enkelt ting, fordi jeg sjældent arbejder med pdf eller docx eller lignende, så er sidenumre ikke så relevante for mig.\nMen når jeg hovedsageligt skriver tekster til digitale medier direkte i plain tekst eller markdown format, som jo også bare er tekst, så er linjenumre til gengæld enormt praktiske at have med i snippets fra en overordnet fritekstsøgning.\nJeg har derfor efterspurgt en feature i Recoll her\nexposing line numbers in snippets (#156) · Issues · Jean-Francois Dockes / recoll · GitLab "
    }
    
    , 
    {
        "url": "/ydelse/raadgivning/miks/",
        "title": "Miks",
        "content": "Hvordan sammensætter man det rette miks af tekster? Hvordan fastholder man læsernes interesse over tid? Og hvordan overrasker og udfordrer man dem uden at skræmme dem væk?\nDet handler om at skabe det rette miks af indhold. Det skal være målrettet, men ikke ensformigt. Det er lidt af en kunst som ikke kan sættes på formel.\nDet er nødvendigt at tage udgangspunkt i dit projekt og din målgruppe, og så lægger vi en plan som tager højde for de ting og giver dine læsere det de vil have, men på dine betingelser.\n"
    }
    
    , 
    {
        "url": "/erfaring/tal/",
        "title": "Fem eller 5",
        "content": "Skal man skrive tal ud i bogstaver?\nDer er ingen officielle regler om det.\nMen der er sædvaner og traditioner.\nTommelfingerreglen går ud på at man skriver tal fra 1 til 10 med bostaver. Sådan er det typisk i almindelig journalistik.\nMen der er altid undtagelser. For eksempel\ni erhvervsjournalistik er det normalt at skrive tal som tal når man tæller valutaenheder og lignende. I andre sammenhænge skriver man 1-10 med bogstaver. Altså: \u0026ldquo;Han fik kun 5 kroner i lommepenge. Kun fem af hans klassekammerater fik mindre.\u0026rdquo;\ni rubrikker virker tal ofte bedst skrevet som tal, det fanger opmærksomheden bedre når en læser skimmer skærmen eller avisen. Det med at fange opmærksom vender jeg tilbage til.\nhvis en situation kræver fokus på effektiv læsning frem for \u0026ldquo;æstetik\u0026rdquo;.\nhvis du har behov for at trække data ud af teksten i form af heltal.\nOverordnet fanger tal opmærksomheden bedre end bogstaver når tallene netop som i en sætning er omgivet af bogstaver. Så står tallene ud.\nDet betyder at man med tal kan fange læserens opmærksomhed.\nBagsiden af medaljen er så at tal kan bryde læserytmen mere og få sproget til at fremstå mere fragmenteret. Det ser i manges øjne også mindre pænt ud.\nTallene er naturligvis hurtigere at skrive og de sparer plads.\nSkriver man tallene ud, viser man derimod at man har gjort sig umage og brugt tid på at få tingene til at fremstå pænere.\nDer er altså et trade off og især i digital journalistik hvor der scrolles meget og hurtigt, kan det ofte være fordelagtigt at tænke i indgange til en tekst, og der kan tal skrevet som tal være med til at fange læseren ind i teksten igen.\nDer er flere andre ting som kan spille ind, og ofte kræver valget af tal eller bogstaver en konkret vurdering.\n"
    }
    
    , 
    {
        "url": "/emner/grammatik/",
        "title": "Grammatik",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/korrektur/",
        "title": "Korrektur",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/retstavning/",
        "title": "Retstavning",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/cli/",
        "title": "CLI",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/effektivisering/",
        "title": "Effektivisering",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/fd/",
        "title": "fd",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/grep/",
        "title": "grep",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/pi/pi-cli/",
        "title": "Hurtigere alternativer til find og grep på Raspberry Pi",
        "content": "Raspberry Pi er ikke nogen hurtig computer. Eller jo, hvis man måler dens ydelse op imod dens strømforbrug, så er den ganske imponerende.\nMen den bruger næsten ingen strøm og er sammenlignet med en moderne laptop ret langsom.\nFor eksempel så tager det cirka 1 sekund at danne hele dette website via static site generatoren Hugo på min Raspberry Pi 4B, mens det tager cirka et kvart sekund på min macbook pro.\nJeg lagde også mærke til at kommandoen find var ret langsom. Men så installerede jeg bare fd som både er hurtigere for mig og meget nemmere at bruge og forstå.\nfind virker omstændelig i sin syntaks, fd er nem at gå til. Meget simplere. Så den er for mig både hurtigere i brug og hurtigere i sin søgen på computeren.\nJeg har også installeret rg som erstatning for eller supplement til grep. Her ved jeg dog ikke om der er så stor en forskel for mig som med find og fd.\n"
    }
    
    , 
    {
        "url": "/emner/kiss/",
        "title": "KISS",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/raspberry-pi/",
        "title": "Raspberry Pi",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/rg/",
        "title": "rg",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/tanker/gear/",
        "title": "Det er svært at forklare min søn, men min datter forstår sine gear",
        "content": "Man skulle tro at flere muligheder er bedre. Men sådan er det ikke.\nKompleksitet er et problem. Og skal man formidle noget komplekst, så står man med en stor udfordring.\nSom den anden dag, hvor jeg skulle forklare min datter hvordan hun bruger de tre gear på sin cykel.\ngear - op ad bakke gear - lige ud gear - ned ad bakke Så simpelt er det vitterlig.\nMin to år ældre søn har 21 gear. Hvordan forklarer man lige det?\nReelt er der ingen nem forklaring.\nOfte er det bedst at undgå at komme i en situation hvor en svær forklaring er nødvendig. Simpelthen at undgå kompleksitet.\nMen det er ikke altid en mulig vej, og så må man væbne sig med tålmodighed og anstrenge sine evner.\nJeg endte med at komme på en tilfredsstillende og brugbar forklaring til min søn.\n"
    }
    
    , 
    {
        "url": "/emner/formidling/",
        "title": "Formidling",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/vim/",
        "title": "Vim",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/journalistik/nutella/",
        "title": "Put aldrig smør under nutella",
        "content": "Hvad nytter et vigtigt budskab hvis ingen ser det?\nPå nettet er rubrikker, altså overskrifter, enormt vigtige fordi de afgør om en tekst bliver læst eller ej.\nJeg har skrevet 10.000 rubrikker. Og jeg har data på 4000 af dem.\nDet gør at jeg har både en følelse for hvad der virker — og konkret viden til at bakke min intuition op.\nEn overskrift skal fange læserens interesse, så læseren klikker og dykkere videre ned i teksten hvor det egentlige budskab så udfoldes.\nLad os tage et eksempel:\n¶ Derfor må du aldrig putte smør under din Nutella-mad Derfor må du aldrig putte smør under Nutella Løfte vedkommende nødvendig bred appel Her lægger rubrikken op til at brødteksten indeholder viden som er vigtig for mange mennesker.\nHvor mange har ikke smurt smør under deres Nutella? Og hvorfor må man så aldrig gøre det?\nOg man skal naturligvis levere den viden man lover i overskriften.\nDet er en måde at lave en fængende overskrift på. Der er mange andre.\nBook en tid og få hjælp til at lave bedre rubrikker.\n"
    }
    
    , 
    {
        "url": "/ydelse/redaktionelt/",
        "title": "Redaktionelt",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/rubrikker/",
        "title": "rubrikker",
        "content": ""
    }
    
    , 
    {
        "url": "/ydelse/redaktionelt/rubrikker/",
        "title": "Rubrikker der rykker",
        "content": "Jeg har skrevet 10.000 rubrikker. Og jeg har data på 4000 af dem.\n"
    }
    
    , 
    {
        "url": "/erfaring/bedrifter/10000-tekster/",
        "title": "Jeg har skrevet over 10.000 tekster - her er den som betyder mest for mig selv",
        "content": "Jeg har skrevet langt over 10.000 tekster. Og det er naturligvis ikke medregnet små grynt på facebook eller beskeder på SMS eller i Signal.\nNej, det er 10.000 rigtige tekster.\nHeraf har jeg data på over 3000.\nDet med data er også vigtigt, for det giver mig mulighed for at finde frem til de virkemidler som har størst effekt.\nMen den tekst som betyder mest for mig selv, har jeg ingen data på.\nDet er en lille tekst som jeg opfandt da min søn kun var et par år gammel — og han altid vågnede meget tidligt om morgenen.\nSå gik jeg en tur med ham i klapvognen - eller karbong som han kaldte den.\nVi gik gennem Humlebæk ned til stranden Peder Mads og videre en tur hen på Sletten Havn.\nSå tidligt om morgenen var der ofte diset, men disen forsvandt i løbet af turen efterhånden som solen fik mere magt.\nDet var på disse ture at jeg udviklede en lille tekst som den dag i dag betyder meget for både mig og mine børn:\nSolen er oppe\nog tågen væk\nDet er morgen\ni Humlebæk\nFra Sletten Havn\nhøres skibets lyd\nog hvilken herlig\nmorgenfryd\nJeg har endda lavet en lille melodi til, men jeg kan ikke skrive noder, så den må I undvære her.\nTeksten i sig selv er banal. Den er ikke tænkt, men levet.\nOg historien som hører til, er vigtig for mig.\nJeg elsker Humlebæk og jeg elsker mine børn.\nJeg elsker at gå en morgentur, jeg elsker stranden og jeg elsker fiskernes flittige forberedelser på havnen når lyset bryder frem.\n"
    }
    
    , 
    {
        "url": "/erfaring/sikkerhed/pixelering/",
        "title": "Pixelering er ikke længere sikker sløring",
        "content": "Når det gælder tekst, er pixelering ikke længere en god måde at sløre på:\nToday, we’re focusing on one such technique – pixelation – and will show you why it’s a no-good, bad, insecure, surefire way to get your sensitive data leaked. To show you why, I wrote a tool called Unredacter that takes redacted pixelized text and reverses it back into its unredacted form.\nhttps://bishopfox.com/blog/unredacter-tool-never-pixelation Nummerplader er også tekst.\nJeg gætter på at pixelering af ansigter og lignende også snart vil kunne afsløres.\n"
    }
    
    , 
    {
        "url": "/emner/sikkerhed/",
        "title": "sikkerhed",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/sl%C3%B8ring/",
        "title": "sløring",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/dateutils/",
        "title": "dateutils",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/fish/",
        "title": "Fish",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/noob/program-1/",
        "title": "Mit første computer-program nogensinde - kan du gennemskue hvad det gør?",
        "content": "Jeg har beskæftiget mig meget med sprog. Taler også flere af dem ganske godt — har jeg fået at vide ;)\nOg så er det naturligvis sproget jeg bruger til at formidle budskaber, ideer og viden. Også i mit professionelle virke.\nOvenikøbet har jeg specialiseret mig i at formidle digitalt. Og her bruger man typisk sproget lidt anderledes end man gør i de mere klassiske udgivelser som bøger og trykte artikler.\nNår man tænker over det, er det egentligt utroligt at jeg aldrig har lært et programmeringssprog!\nDet her jeg stadig ikke, vil nogen med rimelighed anføre når de ser mit \u0026ldquo;program\u0026rdquo; herunder. Men jeg har snuset lidt til emnet og bygget en lille funktion op i et \u0026ldquo;script\u0026rdquo;.\nDet er et lille \u0026ldquo;program\u0026rdquo; der hjælper mig med at gøre børnenes liv bedre. Jeg tror ikke man behøver være programmør for at gennemskue koden:\nfunction D read -p \u0026#39;echo \u0026#34;A sover:\u0026#34;\u0026#39; -l asover read -p \u0026#39;echo \u0026#34;A vågner:\u0026#34;\u0026#39; -l avaagner read -p \u0026#39;echo \u0026#34;A humør:\u0026#34;\u0026#39; -l ahumor read -p \u0026#39;echo \u0026#34;O sover:\u0026#34;\u0026#39; -l osover read -p \u0026#39;echo \u0026#34;O vågner:\u0026#34;\u0026#39; -l ovaagner read -p \u0026#39;echo \u0026#34;O humør:\u0026#34;\u0026#39; -l ohumor set -l ak (datediff 2022-01-01T(echo $asover) 2022-01-02T(echo $avaagner) -f \u0026#39;%0H:%0M\u0026#39;) set -l ok (datediff 2022-01-01T(echo $osover) 2022-01-02T(echo $ovaagner) -f \u0026#39;%0H:%0M\u0026#39;) echo (date \u0026#34;+%Y-%m-%d\u0026#34;), $ak, $ahumor, $ok, $ohumor \u0026gt;\u0026gt; sovn.txt end Kan du gennemskue hvad programmet gør?\nFørst forsøgte jeg selv at udregne tidsperioden, men det var besværligt af mange forskellige årsager.\nHeldigvis kunne jeg installere et lille værktøj datediff fra pakken dateutils. Det gjorde jeg sådan her på macOS\nbrew install dateutils \u0026ldquo;Programmet\u0026rdquo; er skrevet i Fish som er en shell ligesom sh, bash eller zsh.\nMen vigtigst af alt, så har programmet gjort det lettere for mig at sikre at børnene får deres søvn.\nOg hvis ikke digitaliseringen gør vores liv bedre, hvad skal vi så bruge den til?\nPS. Det med at sætte en fast, tilfældig valgt, dato ind i datediff-kommandoen virkede som den letteste måde at løse problemet med at få en tidsperiode hen over et døgnskifte ud i positive tal på.\nDet kan nok gøres mere elegant. Men min løsning virker faktisk helt fint uanset hvad dato jeg bruger programmet på.\n"
    }
    
    , 
    {
        "url": "/emner/programmering/",
        "title": "Programmering",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/venlig-digitalisering/",
        "title": "Venlig digitalisering",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/brugervenlig/",
        "title": "Brugervenlig",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/css/",
        "title": "css",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/energibesparelse/",
        "title": "Energibesparelse",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/klimavenlig/",
        "title": "Klimavenlig",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/klimavenlig-og-brugervenlig/",
        "title": "Med ny dark mode er klimaleksikon både mere bruger- og klimavenlig",
        "content": "Det er kun naturligt at Klimaleksikon skal være et klimavenligt website.\nOg med at dark mode for dem som har indstillet deres enhed til det, så sparer sitet nu en del energi på AMOLED-enheder, som udgør en væsentlig del af mobile enheder.\nDer er lidt uenighed om hvor meget energi dark mode sparer, og det kommer også an på nogle detaljer. Først lød budet på op til 60 procent, men grundigere undersøgelser peger på besparelser mellem 39 procent og 47 procent hvis man normalt har meget brightness på sin enhed.\nEr man en af dem som skruer mere ned, så er der \u0026ldquo;kun\u0026rdquo; omkring 10 procent at spare.\nDet er klimavenligt.\nDet er også er en brugervenlig beslutning at stille dark mode til rådighed, det kan du læse om her:\n— Sådan satte jeg et dark theme op på folkets uden at genere brugerne med flere valgmuligheder Du kan læse mere om energibesparelsen her:\nDash, Pranab \u0026amp; Hu, Y. Charlie (2021) \u0026lsquo;How Much Battery Does Dark Mode Save? An Accurate OLED Display Power Profiler for Modern Smartphones\u0026rsquo; in Proceedings of the 19th Annual International Conference on Mobile Systems Applications and Services, New York, NY, USA: Association for Computing Machinery, pp. 323\u0026ndash;335. https://doi.org/10.1145/3458864.3467682 "
    }
    
    , 
    {
        "url": "/emner/milj%C3%B8venlig/",
        "title": "Miljøvenlig",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/brugervenlighed/",
        "title": "Brugervenlighed",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/b%C3%A6redygtighed/",
        "title": "Bæredygtighed",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/design/",
        "title": "Design",
        "content": ""
    }
    
    , 
    {
        "url": "/cases/folkets/",
        "title": "FOLKETS",
        "content": "En dansk brand- og medieplatform\nFOLKETS.DK er et enorm stort projekt. Visionen er at udfordre både de danske medier og de amerikanske \u0026ldquo;tech giants\u0026rdquo;.\nSamtidig med at øjnene skal holdes på dette langsigtede mål, skal de betalende brugere også løbende serviceres med godt indhold.\nDer skal skabes indtægter og hele projektet skal løbende tilpasses og \u0026ldquo;trimmes\u0026rdquo; da der hele tiden kommer nyt på.\nFOLKETS.DK er uden sammenligning det mest lærerige fagligt set, som jeg har foretaget mig i mit arbejdsliv.\n"
    }
    
    , 
    {
        "url": "/emner/klimavenlighed/",
        "title": "Klimavenlighed",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/media-queries/",
        "title": "media queries",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/brugervenlighed/brugerens-foretrukne-farvepalette-dark-mode-folkets/",
        "title": "Sådan satte jeg et dark theme op på Folkets uden at genere brugerne med flere valgmuligheder",
        "content": "I dag er der mange ting en bruger skal tage stilling til når han eller hun surfer ind på en hjemmeside.\nVil man nu have cookies?\nHvilke cookies vil man have?\nVil man tilmeldes nyhedsbrev?\nEller vil man have notifikationer?\nNogle har også en chatbot som begynder at stille brugeren spørgsmål.\nDet sidste brugere har behov for er endnu en detalje at tage stilling til!\nDerfor var det vigtigt for mig at jeg kunne give brugerne af Folkets.dk mulighed for at vælge et mørkt tema, men uden at skulle spørge dem.\nMuligheden er der takket være to css media queries som hedder henholdsvis\n@media (prefers-color-scheme: dark) { } og\n@media (prefers-color-scheme: light) { } På den måde kunne jeg på simpel maner efterkomme brugerens ønske.\nBrugeren behøver kun at foretage valget een gang i sit operativ-system. Så gælder det automatisk på sites som er sat op til det. Nu også Folkets.\nDu kan læse mere om mulighederne her\nThe prefers-color-scheme CSS media feature is used to detect if the user has requested a light or dark color theme.\nThe user might indicate this preference through an operating system setting (e.g. light or dark mode) or a user agent setting.\n— prefers-color-scheme - CSS: Cascading Style Sheets | MDN Hvordan ser dark mode så ud på Folkets?\nOmtrent sådan her:\nDark mode på Folkets "
    }
    
    , 
    {
        "url": "/emner/valgmuligheder/",
        "title": "Valgmuligheder",
        "content": ""
    }
    
    , 
    {
        "url": "/genrer/bedrifter/",
        "title": "bedrifter",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/seo/google-klima-succes/",
        "title": "Klimaleksikon nummer et i Google på klima",
        "content": "Klimaleksikon er det mest troværdige sted på nettet for unge mennesker at finde viden om klima på dansk.\nDet afspejles nu ikke længere blot i massiv søgetrafik på klima og relaterede emner fra skoler og ungdomsuddannelser til sitet, men også ved en flot topplacering på Google.\nGanske enkelt nummer et på søgeordet klima:\nKlimaleksikon i top på Google for søgeordet \u0026#39;klima\u0026#39; Jeg forventer ikke nødvendigvis at den placering vil holde for evigt. Der er hård konkurrence og mange gode bud.\nMen placeringen er en stor cadeau til det arbejde som mine to medredaktører og jeg selv har udført på Klimaleksikon gennem nu 13 år.\nEn placering over selveste Wikipedia — det er vi enormt glade for og stolte over.\nGoogles søgekonsol bekræfter resultatet:\nFlere fordelagtige placeringer Og viser i øvrigt at Klimaleksikon klarer sig godt på en række relaterede ord også. Faktisk ikke mindre end 682 søgeord med tæt relation til klima:\nKlimarelaterede søgeord på Klimaleksikon Vi fortsætter arbejdet.\n"
    }
    
    , 
    {
        "url": "/erfaring/tips-tricks/html-med-toc-fra-markdown-via-pandoc/",
        "title": "HTML med toc fra markdown via pandoc",
        "content": "I terminalen i samme folder som filen ligger:\npandoc -s --toc filename.md Og kopier så alt mellem body-tags.\nBonus: Pandoc gør ikke æ, ø og å grimme i interne links :)\n"
    }
    
    , 
    {
        "url": "/genrer/lifehacks/",
        "title": "lifehacks",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/sortering/",
        "title": "sortering",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/struktur/",
        "title": "struktur",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/tips/",
        "title": "tips",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/tricks/",
        "title": "tricks",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/atom/",
        "title": "atom",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/indhold/",
        "title": "indhold",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/latex/",
        "title": "latex",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/tips-tricks/sidetal/",
        "title": "Sidetal væk fra forsiden i pdf over Pandoc fra markdown",
        "content": "Først fjernes sidenumre generelt i frontmatter:\n--- header-includes: | \\pagenumbering{gobble} ... --- Så indsættes sidenumre nede i selve dokumentet:\n\\pagenumbering{arabic} ... På den måde får man fjernet sidetal fra forsiden, hvor titlen er, og igen indsat sidetal længere fremme i selve dokumentet.\n"
    }
    
    , 
    {
        "url": "/brands/",
        "title": "Brands",
        "content": "Brands som Kiils råder over. Hosted på platformen Folkets.\n"
    }
    
    , 
    {
        "url": "/erfaring/seo/corona/",
        "title": "Er det sådan censur ser ud?",
        "content": "\nJeg valgte fra starten at alt indhold om den nye coronavirus på FOLKETS skulle være frit tilgængeligt for alle. Også selvom jeg vidste at den beslutning ville komme til at koste mig en del penge.\nJeg fulgte virkelig meget med. Nok for meget. Brugte al min tid på at følge udviklingen i andre lande. Og jeg brugte naturligvis tid på at advare danskerne om at coronavirus var en alvorlig sag. Ikke \u0026ldquo;bare en influenza\u0026rdquo;.\nDenne indsats fra min side blev bestemt ikke belønnet på Facebook. Her havde mine indlæg om coronavirus stort set ingen gennemslagskraft. I hvert fald ikke i forhold til andre ting jeg til dagligt skriver om.\nMen til min store glæde, så kompenserede trafikken fra Google for manglen på Facebook. Når man bruger tid på noget vigtigt, og mener at man har noget at byde ind med, så er det rart at det rent faktisk kommer ud og gør gavn.\nOg det gør oplysning og information jo kun hvis folk rent faktisk for dem at se.\nMen så skete der for et par dage siden noget underligt. Jeg bemærkede hurtigt at trafikken til FOLKETS faldt en del. Ret abrupt.\nDelingerne på Facebook de klarede sig hverken bedre eller dårligere end andre delinger om coronavirus. Så der var noget andet i gære.\nJeg tjekkede så i Googles søgekonsol. Og fik der bekræftet min mistanke.\nPå få dage var FOLKETS skubbet fra en placering på side et til en placering ned på side tre for søgeordet \u0026lsquo;corona\u0026rsquo;. Det er alligevel noget af et \u0026ldquo;drop\u0026rdquo;.\nSå nu står jeg i den situation at jeg ikke får trafik fra hverken Facebook eller Google. Endda på et område hvor jeg har bidraget med væsentlige indlæg før de fleste andre her i landet.\nOg jeg aner ikke hvorfor. Jeg aner det virkelig ikke.\nMen det får mig da til at tænke over den magt Google og Facebook har. Og den magt staten har med Google og Facebook som proxier.\nJeg kan ikke konkludere at der er tale om censur. Og måske er censur slet ikke det rigtige ord. Måske er det bare en fluktuation.\nMen effekten er den samme; folk kommer ikke til at læse det jeg skriver.\nDet må jeg leve med. Og jeg håber da på et comeback.\nOg uanset hvad er det trods alt betydeligt bedre at blive usynliggjort i den digitale verden end at blive \u0026ldquo;taget ud\u0026rdquo; i den virkelige.\n"
    }
    
    , 
    {
        "url": "/brands/folkets-avis/",
        "title": "Folkets Avis",
        "content": "Folkets Avis er et mediebrand på udgiverplatformen FOLKETS.\nLennart Kiil En dansk brand- og medieplatform\nFOLKETS.DK er et enorm stort projekt. Visionen er at udfordre både de danske medier og de amerikanske \u0026ldquo;tech giants\u0026rdquo;.\nSamtidig med at øjnene skal holdes på dette langsigtede mål, skal de betalende brugere også løbende serviceres med godt indhold.\nDer skal skabes indtægter og hele projektet skal løbende tilpasses og \u0026ldquo;trimmes\u0026rdquo; da der hele tiden kommer nyt på.\nFOLKETS.DK er uden sammenligning det mest lærerige fagligt set, som jeg har foretaget mig i mit arbejdsliv.\n"
    }
    
    , 
    {
        "url": "/tools/googles-s%C3%B8gekonsol/",
        "title": "Googles-søgekonsol",
        "content": ""
    }
    
    , 
    {
        "url": "/genrer/overvejelser/",
        "title": "overvejelser",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/seo/",
        "title": "SEO",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/some/facebook/fald/",
        "title": "En langsom pinefuld død på Facebook",
        "content": "En samarbejdspartner fortalte mig for ikke så længe siden:\n– Jeg har brudt koden på facebook!\n– Hvordan?\n– Man betaler bare.\nJo, det tror jeg gerne på.\nEnhver som arbejder med markedsføring eller mediedrift på facebook ved at facebook gør meget ud af at oplyse en om mulighederne for at øge rækkevidden ved at betale for boost af ens indhold.\nDer levnes ingen tvivl om at facebook gerne vil have at man bruger penge på at promovere sine sider og sine ikke-personlige indlæg.\nDer dukker meget ofte forskellige former for påmindelser op om at dette er muligt. Og hvis man betaler og for sat sin målgruppe rigtigt sammen, så kan man sikkert ofte få en del \u0026ldquo;bang for the buck\u0026rdquo;.\nMen det er ikke bare de direkte opfordringer, facebook kommer med, som underbygger teorien om at der skal bruges penge på facebook hvis man vil have hurtige resultater.\nHer ses udviklingen i antal følgere på Folkets Avis\u0026rsquo; facebookside nogle måneder i slutningen af 2019:\nJeg bemærker en jævn langsomt nedadgående trend. Det på trods af at der ellers ofte er interesse og engagement på siden.\nJeg ville ikke blive overrasket hvis facebook arbejder med deres algoritmer på en måde så der falder flere fra end der kommer til - med mindre særlige forhold gør sig gældende.\nSå kan man enten være meget dygtig og dedikeret i sin jagt på flere følgere. Eller man kan betale sig fra det. Eller, naturligvis, kombinere de to tilgange.\nJeg skal her være ærlig:\nSom medieejer er facebook blevet mindre interessant. For for et givet antal følgere er det nu sværere end tidligere at få folk ud af facebooks lukkede have.\nDet er derfor mest sandsynligt at jeg koncentrerer mere af min indsats andre steder fremover. Om at opbygge medieplatformen FOLKETS yderligere.\nFor andre kan facebook til stadighed være en central del af forretningen.\nMen det kræver som hovedregel en betydelig investering af både tid og efterhånden også penge at få ordentligt udbytte af indsatsen.\nDe nemme tider med facebook er for længst forbi.\n"
    }
    
    , 
    {
        "url": "/emner/facebook/",
        "title": "facebook",
        "content": ""
    }
    
    , 
    {
        "url": "/genrer/polemik/",
        "title": "Polemik",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/some/",
        "title": "SoMe",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/fundraising/copydan/copydan-digital/",
        "title": "100.000 gange årligt bruges mine tekster i undervisningen uden at jeg får en krone for det – og CopyDan kan ikke hjælpe mig",
        "content": "På grund af forældet lovgivning kan CopyDan ikke hjælpe mig.\nLad mig forklare sagen:\nJeg er meget glad for og stolt over Klimaleksikon - Danmarks bedste sted for børn og unge at blive klogere på alt hvad der har med klima at gøre.\nSitet virker på alle måder efter hensigten og hjælper hvert år cirka 100.000 børn og unge med at få mere viden om klima og klimarelaterede emner.\nDet kan jeg kun være enormt tilfreds med.\nOg både politikere og erhvervsliv kan slet ikke holde op med at fortælle om hvor vigtigt emnet er.\nSå er det godt at hjælpe med at klæde børn og unge fagligt på til at forstå mekanismerne bag klimaforandringer.\nMen der er også meget følelsesbetonet og irrationel debat om klima i Danmark. Ikke mindst blandt voksne mennesker.\nDet har skabt en situation hvor emnet klima for mange børn og unge er blevet en debiliterende ting i deres hverdag som gør dem bekymrede og kede af det.\nOplysning, af den art som Klimaleksikon leverer med fokus på det faktuelle, kan også være med til at modvirke de debiliterende tendenser til klimaangst i børn.\nOg give dem en forståelse af hvad vi mennesker kan gøre for at imødegå klimaforandringer med hjælp fra vores intelligens og fornuft – og vores enestående evne til at udvikle teknologiske løsninger.\nSom en ekstra bonus kan klima, som emnet tilgås på Klimaleksikon, engagere flere piger i STEM-fagene og STEAM-fagene. Noget som mange mener er meget vigtigt.\nDet lyder jo alt sammen meget godt.\nMen, men, men.\nJeg har nu i 11 år af egen pengepung betalt for at holde Klimaleksikon kørende. Jeg har betalt professionelle fagformidlere for at lave indhold og holde indhold opdateret.\nDet kan jeg ikke blive ved med.\nOg da jeg på forskellig vis kunne se at Klimaleksikon blev aktivt brugt i undervisningen kontaktede jeg CopyDan.\nCopyDan sender nemlig med lovhjemmel fakturaer ud til uddannelsesinstitutionerne på vegne af udgivere og autorer.\nDe var utroligt flinke og rare inde på CopyDan. Men de kunne til min forbløffelse absolut intet gøre for at hjælpe mig.\nPå trods af jeg er både udgiver og autor, som CopyDan kalder forfattere og skribenter, så kunne de ikke hjælpe mig.\nSelvom de jo egentligt som nævnt kræver penge ind fra netop uddannelsesinstitutionerne på vegne af netop sådan nogle som mig, der skaber tekster og andet indhold som bruges massivt i undervisningen.\nOg på trods af at jeg kan bevise dette.\nHer er for eksempel en liste over de ti sites jeg har flest henvisninger fra:\nSom I kan se, så er det hovedsageligt forskellige læringsplatforme som bruges af folkeskoler og ungdomsuddannelser som dominerer de øverste pladser.\nDet betyder at lærere aktivt linker til og altså bruger mit materiale i deres undervisning. Og med god grund.\nOg hvis vi ser på hvornår Klimaleksikon bliver benyttet, så er det også klart i skoletiden:\nMen selvom mit materiale bliver massivt benyttet i undervisningen, også af lærerne, så kan jeg intet få fra CopyDan.\nFordi det foregår digitalt. Og fordi der \u0026ldquo;kun\u0026rdquo; i teknisk forstand foretages en kopiering (af filer ned i elevens browser når de klikker det link som læreren deler med dem.)\nHavde jeg udgivet en håndgribelig fysisk bog som var blevet kopieret og benyttet i undervisningen i samme omgang, så var jeg blevet betalt for det.\nDet virker som om lovgivningen ikke er fulgt med tiden.\nDet kan jeg bare ikke bruge til specielt meget, jeg kan blot konstatere at mange andre, som får deres materiale benyttet i mindre omfang end mig, de får penge for det - mens jeg ikke får en krone.\nSå indtil videre må jeg glæde mig over at have været idealist og gennem 11 år at have gjort over en million mennesker klogere på klima. Gjort flere piger interesserede i tekniske og naturvidenskabelige fag. Og måske endda have forhindret eller afhjulpet klimaangst blandt en del børn.\nOg det er altsammen bestemt også ganske værdifuldt.\n"
    }
    
    , 
    {
        "url": "/emner/copydan/",
        "title": "CopyDan",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/fundraising/",
        "title": "fundraising",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/%C3%B8konomi/",
        "title": "økonomi",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/crowdfunding/",
        "title": "crowdfunding",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/cta/",
        "title": "cta",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/donorbox/",
        "title": "donorbox",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/fundraising/klimaleksikon-crowdfunding-donorbox/",
        "title": "Kan man crowdfunde et klimaleksikon?",
        "content": "Klimaleksikon er en meget væsentlig dansk kilde til især unge menneskers viden om klima og klimaændring.\nOm to måneder fejrer Klimaleksikon 11 års fødselsdag på nettet. Jeg har personligt sørget for at over en million mennesker i den periode er blevet klogere på klima. Det har jeg gjort rent pro bono.\nMen det koster at udvikle og holde et klimaleksikon up to date, og jeg har derfor besluttet at jeg vil skabe et økonomisk fundament for Klimaleksikon der gør at jeg i det mindste får dækket mine udgifter ind fremover.\nJeg har kontaktet et stort antal danske virksomheder, men de var ikke interesserede i at bidrage til at udbrede viden om klima. Til trods for at de i pressen fører sig frem som de store klimaforkæmpere.\nNuvel, deres penge - deres prioriteringer.\nJeg vil nu undersøge om der blandt befolkningen bredt set er en større reel interesse for at sætte sine penge der hvor snakken går.\nDerfor har jeg lavet en crowdfunding med følgende ordlyd:\nLennart Kiil har gennem 11 år for egen regning drevet Klimaleksikon. I den periode er over en million mennesker blevet klogere på klima på grund af Klimaleksikon.\nKlimaleksikon bruges dagligt af især unge over hele landet når de søger viden om klima og relaterede emner. Det er vigtigt at de ved der findes en anden mulighed end at pjække fra skole. Klimaleksikon sørger for at der også er at sted på nettet for dem som vil lære noget og søger at tilgå klimaproblemet konstruktivt.\nDen vidensbaserede og fornuftige tilgang er nu vigtigere end nogensinde før. Vi risikerer at spørgsmålet om klima bliver overtaget af politiske aktivister.\nMen det er dyrt at holde et klimaleksikon kørende, udvikle det og give så mange mennesker i alle aldre mere viden. Det koster årligt titusindvis af kroner.\nDerfor mener Lennart Kiil at det er på tide at flere træder til og bakker op om Klimaleksikon som baserer sig på viden frem for følelser i klimaspørgsmålet. Desværre har danske virksomheder, som ellers taler meget om klima, hidtil vist sig uvillige til at bakke op om og sponsorere det vidensbaserede Klimaleksikon.\nSå nu må almindelige borgere og gode mennesker træde til!\nPå Klimaleksikon har jeg valgt at holde call to action diskret i første omgang.\nDet ser sådan her ud:\nDette CTA sender en videre til en formular.\nDenne formular kan både ses og bruges lige herunder, så du er naturligvis velkommen til at yde et bidrag til Klimaleksikon hvis du har lyst til at støtte en videns- og fornuftsbaseret tilgang til klimaproblemet.\nDet bliver spændende om der er opbakning :)\n"
    }
    
    , 
    {
        "url": "/emner/journalistik/",
        "title": "journalistik",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/journalistik/mellemrubrikker-indholdsoversigt/",
        "title": "Mellemrubrikker som indholdsoversigt",
        "content": "Da jeg for nylig udvidede min profilside på FOLKETS, som du kan finde her: Lennart Kiil , lavede jeg en indholdsoversigt baseret på mellemrubrikkerne i teksten.\nDet viste sig hurtigt at Google i søgeresultatet tog højde for dette ved at linke direkte til nogle af de mellemrubrikker som jeg havde angivet i indholdsoversigten og i selve mellemrubrikkerne med id.\nIndholdsoversigten er teknisk set en uordnet liste.\nSå\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#journalistisk-deklaration\u0026#34;\u0026gt;Journalistisk deklaration\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; linker til længere nede\n\u0026lt;h2 id=\u0026#34;journalistisk-deklaration\u0026#34;\u0026gt;Journalistisk deklaration\u0026lt;/h2\u0026gt; "
    }
    
    , 
    {
        "url": "/erfaring/frontend/jquery-javascript/",
        "title": "jQuery - væk med paranteser i tekst",
        "content": "\u0026lt;script src=\u0026#34;https://code.jquery.com/jquery-2.2.4.min.js\u0026#34; integrity=\u0026#34;sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; function stripParenthesis( node ) { if(node.length) { node.contents().each(function(index, child) { if( child.nodeType === 3 ) { child.nodeValue = child.nodeValue.replace(/\\(|\\)/g, \u0026#39;\u0026#39;); } else { stripParenthesis( $(child) ); } }); } } jQuery(document).ready(function($) { stripParenthesis( $(\u0026#39;a:contains(\u0026#34;Opskriftsgruppe\u0026#34;)\u0026#39;).closest( \u0026#34;span\u0026#34; ) ); $(\u0026#39;a:contains(\u0026#34;Opskriftsgruppe\u0026#34;)\u0026#39;).css(\u0026#39;display\u0026#39;, \u0026#39;none\u0026#39;); $(\u0026#39;a:contains(\u0026#34;Opskriftsgruppe\u0026#34;)\u0026#39;).closest( \u0026#34;span\u0026#34; ).css({ \u0026#34;font-size\u0026#34;: \u0026#34;21px\u0026#34;, \u0026#34;line-height\u0026#34;: \u0026#34;3\u0026#34; }); }); \u0026lt;/script\u0026gt; "
    }
    
    , 
    {
        "url": "/emner/ankertekst/",
        "title": "ankertekst",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/seo/hvad-betyder-ankertekst/",
        "title": "Hvad betyder ankertekst?",
        "content": "Gider du linke til min profil-side på FOLKETS med Lennart Kiil i ankerteksten?\nSpurgte jeg i dag.\nPersonen, jeg spurgte, var så venlig at linke med Lennart Kiil netop i ankerteksten. Han havde linket mit navn til min profil og dermed gjort præcist som jeg havde håbet på han ville.\n\u0026ldquo;Men hvad betyder ankertekst, bare så jeg lærer lidt her?\u0026rdquo;\nSpurgte han så.\nIfølge Wikipedia er ankerteksten:\nThe anchor text, link label, link text, or link title is the visible, clickable text in a hyperlink.\nOversat til dansk betyder det vel noget i retning af:\n\u0026ldquo;Ankerteksten er den synlige, klikbare del af et hyperlink.\u0026rdquo;\nEksempelvis sådan her:\nSe profilen for \u0026lt;a href=\u0026#34;https://www.folkets.dk/brugere/lennart-kiil\u0026#34;\u0026gt;Lennart Kiil\u0026lt;/a\u0026gt; for at lære mere om ham. Som bliver til:\nSe profilen for Lennart Kiil for at lære mere om ham.\nDe fleste er enige om at ankerteksten har betydning i SEO-sammenhæng for ranking i Googles søgemaskine.\nMit håb er netop også at jeg kan generobre førstepladsen på Google for mit eget navn, en plads jeg har måttet - midlertidigt forhåbentligt - overlade til Berlingske.\n"
    }
    
    , 
    {
        "url": "/emner/linkbuilding/",
        "title": "linkbuilding",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/ranking/",
        "title": "ranking",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/perl/",
        "title": "perl",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/tips-tricks/sorter-markdown-efter-overskrifter/",
        "title": "Sorter markdown dokument",
        "content": "Sorter sektioner i markdown. For eksempel efter #\nSorter # b mellemrubrik efter # a mellemrubrik.\n#B a content of B #A b content of A til\n#A b content of A #B a content of B I terminal med\nperl -0777 -ne \u0026#39; (undef,@paragraphs) = split /^#(?=[^#])/m; print map {\u0026#34;#$_\u0026#34;} sort @paragraphs; \u0026#39; file.md For yderligere info se også svar her "
    }
    
    , 
    {
        "url": "/erfaring/tips-tricks/bevar-whitespace-output/",
        "title": "Bevar whitespace i output med &nbsp;",
        "content": "Nogle gange her man bare brug for noget plads i et dokument.\nNon-breaking space – \u0026amp;nbsp; – er ikke bare non-breaking, den er også \u0026rsquo;non-collapsing'.\nSom du kan læse på wikipedia :\nNon-collapsing behavior A second common application of non-breaking spaces is in plain text file formats such as SGML, HTML, TeX and LaTeX, whose rendering engines are programmed to treat sequences of whitespace characters (space, newline, tab, form feed, etc.) as if they were a single character (but this behavior can be overridden). Such \u0026ldquo;collapsing\u0026rdquo; of whitespace allows the author to neatly arrange the source text using line breaks, indentation and other forms of spacing without affecting the final typeset result.\nIn contrast, non-breaking spaces are not merged with neighboring whitespace characters when displayed, and can therefore be used by an author to simply insert additional visible space in the resulting output without using spans styled with peculiar values of the CSS “white-space” property. Conversely, indiscriminate use (see the recommended use in style guides), in addition to a normal space, gives extraneous space in the output.\nDerfor kan \u0026amp;nbsp; bruges til at bevare whitespace, altså tomrum - herunder blanke linjer, i html-output i browsere, pdf-output i dokumenter og så videre, når kilden er en tekst-fil, markdown eller anden \u0026lsquo;ren tekst\u0026rsquo;-baseret fil.\nEksempler:\nText Text giver\nText\nText\nMens\nText \u0026amp;nbsp; \u0026amp;nbsp; Text giver\nText\nText\n"
    }
    
    , 
    {
        "url": "/tools/bootstrap-4/",
        "title": "bootstrap-4",
        "content": ""
    }
    
    , 
    {
        "url": "/cm/",
        "title": "Cm",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/drupal-8/",
        "title": "Drupal 8",
        "content": ""
    }
    
    , 
    {
        "url": "/cm/feed/",
        "title": "feed",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/frontend/",
        "title": "frontend",
        "content": ""
    }
    
    , 
    {
        "url": "/tools/pantheon/",
        "title": "pantheon",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/frontend/klimaleksikon-tachyons-performance/",
        "title": "Sådan fik jeg perfekte 100 i mobilhastighed",
        "content": "Med en static site generator er det efterhånden relativt nemt at bygge et site som er optimeret på ydelse.\nMen hvis nu man skal bygge noget mere kompliceret hvor man har brug for et CMS. Eller endda en DXP, som typisk er endnu tungere — hvad så?\nKan man stadig komme helt i top med performance i frontend med et CMS?\nJa! Heldigvis da.\nKlimaleksikon, Danmarks bedste sted at blive klog på klima , er bygget med Drupal 8. Tidligere brugte jeg Bootstrap 4 i frontend. Nu har jeg skiftet til Tachyons.\nSitet er hosted på Pantheon. Og de arbejder sammen med Fastly omkring CDN.\nAllerede med Bootstrap 4 klarede Klimaleksikon sig flot i Chromes test for ydelse i mobil. Med resultater i de helt høje 90\u0026rsquo;ere.\nMen jeg udskiftede Bootstrap 4 med Tachyons. Og nu er det lykkedes mig at få det bedst mulige resultat på 100 i mobil-testen.\nOg resultatet er vel at mærke opnået med den hårde indstilling: \u0026ldquo;Applied Fast 3G, 4x CPU Slowdown\u0026rdquo;\nDet skal siges at det er på sider uden billeder. På sider med billeder, som for eksempel forsiden, får jeg \u0026ldquo;kun\u0026rdquo; 99 som resultat.\nMen alt i alt yderst tilfredstillende resultater. Som du naturligvis selv kan efterprøve hvis du har Chrome som browser.\nKonklusion:\nKombinationen Pantheon, Drupal 8 og Tachyons kan bestemt anbefales hvis du vil have et hurtigt site.\n"
    }
    
    , 
    {
        "url": "/tools/tachyons/",
        "title": "tachyons",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/ydelse/",
        "title": "Ydelse",
        "content": "Ydelse, på engelsk performance, er en meget væsentlig parameter i næsten alle digitale produkter.\n"
    }
    
    , 
    {
        "url": "/erfaring/frontend/hastighed-uden-bannere/",
        "title": "FOLKETS meget hurtigere efter drop af bannere",
        "content": "For lidt over to uger siden droppede jeg bannere helt på FOLKETS.\nDe første resultater viste at det gav betydeligt hurtigere sider til brugerne.\nNu er der data nok til at konkludere noget mere håndfast i forhold til hastighed. Og til at se nærmere på de forskelige enheder:\nIkke overraskende er de største forbedringer der hvor der før var flest bannere. En halvering af tiden det tager at loade på tablet og laptop/desktop.\nPå mobil var der færre bannere og her er effekten mindre. En forbedring på knap 10 procent.\nMobil er også mere afhængig af ting som jeg ikke har indflydelse på såsom folks mobile dækning. Hvis folk sidder i toget eller andre steder med dårlig dækning, så kan ens site være nok så optimeret - så vil det stadig gå langsomt for brugeren.\nOg det afspejler sig i at det er svært at få gennemsnitstiderne lige så langt ned som for enheder der er på mere stabile netværk.\nAltså, en forbedring i snit på knap 10 procent på mobil. Betyder det så at ændringen har været omsonst for mobil?\nNej, man skal ikke lade sig snyde af gennemsnittet som især på mobil kan påvirkes af outliers, når folk sidder med en dårlig mobil forbindelse, og det tager måske 20 sekunder at hente en side. Det sker næppe ofte på tablets på wifi eller desktops på kablede forbindelser.\nOg hvis vi ser på intervaller i stedet for gennemsnit, så er der en klar forbedring - også for mobil:\nLæg mærke til at uanset om vi ser på mobil eller tablet / desktop, så er der nu langt, langt flere end før i de gode, hurtige intervaller og langt, langt færre i de dårlige, langsomme intervaller.\nEksempelvis er der efter at jeg droppede bannere mange flere i intervallet 0-1 sekunder og i intervallet 1-3 sekunder. Og meget færre i intervallet 7-13 sekunder. På tværs af enheder.\nDet vil sige at hvadenten vi ser på mobil eller desktop, så er der nu langt færre end før som oplever FOLKETS som langsomt.\nHvis vi alene ser på hastighed og den brugeroplevelse der ligger i forbindelse hermed, så har valget om at fjerne bannere været en ubetinget succes på tværs af alle enhedstyper.\nSenere vil jeg se på hvad det har betydet for andre faktorer såsom tid brugt på sitet, afvisningsrate og konvertering.\n"
    }
    
    , 
    {
        "url": "/tools/google-analytics/",
        "title": "google-analytics",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/seo/lovende-ctr-google-discover/",
        "title": "Lovende Google Discover klikrate (CTR)",
        "content": "Torsdag den 30. april 2019 dukkede en side fra FOLKETS for føste gang op i Googles Discover.\nSiden da er det sket nogle gange:\nKliks Visninger CTR1 154 ~ 1400 11% Google Discover er en slags personligt feed baseret på Googles søgemaskine kombineret med kunstig intelligens som kan give personlige resultater.\nGoogles Discover funktion er tilgængelig på mobile Android-enheder. Discover kan tilgås med selve Google-appen.\nSet fra en udgivers synspunkt ser Google Discover interessant ud da klikraten umiddelbart er meget høj:\nPå billedet ses det også at man nu for nogle sites i Search Console kan få oplysninger om visninger og kliks fra Google Discover. Det tyder på at Google satser en del på det her.\nAntallet af kliks fra Google Discover er samlet set stadigt meget lavt, men mon ikke det kommer til at stige hvis for eksempel at Google Discover kobles mere sammen med Googles Assistent, for eksempel.\nClick-through rate, på dansk klikrate - sommetider benævnt klikfrekvens. Andelen af kliks per 100 visninger.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"
    }
    
    , 
    {
        "url": "/cases/climate-encyclopedia/",
        "title": "Climate Encyclopedia",
        "content": "Climate Encyclopedia er den engelske udgave af Klimaleksikon.dk\n"
    }
    
    , 
    {
        "url": "/erfaring/frontend/bootstrap-4/",
        "title": "Det nemmeste CSS framework",
        "content": "Bootstrap 4 er næppe det nemmeste og hurtigste at prototype i længere. Og lidt for tungt hvis man virkelig går op i hastighed også på langsommere mobilforbindelser.\n"
    }
    
    , 
    {
        "url": "/cases/gastrofun/",
        "title": "Gastro Fun",
        "content": "For mig er der en ekstra tilfredsstillelse ved at arbejde på ting hvor jeg har været med fra starten til at lægge fundamentet. Og det var tilfældet med madsitet GastroFun.dk .\nSammen med Per Asmussen byggede jeg GastroFun.dk fra bunden. Vi har været gode til at finde de rigtige løsninger i forhold til indholdsstruktur og informationsarkitektur.\nSiden har allerede opnået en meget prominent placering i Googles søgemaskine hvilket har været et centralt succeskriterie.\nPer er meget ambitiøs med siden, og det passer mig godt. I dag er udvikling på nettet altid noget løbende fordi konkurrenterne hele tiden er i bevægelse.\nJeg er derfor fortsat med til at rådgive og løse konkrete udfordringer på GastroFun.dk så siden forhåbentligt kan klare sig endnu bedre i fremtiden.\nSe også docs "
    }
    
    , 
    {
        "url": "/erfaring/seo/google-tidlig-indsats/",
        "title": "Google belønner tidlig indsats",
        "content": "Små medier kan markere sig ved at være først med på internationale navne. Og det er tilsyneladende også noget som giver bonus i søgeresultaterne.\nFor ikke så længe tid siden skrev jeg et indlæg her på Kiils med titlen: Når de små medier overhaler de store :\nDe små medier er generelt mere manøvredygtige end de store. Det gælder også på indholdsstrategien.\nDet betyder at små medier kan reagere hurtigt på internationale trends.\nEt eksempel på dette er at Folkets Avis har skrevet meget om Jordan Peterson . Det har de store danske medier ikke, på trods af at han er en meget omtalt mand i den internationale presse.\nFolkets Avis var altså tidligt ude og markere sig med indhold om Jordan Peterson, som ikke var blevet opdaget af den øvrige danske presse endnu på det tidspunkt.\nI dag har flere medier så skrevet om manden.\nMen den indsats, Folkets Avis gjorde, gav ikke bare trafik dengang. Noget tyder på at en tidlig og relativ omfattende indsats belønnes af Googles søgemaskinealgoritme.\nSe her:\nDet er en flot placering. Om det bliver muligt at holde den, vil tiden vise.\nMen det er i hvert fald rart at se at det betaler sig at gøre en grundig og tidlig indsats.\n"
    }
    
    , 
    {
        "url": "/erfaring/indhold/om-oplevelser-og-langsigtet-indholdsstrategi/",
        "title": "Om oplevelser og langsigtet indholdsstrategi",
        "content": "Præmisserne på internettet ændrer sig hele tiden.\nKan det så overhovedet betale sig at tænke langsigtet?\nJa!\nDet er faktisk noget nær nødvendigt. Ikke mindst hvis du har planer om at hente trafik fra søgemaskiner som tillægger \u0026ldquo;historik\u0026rdquo; en stor betydning.\nOg det gør for eksempel Googles søgemaskine i min erfaring.\n(Jeg har Klimaleksikon.dk med hele ti år på nettet i næsten uforandret form at bygge den påstand på, men det vil jeg skrive om i et andet indlæg.)\nHvis du engang i fremtiden vil klare dig godt på et bestemt søgeord, er det en god idé allerede nu at gå igang med at bygge fundamentet.\nPå Folkets Avis har jeg lavet muligheden for at man kan lave publikationer, som får sin egen plads på avisen.\nHver publikation kan være redaktionelt og økonomisk uafhængig af Folkets Avis og kan i princippet endda udgives på et separat domæne.\nDen første publikation, jeg har lavet, er et magasin kaldet \u0026lt;em\u0026gt;Oplevelser\u0026lt;/em\u0026gt; . På Folkets Avis fylder politik ret meget. Så er det rart at blive mindet om at livet også er andet end det.\nIdeen er altså dels nu og her at skabe godt indhold som supplerer den redaktionelle linje og samtidig på længere sigt at rykke frem i Google på ordet \u0026lsquo;oplevelser\u0026rsquo;.\nMåske er online publikationer og magasiner i det hele taget en god måde at opbygge digital tilstedeværelse på. Og man behøver ikke nødvendigvis et domæne til hver af dem.\n"
    }
    
    , 
    {
        "url": "/erfaring/abo/salg/",
        "title": "risikoen for at abonnenter forsvinder med denne teknik er desværre stor",
        "content": "Tidligere telefonmand skrev til mig med godt råd – lige efter kampagnen var gået i luften.\nMan kan ikke tage højde for alt selv. Og nogle gange prøver man noget af uden at have tænkt alle konsekvenser helt igennem.\nOg i forhold til abonnementsmodellen bør man nok altid overveje et eventuelt tiltags effekt ikke bare på konverteringsraten, men også på frafaldsraten.\nOg blot få minutter efter jeg i dag havde lovet en signeret madbog af Knud Damgaard til nye privat- og supersponsorer på Folkets Avis tikkede følgende besked ind:\nDu laver en klassisk fejl med at belønne nye abonnenter med din bog, hvor nogle af de gamle abonnenter så vil føle sig forfordelt. Jeg er personligt ligeglad, men risikoen for at abonnenter forsvinder med denne teknik er desværre stor. Jeg så det specielt, da jeg arbejdede i telebranchen omkring årtusindskiftet. Folk skiftede teleselskab oftere end de skiftede underbukser, fordi teleselskaberne lokkede nye kunder til og belønnede ikke dem der blev. Det er heldigvis skiftet nu. Pas på ikke at falde i den samme fælde. Dette er skrevet i kærlighed til Folkets Avis og dit arbejde.\nDet kunne jeg jo egentligt godt se at han havde ret i.\nMen han var ikke færdig endnu.\nHan skrev videre:\nEn alternativ mulighed er næste gang at benytte de ting du har til rådighed som belønning i en konkurrence, hvor du udtrækker blandt alle dine abonnenter/sponsorer.\nOg det vil jeg så gøre snart.\nFor man skal behandle sine abonnenter godt. Simpelthen vise at man husker på dem man har – og ikke kun er opmærksom på at få nye ind.\nMan bliver en bedre forretningsmand af at lytte til andres råd.\nOg et bedre menneske.\n"
    }
    
    , 
    {
        "url": "/erfaring/muren/redning/",
        "title": "En redningsplan for Folkets Avis – sådan tilpasser jeg mig for at overleve",
        "content": "Folkets Avis er enestående i den forstand at mediet i modsætning til den øvrige danske presse fungerer helt uden mediestøtte.\nDet gør at den er skarpere end de andre medier i sin kritik af systemet og politikerne. Og det er godt for demokratiet.\nMen det skal heller ikke være nogen hemmelighed at det er lidt af en udfordring at få sådan en størrelse til at løbe rundt og give overskud.\nIkke desto mindre havde jeg held med det. Og i en periode var udviklingen endog meget positiv.\nMen så ændrede Facebook på sin algoritme.\n¶ Helt andre præmisser Facebook ændrede kort sagt på sine algoritmer, og det halverede trafikken til Folkets Avis .\nNår trafikken halveres, så halveres også antallet af abonnenter som sitet kan oppebære . Det er simpel matematik.\nÆndringen i Facebooks algoritmer betød således at antallet af betalende brugere på Folkets Avis begyndte at falde i stedet for at stige. Og det er ikke en holdbar udvikling i længden.\nNår præmisserne på den måde radikalt forandrer sig, så må man tilpasse sig. Eller opgive. Eller søge mediestøtten som de andre.\nMen for mig er mediestøtten ikke en mulighed, jeg vil benytte mig af til Folkets Avis. Så ville den blive lige så ligegyldig og systembevarende som de andre medier i Danmark.\nHeldigvis er der andre veje frem!\nFremover vil jeg fokusere mindre på de sociale medier og mere på at skabe værdi for læsere og virksomheder inde på FOLKETS.DK som nu er en udgiverplatform med plads til brands.\nFolkets Avis er altså ikke længere alene på FOLKETS.DK.\nFolkets Avis er stadig flagskibet på FOLKETS.DK - men der er også andre medier på platformen. Og plads til brands og produkter!\nMan kan sige at Folkets Avis i den forstand er blevet til et brand på FOLKETS.DK\nEt andet brand på FOLKETS.DK er mit magasin om det gode i livet: Oplevelser .\nFolkets Avis vil nok altid have lidt en særstilling i mine øjne. Folkets Avis har opbygget FOLKETS.DK.\nMen nu bliver der også plads til Folkets TV. Og meget, meget mere.\nDet er Folkets Avis der har bygget FOLKETS.DK op. Men nu kommer andre brands og medier til og understøtter det arbejde.\nSåledes klarer FOLKETS.DK sig allerede nu rigtigt fint på en række søgeord som ikke kun har relevans for Folkets Avis (omend det er Folkets Avis\u0026rsquo; fortjeneste), men også for andre brands som er på eller kunne tænkes at komme til på FOLKETS.DK.\nSamtidig vil de nye medier og brands på FOLKETS.DK bidrage yderligt til opbygningen af både forside og landingssider. Det er synergi-effekten i praksis.\nOg den slags skal der til hvis kampen skal tages bare en lille smule op imod de amerikanske medie-giganter ;)\nLad os tage landingssider som eksempel på hvordan synergi-effekten kan tage sig ud i praksis:\nLandingssider på FOLKETS.DK fungerer på tværs af de enkelte brands, og det giver en række fordele for alle parter. Hver publikation og hvert brand kan udgive på de fælles landingssider for personer og organisationer.\nFor eksempel ville et forlag kunne omtale en bog på siden for Jordan Peterson .\nEn landingsside der får en del specifik trafik. Det vil sige at de brugere som kommer ind på siden i forvejen har en interesse for emnet. Så har man et produkt, som knytter sig til den person, så er det her man skal ud med det.\nOgså forsiden er tilgængelig for alle brands og medier på platformen - når bestemte betingelser er opfyldt.\nForsiden giver plads til de bedste og mest interessante indlæg fra hver af udgivelserne og også til brands som vil kunne nyde godt af en forøget trafik og bedre placering i søgeresultaterne på Google.\nEndelig kan hver enkelt bruger på FOLKETS.DK opbygge sin egen nyhedsstrøm og følge relevante brands og medier.\n¶ Mikromedier og rapid prototyping Hele denne model giver også plads til rapid prototyping - altså det at man prøver af om noget virker. Man har allerede et publikum til rådighed og værktøjer til sammenligning med andre medier og brands.\nPå den måde kommer alt det, som er bygget op på FOLKETS.DK i forbindelse med udviklingen af Folkets Avis, mange flere til gode.\nOg uanset om det er noget omkring ens brand eller ens udgivelse, man vil have afprøvet, så kan det lade sig gøre. Lykkes eksperimentet, kan man eventuelt køre en bredere kampagne.\nDet er værd at understrege de enkelte udgiveres autonomi.\nHvert brand på FOLKETS.DK kan have sin egen redaktør, sin egen redaktionelle linje, sit eget design (inden for visse rammer) og så fremdeles.\nDer er meget andet og sige om alt dette, men afslutningsvist vil jeg blot nævne én ting mere:\nForsiden og FOLKETS.DK bliver meget mere mangfoldig på den her måde. Så det ikke altsammen handler om politik. Og det gør livet jo heller ikke.\nOg den bliver mere levende og dynamisk.\nJeg er glad for at skabe mere rum til at det gode og rare i livet også får mere omtale og plads på nettet. Og til at de dygtige producenter i Danmark kan fortælle om de de skaber til gavn for os alle.\nOg så lover jeg ikke at glemme den systemkritiske journalistik som ligger mit hjerte nært. Det er nemlig den alt det andet kan være med til at give bedre økonomiske vilkår.\nGod dag derude og tak fordi du læste med!\nLennart Se også min video her:\n"
    }
    
    , 
    {
        "url": "/emner/abonnementsmodellen/",
        "title": "Alt om Abonnementsmodellen",
        "content": " ¶ Abonnementsmodellen forbindes på engelsk ofte med SaaS, men den rette term er snarere subscription model "
    }
    
    , 
    {
        "url": "/cm/featured/",
        "title": "Featured",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/abo/abonnenter-nok/",
        "title": "Får jeg abonnenter nok til at leve af mit online-medie?",
        "content": "Sandsynligvis ikke. Men læs alligevel videre og få et simpelt værktøj til at vurdere dine chancer.\nAbonnementsmodellen for indhold er gammelkendt og har vist sit værd gennem tiden for magasiner og aviser.\nOg i dag har andre leverandører af indhold, for eksempel Netflix, stor succes med modellen. Også privatpersoner, som skaber indhold af forskellig art, har med hjælp fra services som Patroen haft glæde af modellen - nok oftest som supplement til anden indtægt.\nSelv har jeg erfaring med modellen fra det medie jeg har stiftet og opbygget: Folkets Avis .\nJeg kan nu leve af Folkets Avis. Det er en lille sejr i sig selv og forhåbentligt første skridt på vej mod flere succeser.\nMen hvad med dig?\nMange vil gerne starte et medie op eller på anden vis leve at at skabe indhold og sælge det online på et site man selv er ejer af.\n¶ Hvor meget skal der til? Inden man går i gang kan man med fordel gøre sig nogle overvejelser om hvad der skal til.\nDet handler om\nat få nogle læsere ind på sin side og sælge abonnementer til dem Vi kan nu se nærmere på hvor mange læsere der skal til, hvor god man skal være til at overbevise dem om at købe et abonnement, og hvor dygtig man skal være til at fastholde sine kunder, når man først har fået dem ind som abonnenter.\nHver solgt abonnement er en \u0026ldquo;vundet\u0026rdquo; abonnent. Las os kalde antallet af vundne abonnenter for Va.\nDet antal abonnenter, som kan vindes inden for en given periode, er givet ved antal læsere, noteret som L, og den andel af læsere man får solgt et abonnement til. Denne andel kalder vi konverteringraten, noteret som K.\nFor en given periode er tilvæksten i antal abonnenter således givet ved:\n$ V_a = L \\cdot K $\nHvis der ikke er noget frafald så er det samlede antal abonnenter, noteret A, ganske enkelt lig antallet af abonnenter vundet over tid, altså Va.\nMen sådan er virkeligheden ikke. Abonnenter falder hele tiden fra og tabes konstant af mange forskellige årsager.\nDet antal abonnenter, som tabes over en given periode, kan vi kalde Ta for tabte abonnenter. Det kan udregnes som produktet af det samlede antal abonnenter, A, og den andel af disse abonnenter som tabes inden for en given periode. Denne andel kalder vi frafaldsraten, F.\n$ T_a = A \\cdot F $\nGivet et nogenlunde stabilt læsertal og stabile konverterings- og frafaldsrater, så vil mediet på et tidspunkt nå et plateau, eller et vækstloft om man vil, hvor antal af løbende vundne abonnenter er lig med antallet af løbende tabte abonnenter – og det samlede antal abonnenter vil da stagnere. En ligevægt er på plads:\n$ T_a = V_a $\nHvis vi i stedet indsætter komponenterne for Ta og Va, får vi:\n$ A \\cdot F = L \\cdot K $\nDet antal abonnenter, du vil kunne opnå med et givet antal læsere og en fastlagt konverterings- og frafaldsrate, kan altså forudsiges ud fra denne simple formel:\n$ A = \\frac{L \\cdot K}{F } $\nLad os tage et konkret eksempel med 100.000 månedlige læsere, en månedlig konverteringsrate på en halv promille og en månedlig frafaldsrate på fem procent.\n$ A = \\frac{100000 \\cdot 0{,}0005}{0{,}05} = 1000 $\nAltså kan du under de forudsætninger ikke forvente mere end maksimalt 1000 abonnenter.\n¶ Få læsere - få abonnenter Hvis du i stedet kun har 10.000 læsere rammes vækstloftet allerede ved 100 opnåede abonnenter og så fremdeles.\nHvis dit medie er mere specialiseret, kan du måske øge konverteringsraten og sænke frafaldsraten, men så er det til gengæld også sværere at opnå det store antal læsere.\nOg husk på: Med tiden vil et større antal af læserne allerede være abonnenter og kan således ikke vindes. Og i takt med at antallet af abonnenter stiger vil det samlede antal abonnenter, der tabes, gøre det samme.\nDin vækst vil med andre ord flade asymptotisk ud, når antallet af abonnenter nærmer sig vækstloftet. Og så vil antallet ellers forblive omkring vækstloftet, med mindre du kan ændre markant på nogle af de nævnte faktorer.\nDu vil altså med stor sandsyblighed opleve at det bliver svært at opretholde vækst.\nOg du vil med næsten usvigelig sikkerhed ramme loftet. Og man kan nå dertil overraskende hurtigt.\nKan du leve af for eksempel 500 abonnenter - eller af 1000?\nDet kommer vel dels an på, hvor meget hver især betaler om måneden. Men prisen på abonnementet påvirker også antallet af abonnementer som kan sælges og dermed antallet af abonnenter som kan vindes og fastholdes.\nDet vender vil tilbage til.\n"
    }
    
    , 
    {
        "url": "/erfaring/some/delinger-bonus-linkedin/",
        "title": "Delinger giver bonus på LinkedIn",
        "content": "Læg relevante links på LinkedIn og forøg antallet af besøg til din profilside mangefold.\nFor ganske nylig begyndte jeg via LinkedIn at dele links til min blog her på Kiils .\nI første omgang var hensigten at dele ud af de erfaringer, som opbygningen af et digitalt medie helt fra bunden, har givet mig. Og det er ikke så få!\nJeg har brugt fem år på at skabe Folkets Avis , og i det tidsrum har jeg faktisk kun sporadisk haft tid til at bruge LinkedIn.\nModtagelsen på LinkedIn efter fem års pause har været rigtig god. Se blot her:\nMin aktivitetsforøgelse på LinkedIn, hvor jeg på det allerseneste flittigt har delt relevante links med originalt indhold, er i den grad blevet belønnet.\nMåske er der i dag mere fokus på indhold på LinkedIn end der var for fem år siden, da jeg sidst brugte LinkedIn med jævne mellemrum.\nI hvert fald kan jeg konstatere at deling af relevant og originalt indhold som links på LinkedIn resulterer i en markant stigning i antallet af mennesker som tjekker ens profilside ud.\nKonklusion:\nHvis du gerne vil have flere mennesker til at besøge din profilside på LinkedIn, skal du bare dele godt og originalt indhold.\nOm sammenhængen også gælder i samme grad hvis du deler andres indhold, skal jeg ikke kunne sige.\n"
    }
    
    , 
    {
        "url": "/emner/linkedin/",
        "title": "Lidt om LinkedIn",
        "content": ""
    }
    
    , 
    {
        "url": "/emner/sociale-medier/",
        "title": "Sociale medier",
        "content": ""
    }
    
    , 
    {
        "url": "/erfaring/trafik/kilder/",
        "title": "Sociale medier vigtige – men husk de andre trafikkilder",
        "content": "2017 var et rekordår for Folkets Avis på mange måder.\nSåledes var også de samlede antal sidevisninger højere end noget tidligere år.\nSer vi på anskaffelse skete der noget lidt overraskende. I hvert fald når man tager i betratning at antallet af fans på Folkets Avis Facebook side voksede pænt hen over året og nærmede sig 10.000 ved dets afslutning.\nFor på trods af stigningen faldt antallet af brugere som blev sendt til Folkets Avis fra de sociale medier, og med de sociale medier menes praktisk taget ene og alene Facebook.\nDenne udvikling passer fint med Facebooks ambitioner om at holde flere brugere inden for Facebooks egne rammer. Samtidig gør medier klogt i at finde andre trafikkilder og opdyrke et eget trofast publikum.\nOg måske endda tænke lidt i SEO-optimering.\nFolkets Avis oplevede således en stor stigning - næsten en fordobling - af forside trafik i 2017 i forhold il 2016. Det er godt.\nFlere kom også ind via søgninger på Google. Og web push notifikationer via Onesignal.\nEt område hvor Folkets Avis virkelig kan oppe sig er på email. Altså at få brugere ind gennem nyhedsbreve.\nUdviklingen på fem områder fra 2016 til 2017:\n"
    }
    
    , 
    {
        "url": "/erfaring/indhold/overhaling/",
        "title": "Når de små medier overhaler de store",
        "content": "Den korte afstand mellem læser og redaktion er en fordel.\nDe små medier er generelt mere manøvredygtige end de store. Det gælder også på indholdsstrategien.\nDet betyder at små medier kan reagere hurtigt på internationale trends.\nEt eksempel på dette er at Folkets Avis har skrevet meget om Jordan Peterson. Det har de store danske medier ikke, på trods af at han er en meget omtalt mand i den internationale presse.\nArbejdsgangene er kortere - og afstanden mellem læsere og redaktion ligeså - på de små medier.\nOg nogle gange er det læserne der her fingeren på pulsen.\nFolkets Avis giver så læseren mulighed for at blive skribent. Og i tilfældet Jordan Peterson har det for alvor givet pote.\n"
    }
    
    , 
    {
        "url": "/erfaring/devops/language-domains/",
        "title": "",
        "content": "Efter databases connction info\n$config[\u0026rsquo;language.negotiation\u0026rsquo;][\u0026lsquo;url\u0026rsquo;][\u0026lsquo;domains\u0026rsquo;][\u0026rsquo;en\u0026rsquo;] = \u0026lsquo;my-en-url.localhost\u0026rsquo;; $config[\u0026rsquo;language.negotiation\u0026rsquo;][\u0026lsquo;url\u0026rsquo;][\u0026lsquo;domains\u0026rsquo;][\u0026lsquo;de\u0026rsquo;] = \u0026lsquo;my-de-url.localhost\u0026rsquo;; $config[\u0026rsquo;language.negotiation\u0026rsquo;][\u0026lsquo;url\u0026rsquo;][\u0026lsquo;domains\u0026rsquo;][\u0026rsquo;es\u0026rsquo;] = \u0026lsquo;my-es-url.localhost\u0026rsquo;; $config[\u0026rsquo;language.negotiation\u0026rsquo;][\u0026lsquo;url\u0026rsquo;][\u0026lsquo;domains\u0026rsquo;][\u0026lsquo;fr\u0026rsquo;] = \u0026lsquo;my-fr-url.localhost\u0026rsquo;;\n"
    }
    
    , 
    {
        "url": "/erfaring/devops/litespeed-server/",
        "title": "",
        "content": "Search Api suggestions only working for loggged in users\n"
    }
    
    , 
    {
        "url": "/erfaring/devops/workflow/rollback/",
        "title": "",
        "content": "https://www.bounteous.com/insights/2020/03/11/automate-drupal-deployments/ "
    }
    
    , 
    {
        "url": "/erfaring/indhold/tegninger-grafik-illustrationer-billeder-fotos-gratis/",
        "title": "",
        "content": "https://undraw.co/illustrations http://www.heropatterns.com/ Jeg har ikke taget ikoner med.\nIkoner - mange. Men ofte er der enfin utf-8 karakter som kan klare opgaven.\n"
    }
    
    , 
    {
        "url": "/erfaring/muren/dogmer/",
        "title": "",
        "content": "Medier uden mur\nAlle medier på FOLKETS er frit tilgængelige - ingen betlaingsmur.\n"
    }
    
    , 
    {
        "url": "/erfaring/tips-tricks/git-tips/",
        "title": "",
        "content": "Reset dev branch til master\ngit checkout dev git reset --hard master git push --force origin dev "
    }
    
    , 
    {
        "url": "/old_index/",
        "title": "",
        "content": " Jeg hedder Lennart Kiil og har 20 års praktisk erfaring i krydsfeltet mellem internet, journalistik og sociale medier Jeg arbejder både med journalistiske ydelser og rådgivning — og har gennem årene hjulpet blandt andre Berlingske, Dansk Industri, Gentofte Hospital, Illustreret Videnskab, Ingeniøren, Ugeskrift for Læger, Region Syddanmark, Rigshospitalet, Aarhus Universitet og Statens Naturhistoriske Museum\nMine varmeste anbefalinger ―Per Asmussen Måske kan jeg hjælpe dig? Kontakt mig nu! "
    }
    
    , 
    {
        "url": "/kunde/berlingske/",
        "title": "Berlingske",
        "content": "Kiils havde en aftale med Berlingske om videnskabsjournalistik og formidling løftet fra det hedengangne forsker.net som Lennart Kiil stod bag.\n"
    }
    
    , 
    {
        "url": "/kunde/billetkontoret/",
        "title": "Billetkontoret A/S",
        "content": " Vi anvender løbende Lennart i vores arbejde med artikler til forske llige medier og platforme. Han formår at trække den vigtigste essens ud af de enkelte artikler. Vi er meget tilfredse med vores samarbejde.\n"
    }
    
    , 
    {
        "url": "/cases/coronakatastrofen/",
        "title": "Coronakatastrofen",
        "content": "En dansk brand- og medieplatform\nCoronakatastrofen er en bog om coronavirus.\n"
    }
    
    , 
    {
        "url": "/kunde/dansk-industri/",
        "title": "Dansk Industri",
        "content": "I forbindelse med klimaformidling.\n"
    }
    
    , 
    {
        "url": "/prompts/",
        "title": "Danske ChatGPT prompts",
        "content": "Det indledende prompt er afgørende for en brugbar samtale med ChatGPT. Følgende prompts giver ChatGPT en klar rolle og afgrænser dens svar på en meningsfuld måde.\nSådan bruger du prompts i listen\nFind prompt som bedst passer til den opgave du ønsker løst Tilpas med klik på tekst, udskift parenteser med egne ord Kopier prompt med saks og indsæt det i ny samtale i ChatGPT Se video: Sådan bruger du de danske ChatGPT prompts "
    }
    
    , 
    {
        "url": "/brands/digitalt/",
        "title": "digitalt",
        "content": ""
    }
    
    , 
    {
        "url": "/domains/",
        "title": "Domæner",
        "content": ""
    }
    
    , 
    {
        "url": "/domains/folkets/",
        "title": "Folkets.dk",
        "content": ""
    }
    
    , 
    {
        "url": "/personas/",
        "title": "Generelle ChatGPT Personaer",
        "content": "I OpenAI\u0026rsquo;s ChatGPT bruges den indledende \u0026ldquo;system message\u0026rdquo; ofte til en prompt som opstiller et emne eller opgave for samtalen.\nHer forsøger jeg i stedet at påvirke chattens \u0026ldquo;personlighed\u0026rdquo; og samtalens skrivestil med en \u0026ldquo;persona\u0026rdquo;.\nSådan bruger du personaer i listen\nFind persona som passer til den stil du ønsker i din tekst Tilpas eventuelt med egne inputs ved at klikke på teksten Kopier prompt med saks og indsæt det i ny samtale i ChatGPT "
    }
    
    , 
    {
        "url": "/kunde/gentofte-hospital/",
        "title": "Gentofte Hospital",
        "content": "Workshop om formidling af svært stof.\n"
    }
    
    , 
    {
        "url": "/kunde/hideaways/",
        "title": "Hideaways",
        "content": "Skrivning og redigering af tekster.\n"
    }
    
    , 
    {
        "url": "/kunde/illustreret-videnskab/",
        "title": "Illustreret Videnskab",
        "content": "Adskillige lange artikler om forskellige videnskabelige emner.\n"
    }
    
    , 
    {
        "url": "/kunde/ingeni%C3%B8ren/",
        "title": "Ingeniøren",
        "content": "Artikler om tekniske emner, ofte med udspring i biomimetik.\n"
    }
    
    , 
    {
        "url": "/venlig_index/",
        "title": "Kiils",
        "content": " Brugervenlig Klimavenlig Læsevenlig Er jeres digitale tilstedeværelse venlig nok? Kontakt Kiils nu! "
    }
    
    , 
    {
        "url": "/kontakt/",
        "title": "Kontakt",
        "content": "Du kan ringe på telefon 40261872 eller skrive en mail direkte til lennartkiil@gmail.com Postadresse:\nKiils v/Lennart Kiil Kirkeskov Allé 72 3050 Humlebæk\n"
    }
    
    , 
    {
        "url": "/kunde/",
        "title": "Kunder",
        "content": ""
    }
    
    , 
    {
        "url": "/brands/mediem%C3%B8llen/",
        "title": "Mediemøllen",
        "content": ""
    }
    
    , 
    {
        "url": "/brands/oplevelser/",
        "title": "Oplevelser",
        "content": ""
    }
    
    , 
    {
        "url": "/kunde/per-asmussen/",
        "title": "Per Asmussen",
        "content": "Per Asmussen siger:\nI forbindelse med etableringen af mit madmedie www.gastrofun.dk var jeg i dialog med flere digitale udviklingshuse, men efter en god snak med Lennart fra Kiils var jeg aldrig i tvivl om at han skulle være min samarbejdspartner hele vejen igennem – fra konceptudvikling, hjemmesideopbygning, indholdsstrategi, tekniske krav samt det visuelle udtryk.\nForståelsen for hvad det vil sige at gøre mediet brugervenligt både for læserne og brugerne var helt i top og en masse god sparring og feedback har givet mig et fremtidssikret og stærkt medie.\nProcessen fra ide til et færdigt medie var imponerende hurtig og siden var sågar udgivet 14 dage før lovet, hvilket var helt perfekt.\nTre måneder efter siden var i luften, fik jeg et SEO-bureau til at vurdere siden på nærmest alle parametre og siden fik en gennemsnitskarakter på 9 (på en 1-10 skala) og især sidens hurtighed og taksonomi-opbygning har imponeret mig.\nMediet har brug for konstant tilpasning og Kiils hurtige rettelser og justeringer er lige det jeg har brug for i en travl hverdag.\nJeg giver Kiils mine varmeste anbefalinger.\n"
    }
    
    , 
    {
        "url": "/priser/",
        "title": "Priser",
        "content": "Prisen er ens for offentlige institutioner, virksomheder og privatpersoner.\nKr. 700 i timen for tider mellem 09 og 11. Resten af arbejdstimerne koster 500,- i timen.\nDer afregnes kun i hele timer.\nPris eksklusiv moms.\n"
    }
    
    , 
    {
        "url": "/privacy/",
        "title": "Privacy",
        "content": "Kiils bruger så få cookies som nærmest muligt.\n"
    }
    
    , 
    {
        "url": "/kunde/videnplus/",
        "title": "PRO Ejendomme",
        "content": "Sten Thorup Kristensen fra VidenPlus siger:\n”Lennart Kiil arbejder seriøst, og han forstår ikke bare mit behov som udgiver, men også hvad der er vigtigt for læserne af PRO Ejendomme. Desuden kan han sætte sig ind i stoffet og kommentere det kvalificeret, selv om ejendomme ikke er hans fagområde. Det er en stor hjælp, når der er travlhed op til deadline.”\nKiils.dk læser korrektur på PRO Ejendomme så kunderne får et gennemarbejdet og finpudset produkt.\nPRO Ejendomme er et månedsbrev til professionelle i ejendomsbranchen.\n"
    }
    
    , 
    {
        "url": "/kunde/region-syddanmark/",
        "title": "Region Syddanmark",
        "content": "Klimaformidling til børn og unge.\n"
    }
    
    , 
    {
        "url": "/kunde/rigshospitalet/",
        "title": "Rigshospitalet",
        "content": "Kort formidlingskursus, workshop.\n"
    }
    
    , 
    {
        "url": "/brands/r%C3%A6vekagen/",
        "title": "Rævekagen",
        "content": "Rævekagen Satire og provokerende politisk analyse.\nFokus på personer, magtkampe, hykleri.\n"
    }
    
    , 
    {
        "url": "/kunde/statens-naturhistoriske-museum/",
        "title": "Statens naturhistoriske museum",
        "content": "Formidling omkring biomimetik.\n"
    }
    
    , 
    {
        "url": "/search/",
        "title": "Søgning",
        "content": " Tast søgeord i feltet Noget du ikke fandt? Kontakt Kiils "
    }
    
    , 
    {
        "url": "/kunde/ugeskrift-for-l%C3%A6ger/",
        "title": "Ugeskrift for læger",
        "content": "Artikler om robotteknologi og biomimetik og potentiale for brug i behandling og diagnostik.\n"
    }
    
    , 
    {
        "url": "/video/danske-chatgpt-prompts-intro-video/",
        "title": "Video: Sådan bruger du danske ChatGPT prompts",
        "content": " Se hele listen over danske prompts "
    }
    
    , 
    {
        "url": "/video/",
        "title": "Videoes",
        "content": ""
    }
    
    , 
    {
        "url": "/kunde/aarhus-universitet/",
        "title": "Aarhus Universitet",
        "content": "Formidling.\n"
    }
    
]
